{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfkjeDUil9FJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9PB5MH5hLay",
        "outputId": "ecccf6a0-aecf-4069-b28b-e42d0c1216f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBto6MOUj-DZ",
        "outputId": "1c7ce369-4ed2-4897-8b2f-88874545622c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "c1vobH8ij_K8",
        "outputId": "1c7a7e39-d8a8-423d-8075-e1e0cdd8c4dc"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "# fc8b5ea957cf72c6563226b2ffc1ef01cde29bf0\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgPX4qWnpWI4"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-ukGZ6sm-C1"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/MyDrive/Đồ án model recommendation/data_youchoose\"\n",
        "os.listdir(data_path)\n",
        "buy_data_path = 'yoochoose-buys.dat'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgvhGXYSnlAt"
      },
      "outputs": [],
      "source": [
        "buy_data = pd.read_csv(os.path.join(data_path, buy_data_path), names = ['SessionId', 'DateTime', 'ItemId', 'Price', 'Quantity'])\n",
        "buy_data['DateTime'] = buy_data['DateTime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
        "buy_data['Timestamp'] = buy_data['DateTime'].apply(lambda x: x.strftime('%s.%f'))\n",
        "buy_data = buy_data.sort_values(by = ['SessionId', 'DateTime'], ascending = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hpk7w973ows-",
        "outputId": "fe18534a-1145-4dce-a847-db9ac81ed9c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cddd8efe-95d8-4b45-b05e-90e3ac05ca80\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SessionId</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>ItemId</th>\n",
              "      <th>Price</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>2014-04-03 11:04:11.417</td>\n",
              "      <td>214821371</td>\n",
              "      <td>1046</td>\n",
              "      <td>1</td>\n",
              "      <td>1396523051.417000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>2014-04-03 11:04:18.097</td>\n",
              "      <td>214821371</td>\n",
              "      <td>1046</td>\n",
              "      <td>1</td>\n",
              "      <td>1396523058.097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>2014-04-02 10:42:17.227</td>\n",
              "      <td>214717867</td>\n",
              "      <td>1778</td>\n",
              "      <td>4</td>\n",
              "      <td>1396435337.227000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>21</td>\n",
              "      <td>2014-04-07 09:24:18.307</td>\n",
              "      <td>214548744</td>\n",
              "      <td>3141</td>\n",
              "      <td>1</td>\n",
              "      <td>1396862658.307000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>21</td>\n",
              "      <td>2014-04-07 09:24:18.360</td>\n",
              "      <td>214838503</td>\n",
              "      <td>18745</td>\n",
              "      <td>1</td>\n",
              "      <td>1396862658.360000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cddd8efe-95d8-4b45-b05e-90e3ac05ca80')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cddd8efe-95d8-4b45-b05e-90e3ac05ca80 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cddd8efe-95d8-4b45-b05e-90e3ac05ca80');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd6434fd-0bf8-4c1a-a911-f841145f1e7e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd6434fd-0bf8-4c1a-a911-f841145f1e7e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd6434fd-0bf8-4c1a-a911-f841145f1e7e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    SessionId                DateTime     ItemId  Price  Quantity  \\\n",
              "10         11 2014-04-03 11:04:11.417  214821371   1046         1   \n",
              "11         11 2014-04-03 11:04:18.097  214821371   1046         1   \n",
              "12         12 2014-04-02 10:42:17.227  214717867   1778         4   \n",
              "23         21 2014-04-07 09:24:18.307  214548744   3141         1   \n",
              "24         21 2014-04-07 09:24:18.360  214838503  18745         1   \n",
              "\n",
              "            Timestamp  \n",
              "10  1396523051.417000  \n",
              "11  1396523058.097000  \n",
              "12  1396435337.227000  \n",
              "23  1396862658.307000  \n",
              "24  1396862658.360000  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "buy_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "limnsoBfpUw3",
        "outputId": "98a3716a-7aea-4b92-9f73-ba14edca45f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1150753, 6)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "buy_data['Quantity'].value_counts().sort_index()\n",
        "buy_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "RE233CpPuoOe",
        "outputId": "cdf7c406-c38a-43da-dd95-3a99c56a16cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-218fb88e-030e-4c0f-87e4-a83e5d2dd5fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DateTime</th>\n",
              "      <th>ItemId</th>\n",
              "      <th>Price</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Timestamp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SessionId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2014-04-03 11:04:11.417</td>\n",
              "      <td>214821371</td>\n",
              "      <td>1046</td>\n",
              "      <td>1</td>\n",
              "      <td>1396523051.417000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2014-04-03 11:04:18.097</td>\n",
              "      <td>214821371</td>\n",
              "      <td>1046</td>\n",
              "      <td>1</td>\n",
              "      <td>1396523058.097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2014-04-02 10:42:17.227</td>\n",
              "      <td>214717867</td>\n",
              "      <td>1778</td>\n",
              "      <td>4</td>\n",
              "      <td>1396435337.227000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-218fb88e-030e-4c0f-87e4-a83e5d2dd5fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-218fb88e-030e-4c0f-87e4-a83e5d2dd5fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-218fb88e-030e-4c0f-87e4-a83e5d2dd5fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d804a4c1-bf90-4acf-a798-0175666ca649\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d804a4c1-bf90-4acf-a798-0175666ca649')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d804a4c1-bf90-4acf-a798-0175666ca649 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                         DateTime     ItemId  Price  Quantity  \\\n",
              "SessionId                                                       \n",
              "11        2014-04-03 11:04:11.417  214821371   1046         1   \n",
              "11        2014-04-03 11:04:18.097  214821371   1046         1   \n",
              "12        2014-04-02 10:42:17.227  214717867   1778         4   \n",
              "\n",
              "                   Timestamp  \n",
              "SessionId                     \n",
              "11         1396523051.417000  \n",
              "11         1396523058.097000  \n",
              "12         1396435337.227000  "
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = buy_data\n",
        "# x.head()\n",
        "x = x.set_index('SessionId')\n",
        "x.head()\n",
        "# x.index\n",
        "x = x[(x.index == 11) | (x.index == 12)]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDaco0K2rUIW",
        "outputId": "6dd4d2ff-e1c5-4b4f-afc5-e340585c67fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1132868, 6)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Thống kê số lượt xuất hiện và lọc ra các ItemId có trên 5 lượt xuất hiện\n",
        "df_item_count = buy_data[['ItemId', 'SessionId']].groupby('ItemId').count().sort_values(by = 'SessionId', ascending = False)\n",
        "df_item_count.columns = ['CountItemId']\n",
        "df_item_count_5 = df_item_count[df_item_count['CountItemId'] < 5]\n",
        "# Lọc khỏi dataset những ItemId có ít hơn 5 lượt xuất hiện\n",
        "dataset = buy_data[~buy_data['ItemId'].isin(list(df_item_count_5.index))]\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksL4tirEuOwW",
        "outputId": "fa14a20c-b24a-41c0-a1de-6cf6eceacf29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2014-09-30 02:35:12.859000\n",
            "(121743, 6)\n",
            "(1011125, 6)\n"
          ]
        }
      ],
      "source": [
        "from datetime import timedelta\n",
        "# Phân chia tập train/test sao cho tập test là 7 ngày gần đây nhất và train là dữ liệu còn lại\n",
        "maxdate = dataset['DateTime'].max()\n",
        "print(maxdate)\n",
        "mindate7 = maxdate - timedelta(days = 17)\n",
        "test = dataset[dataset['DateTime'] >= mindate7]\n",
        "dataset = dataset[dataset['DateTime'] <= mindate7]\n",
        "print(test.shape)\n",
        "print(dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xos_YVmlvYu4",
        "outputId": "0138478d-db4e-44e2-dec9-be440b99c4c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-48715c0f-3070-41ed-a983-7801d983c304\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SessionId</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>ItemId</th>\n",
              "      <th>Price</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>2014-04-03 11:04:11.417</td>\n",
              "      <td>214821371</td>\n",
              "      <td>1046</td>\n",
              "      <td>1</td>\n",
              "      <td>1396523051.417000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>2014-04-03 11:04:18.097</td>\n",
              "      <td>214821371</td>\n",
              "      <td>1046</td>\n",
              "      <td>1</td>\n",
              "      <td>1396523058.097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>2014-04-02 10:42:17.227</td>\n",
              "      <td>214717867</td>\n",
              "      <td>1778</td>\n",
              "      <td>4</td>\n",
              "      <td>1396435337.227000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>2014-04-07 09:24:18.307</td>\n",
              "      <td>214548744</td>\n",
              "      <td>3141</td>\n",
              "      <td>1</td>\n",
              "      <td>1396862658.307000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>2014-04-07 09:24:18.360</td>\n",
              "      <td>214838503</td>\n",
              "      <td>18745</td>\n",
              "      <td>1</td>\n",
              "      <td>1396862658.360000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48715c0f-3070-41ed-a983-7801d983c304')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48715c0f-3070-41ed-a983-7801d983c304 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48715c0f-3070-41ed-a983-7801d983c304');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ade8581c-5dd6-4d12-8243-2ce141c0b081\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ade8581c-5dd6-4d12-8243-2ce141c0b081')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ade8581c-5dd6-4d12-8243-2ce141c0b081 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   SessionId                DateTime     ItemId  Price  Quantity  \\\n",
              "0         11 2014-04-03 11:04:11.417  214821371   1046         1   \n",
              "1         11 2014-04-03 11:04:18.097  214821371   1046         1   \n",
              "2         12 2014-04-02 10:42:17.227  214717867   1778         4   \n",
              "3         21 2014-04-07 09:24:18.307  214548744   3141         1   \n",
              "4         21 2014-04-07 09:24:18.360  214838503  18745         1   \n",
              "\n",
              "           Timestamp  \n",
              "0  1396523051.417000  \n",
              "1  1396523058.097000  \n",
              "2  1396435337.227000  \n",
              "3  1396862658.307000  \n",
              "4  1396862658.360000  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# list các sessionIds\n",
        "sessIds = list(dataset['SessionId'].unique())\n",
        "# Lấy ngẫu nhiên 1/4 số lượng các session\n",
        "# n_filter = int(len(sessIds)/4)\n",
        "n_filter = int(len(sessIds))\n",
        "np.random.shuffle(sessIds)\n",
        "sessIdsFilter = sessIds[:n_filter]\n",
        "# Lựa chọn các 1/4 session làm dataset train (dữ liệu này bao gồm cả train và validation)\n",
        "# Set index là sessionId để filter nhanh hơn\n",
        "dataset.set_index('SessionId', inplace=True)\n",
        "dataset_filter = dataset[dataset.index.isin(sessIdsFilter)]\n",
        "dataset_filter = dataset_filter.reset_index()\n",
        "dataset_filter.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j516QCnt-w9R",
        "outputId": "197ae06c-e961-496a-83d6-8f70da4855f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(886969, 6)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_filter.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNfIqf27x7BI"
      },
      "outputs": [],
      "source": [
        "# convert item id to 0 -> n\n",
        "num_items = dataset_filter['ItemId'].unique().shape[0]\n",
        "\n",
        "sorted_list = np.sort(dataset_filter['ItemId'].unique())\n",
        "sorted_list\n",
        "\n",
        "dataset_filter['ItemId'] = dataset_filter['ItemId'].apply(lambda x: np.where(sorted_list == x)[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uV1pim5K0CvR",
        "outputId": "829302ff-497e-4cc1-8345-b576c1c58d9e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2c22370f-169c-4761-a7d5-f95fad2e77c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SessionId</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>ItemId</th>\n",
              "      <th>Price</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>2014-04-02 10:42:17.227</td>\n",
              "      <td>214717867</td>\n",
              "      <td>1778</td>\n",
              "      <td>4</td>\n",
              "      <td>1396435337.227000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>2014-04-07 09:24:18.307</td>\n",
              "      <td>214548744</td>\n",
              "      <td>3141</td>\n",
              "      <td>1</td>\n",
              "      <td>1396862658.307000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>2014-04-07 09:24:18.360</td>\n",
              "      <td>214838503</td>\n",
              "      <td>18745</td>\n",
              "      <td>1</td>\n",
              "      <td>1396862658.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>2014-04-06 18:24:51.206</td>\n",
              "      <td>214834865</td>\n",
              "      <td>523</td>\n",
              "      <td>2</td>\n",
              "      <td>1396808691.206000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>2014-04-06 18:24:51.207</td>\n",
              "      <td>214706441</td>\n",
              "      <td>1360</td>\n",
              "      <td>1</td>\n",
              "      <td>1396808691.207000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c22370f-169c-4761-a7d5-f95fad2e77c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c22370f-169c-4761-a7d5-f95fad2e77c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c22370f-169c-4761-a7d5-f95fad2e77c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-981d876b-c707-4168-add9-e31c39c9477c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-981d876b-c707-4168-add9-e31c39c9477c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-981d876b-c707-4168-add9-e31c39c9477c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   SessionId                DateTime     ItemId  Price  Quantity  \\\n",
              "0         12 2014-04-02 10:42:17.227  214717867   1778         4   \n",
              "1         21 2014-04-07 09:24:18.307  214548744   3141         1   \n",
              "2         21 2014-04-07 09:24:18.360  214838503  18745         1   \n",
              "3         33 2014-04-06 18:24:51.206  214834865    523         2   \n",
              "4         33 2014-04-06 18:24:51.207  214706441   1360         1   \n",
              "\n",
              "           Timestamp  \n",
              "0  1396435337.227000  \n",
              "1  1396862658.307000  \n",
              "2  1396862658.360000  \n",
              "3  1396808691.206000  \n",
              "4  1396808691.207000  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_filter.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlFmPhnaxBtX"
      },
      "outputs": [],
      "source": [
        "# Lấy ra dictionary có dạng {SessionId:{ItemId1:Timestamp1, ItemId2:Timestamp2, ...}}\n",
        "train_sess = dataset_filter[['SessionId', 'ItemId', 'Timestamp']].groupby('SessionId').apply(lambda x: dict(zip(x['ItemId'], x['Timestamp'])))\n",
        "test_sess = test[['SessionId', 'ItemId', 'Timestamp']].groupby('SessionId').apply(lambda x: dict(zip(x['ItemId'], x['Timestamp'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNqTb9z3xLz3",
        "outputId": "08807e0c-98c4-48f3-fc38-d34072ada1f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SessionId\n",
              "11                      {214821371: '1396523058.097000'}\n",
              "87     {214652220: '1396853842.557000', 214840483: '1...\n",
              "138                     {214594592: '1396605582.860000'}\n",
              "197                     {214774685: '1396721945.047000'}\n",
              "216                     {214821277: '1396461361.797000'}\n",
              "dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sess.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIeFQX9nyuQR",
        "outputId": "16d82ab2-68b4-4ee5-ab97-35f8646c0d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input sequences:  [[214834865], [214834865, 214820225]]\n",
            "input times:  ['1396808691.422000', '1396808691.426000']\n",
            "targets:  [214820225, 214706441]\n",
            "sequence:  [214834865, 214820225, 214706441]\n"
          ]
        }
      ],
      "source": [
        "sessDict = {214834865: '1396808691.295000', 214706441: '1396808691.426000', 214820225: '1396808691.422000'}\n",
        "\n",
        "def _preprocess_sess_dict(sessDict):\n",
        "    sessDictTime = dict([(v, k) for (k, v) in sessDict.items()])\n",
        "    sessSort = sorted(sessDictTime.items(), reverse = False)\n",
        "    times = [item[0] for item in sessSort]\n",
        "    itemIds = [item[1] for item in sessSort]\n",
        "    inp_seq = []\n",
        "    labels = []\n",
        "    inp_time = []\n",
        "\n",
        "    for i in range(len(sessSort)):\n",
        "        if i >= 1:\n",
        "            inp_seq += [itemIds[:i]]\n",
        "            labels += [itemIds[i]]\n",
        "            inp_time += [times[i]]\n",
        "    return inp_seq, inp_time, labels, itemIds\n",
        "\n",
        "inp_seq, inp_time, labels, itemIds = _preprocess_sess_dict(sessDict)\n",
        "print('input sequences: ', inp_seq)\n",
        "print('input times: ', inp_time)\n",
        "print('targets: ', labels)\n",
        "print('sequence: ', itemIds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCUo8_qrd8-_",
        "outputId": "c2fbfe68-f5e5-41e1-90dc-c1bff3db169c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n"
          ]
        }
      ],
      "source": [
        "def _preprocess_data(data_sess):\n",
        "    inp_seqs = []\n",
        "    inp_times = []\n",
        "    labels = []\n",
        "    sequences = []\n",
        "    sessIds = list(data_sess.index)\n",
        "    # print(len(sessIds))\n",
        "    for sessId in sessIds:\n",
        "        sessDict = data_sess.loc[sessId]\n",
        "        inp_seq, inp_time, label, sequence = _preprocess_sess_dict(sessDict)\n",
        "        inp_seqs += inp_seq\n",
        "        inp_times += inp_time\n",
        "        labels += label\n",
        "        sequences += sequence\n",
        "    # print(len(inp_seqs))\n",
        "    return inp_seqs, inp_times, labels, sequences\n",
        "\n",
        "train_inp_seqs, train_inp_dates, train_labs, train_sequences = _preprocess_data(train_sess)\n",
        "test_inp_seqs, test_inp_dates, test_labs, test_sequences = _preprocess_data(test_sess)\n",
        "\n",
        "train = (train_inp_seqs, train_labs)\n",
        "test = (test_inp_seqs, test_labs)\n",
        "\n",
        "print('Done.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_96GwD5eqFR"
      },
      "outputs": [],
      "source": [
        "# save data by pickle\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "def _save_file(filename, obj):\n",
        "  with open(filename, 'wb') as fn:\n",
        "    pickle.dump(obj, fn)\n",
        "\n",
        "# Tạo folder yoochoose-data-4 để lưu dữ liệu train/test nếu chưa tồn tại\n",
        "# if not os.path.exists('yoochoose-data/yoochoose-data-4'):\n",
        "#   os.mkdir('yoochoose-data/yoochoose-data-4')\n",
        "\n",
        "# Lưu train/test\n",
        "# _save_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/full_data/train.pkl', train)\n",
        "# _save_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/full_data/test.pkl', test)\n",
        "\n",
        "_save_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/full_data_increase_test_sample/train.pkl', train)\n",
        "_save_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/full_data_increase_test_sample/test.pkl', test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdlNRai5gilD"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# load pkl file\n",
        "\n",
        "def _load_file(filename):\n",
        "  with open(filename, 'rb') as fn:\n",
        "    data = pickle.load(fn)\n",
        "  return data\n",
        "\n",
        "# Load dữ liệu train/test từ folder\n",
        "# train = _load_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/full_data/train.pkl')\n",
        "# test = _load_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/full_data/test.pkl')\n",
        "\n",
        "train = _load_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/full_data_increase_test_sample/train.pkl')\n",
        "test = _load_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/full_data_increase_test_sample/test.pkl')\n",
        "\n",
        "# train = _load_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/train.pkl')\n",
        "# test = _load_file('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFeo4ifaqtyA",
        "outputId": "7a796b67-d018-4c2a-8a0a-05a0e159c863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51\n",
            "1\n",
            "457712\n"
          ]
        }
      ],
      "source": [
        "# max input sequence length\n",
        "x1 = train[0]\n",
        "l = [len(x) for x in x1]\n",
        "print(max(l))\n",
        "print(min(l))\n",
        "print(len(x1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzunyLPr5vFc",
        "outputId": "37733dd1-89df-4eb1-9c79-55c68f2d1118"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "59509"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5NCBvQ2vsf-"
      },
      "outputs": [],
      "source": [
        "# Các token default\n",
        "PAD_token = 0  # token padding cho câu ngắn ==> index = 0\n",
        "\n",
        "# tạo Vocabulary for index input\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.item2index = {}\n",
        "        self.item2count = {}\n",
        "        self.index2item = {PAD_token: \"PAD\"}\n",
        "        self.num_items = 1  # số lượng mặc định ban đầu là 1 ứng với PAD_token\n",
        "\n",
        "    def addSenquence(self, data):\n",
        "        for sequence in data:\n",
        "          for item in sequence:\n",
        "              self.addItem(item)\n",
        "\n",
        "    # Thêm một item vào hệ thống\n",
        "    def addItem(self, item):\n",
        "        if item not in self.item2index:\n",
        "            self.item2index[item] = self.num_items\n",
        "            self.item2count[item] = 1\n",
        "            self.index2item[self.num_items] = item\n",
        "            self.num_items += 1\n",
        "        else:\n",
        "            self.item2count[item] += 1\n",
        "\n",
        "    # Loại các item dưới ngưỡng xuất hiện min_count\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_items = []\n",
        "\n",
        "        for k, v in self.item2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_items.append(k)\n",
        "\n",
        "        print('keep_items {} / {} = {:.4f}'.format(\n",
        "            len(keep_items), len(self.item2index), len(keep_items) / len(self.item2index)\n",
        "        ))\n",
        "\n",
        "        # Khởi tạo lại từ điển\n",
        "        self.item2index = {}\n",
        "        self.item2count = {}\n",
        "        self.index2item = {PAD_token: \"PAD\"}\n",
        "        self.num_items = 1\n",
        "\n",
        "        # Thêm các items vào từ điển\n",
        "        for item in keep_items:\n",
        "            self.addItem(item)\n",
        "\n",
        "    # Hàm convert sequence về chuỗi các indices\n",
        "    def _seqItem2seqIndex(self, x):\n",
        "        return [self.item2index[item] if item in self.item2index else 0 for item in x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WROrklHjlilF",
        "outputId": "ba03ca21-b5bd-406b-b494-e421328f4989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of itemIds :  9948\n",
            "457712\n"
          ]
        }
      ],
      "source": [
        "from itertools import chain\n",
        "seq_targets = [train[1]] + [test[1]]\n",
        "itemIds  = list(chain.from_iterable(seq_targets))\n",
        "itemIds  = set(itemIds)\n",
        "print('Number of itemIds : ', len(itemIds))\n",
        "print(len(seq_targets[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnr_4cTVnhnT",
        "outputId": "614cfeef-63c3-4f69-fb40-aaedb0684c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequence of itemIds:  [214652220]\n",
            "converted indices:  [1865]\n"
          ]
        }
      ],
      "source": [
        "# tạo dict vocabuary data\n",
        "voc = Voc('DictItemId')\n",
        "voc.addSenquence(seq_targets)\n",
        "\n",
        "# Convert thử nghiệm một sequence itemIds\n",
        "print('sequence of itemIds: ', train[0][3])\n",
        "print('converted indices: ', voc._seqItem2seqIndex(train[0][3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mio_m5WD3oAy",
        "outputId": "be8b917c-0f95-4608-d2e0-9c631b18dc53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4]\n",
            "[6]\n"
          ]
        }
      ],
      "source": [
        "print(voc._seqItem2seqIndex([214840483]))\n",
        "print(voc._seqItem2seqIndex([214826837]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mctR1y46uja",
        "outputId": "c84cea61-ff5f-4757-df21-2f07b78e9998"
      },
      "outputs": [],
      "source": [
        "print(voc.index2item.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLc8k56c3Mp_"
      },
      "source": [
        "## Sequence data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYpqm7znocOB"
      },
      "outputs": [],
      "source": [
        "train_x_index = [voc._seqItem2seqIndex(seq) for seq in train[0]]\n",
        "test_x_index = [voc._seqItem2seqIndex(seq) for seq in test[0]]\n",
        "train_y_index = voc._seqItem2seqIndex(train[1])\n",
        "test_y_index = voc._seqItem2seqIndex(test[1])\n",
        "train_index = (train_x_index, train_y_index)\n",
        "test_index = (test_x_index, test_y_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xawoMXHV3Pbp"
      },
      "source": [
        "## Feature data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyAnEuZnQOv6",
        "outputId": "e69f4fd5-ffa2-4e6a-9afa-a1d9c441e411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(170653, 9)\n",
            "   valence  acousticness  danceability  energy                      id  \\\n",
            "0   0.0594         0.982         0.279   0.211  4BJqT0PrAfrxzMOxytFOIz   \n",
            "1   0.9630         0.732         0.819   0.341  7xPhfUan2yNtyFG0cUWkt8   \n",
            "2   0.0394         0.961         0.328   0.166  1o6I8BglA6ylDMrIELygv1   \n",
            "3   0.1650         0.967         0.275   0.309  3ftBPsC5vPBKxYSee08FDH   \n",
            "4   0.2530         0.957         0.418   0.193  4d6HGyGT8e121BsdKmw9v6   \n",
            "\n",
            "   liveness  loudness  speechiness    tempo  \n",
            "0     0.665   -20.096       0.0366   80.954  \n",
            "1     0.160   -12.441       0.4150   60.936  \n",
            "2     0.101   -14.850       0.0339  110.339  \n",
            "3     0.381    -9.316       0.0354  100.109  \n",
            "4     0.229   -10.096       0.0380  101.665  \n"
          ]
        }
      ],
      "source": [
        "# data about feature of items\n",
        "'''\n",
        "feature_data={\n",
        "    1: [44, 55, 66],\n",
        "    2: [34, 445, 665],\n",
        "    3: [1278, 93, 30],\n",
        "    4: [22222, 933, 930],\n",
        "    5: [777, 983, 8830],\n",
        "}\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "feature_data_raw = pd.read_csv('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/data_spotify_track.csv', usecols=['id', 'danceability', 'energy', 'valence', 'acousticness',\n",
        "                                                                                                                                      'tempo', 'loudness', 'liveness', 'speechiness'])\n",
        "\n",
        "print(feature_data_raw.shape)\n",
        "\n",
        "print(feature_data_raw.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W_pL2p6-8vM",
        "outputId": "b6e525b1-0243-49c1-9dfa-740e62cc9773"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(17065, 9)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_data_filter = feature_data_raw.sample(frac=0.1)\n",
        "feature_data_filter.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HeAy-WP5_K9i",
        "outputId": "c9d98a1e-2068-40dc-fa7b-f9e8162d432f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5a45acd8-14a9-439b-8618-0f1d592e5974\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valence</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>id</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>104239</th>\n",
              "      <td>0.513</td>\n",
              "      <td>0.0354</td>\n",
              "      <td>0.466</td>\n",
              "      <td>0.838</td>\n",
              "      <td>1CP8UCFq3Buyg4MN8mZUka</td>\n",
              "      <td>0.3400</td>\n",
              "      <td>-6.258</td>\n",
              "      <td>0.2480</td>\n",
              "      <td>99.816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27380</th>\n",
              "      <td>0.666</td>\n",
              "      <td>0.7980</td>\n",
              "      <td>0.418</td>\n",
              "      <td>0.445</td>\n",
              "      <td>4aWWhnZ3izYAfmmCSOkqlM</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>-8.690</td>\n",
              "      <td>0.0301</td>\n",
              "      <td>95.974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118536</th>\n",
              "      <td>0.788</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.642</td>\n",
              "      <td>0.979</td>\n",
              "      <td>58nnHo2vaWBX7LKU0kMxFv</td>\n",
              "      <td>0.0259</td>\n",
              "      <td>-4.102</td>\n",
              "      <td>0.0462</td>\n",
              "      <td>110.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99504</th>\n",
              "      <td>0.752</td>\n",
              "      <td>0.0508</td>\n",
              "      <td>0.556</td>\n",
              "      <td>0.758</td>\n",
              "      <td>1v0PatOEeF1g1fVRNlmw9k</td>\n",
              "      <td>0.2840</td>\n",
              "      <td>-14.826</td>\n",
              "      <td>0.0366</td>\n",
              "      <td>127.897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34900</th>\n",
              "      <td>0.570</td>\n",
              "      <td>0.0266</td>\n",
              "      <td>0.622</td>\n",
              "      <td>0.669</td>\n",
              "      <td>0jG92AlXau21qgCQRxGLic</td>\n",
              "      <td>0.1520</td>\n",
              "      <td>-8.419</td>\n",
              "      <td>0.3290</td>\n",
              "      <td>93.839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a45acd8-14a9-439b-8618-0f1d592e5974')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a45acd8-14a9-439b-8618-0f1d592e5974 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a45acd8-14a9-439b-8618-0f1d592e5974');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e90125cf-19ef-405b-bdad-73e70cea25f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e90125cf-19ef-405b-bdad-73e70cea25f9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e90125cf-19ef-405b-bdad-73e70cea25f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        valence  acousticness  danceability  energy                      id  \\\n",
              "104239    0.513        0.0354         0.466   0.838  1CP8UCFq3Buyg4MN8mZUka   \n",
              "27380     0.666        0.7980         0.418   0.445  4aWWhnZ3izYAfmmCSOkqlM   \n",
              "118536    0.788        0.0660         0.642   0.979  58nnHo2vaWBX7LKU0kMxFv   \n",
              "99504     0.752        0.0508         0.556   0.758  1v0PatOEeF1g1fVRNlmw9k   \n",
              "34900     0.570        0.0266         0.622   0.669  0jG92AlXau21qgCQRxGLic   \n",
              "\n",
              "        liveness  loudness  speechiness    tempo  \n",
              "104239    0.3400    -6.258       0.2480   99.816  \n",
              "27380     0.1070    -8.690       0.0301   95.974  \n",
              "118536    0.0259    -4.102       0.0462  110.026  \n",
              "99504     0.2840   -14.826       0.0366  127.897  \n",
              "34900     0.1520    -8.419       0.3290   93.839  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_data_filter.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi1WOqNc_PfM",
        "outputId": "34ad6aae-dab1-4bbf-c239-b0d001830a76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "valence          1355\n",
              "acousticness     2890\n",
              "danceability      927\n",
              "energy           1606\n",
              "id              17065\n",
              "liveness         1517\n",
              "loudness        11199\n",
              "speechiness      1344\n",
              "tempo           15464\n",
              "dtype: int64"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_data_filter.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9nReLNxAKfc"
      },
      "outputs": [],
      "source": [
        "# convert item id to 0 -> n\n",
        "feature_data_filter['id'] = range(1, 17066)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YVpBn5v4CFFQ",
        "outputId": "8320b404-6344-41f3-dd8f-b901396e296c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f9a835e9-fb0e-4976-ab2f-29a95e767a66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valence</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>id</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>156550</th>\n",
              "      <td>0.480</td>\n",
              "      <td>0.8730</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.793</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4750</td>\n",
              "      <td>-10.372</td>\n",
              "      <td>0.0476</td>\n",
              "      <td>127.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35110</th>\n",
              "      <td>0.412</td>\n",
              "      <td>0.4710</td>\n",
              "      <td>0.558</td>\n",
              "      <td>0.687</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>-8.634</td>\n",
              "      <td>0.0381</td>\n",
              "      <td>94.989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28426</th>\n",
              "      <td>0.429</td>\n",
              "      <td>0.0898</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.546</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0898</td>\n",
              "      <td>-10.026</td>\n",
              "      <td>0.0548</td>\n",
              "      <td>181.373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6753</th>\n",
              "      <td>0.411</td>\n",
              "      <td>0.8540</td>\n",
              "      <td>0.374</td>\n",
              "      <td>0.208</td>\n",
              "      <td>4</td>\n",
              "      <td>0.4560</td>\n",
              "      <td>-14.159</td>\n",
              "      <td>0.0367</td>\n",
              "      <td>151.867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40460</th>\n",
              "      <td>0.565</td>\n",
              "      <td>0.9770</td>\n",
              "      <td>0.453</td>\n",
              "      <td>0.622</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5050</td>\n",
              "      <td>-7.977</td>\n",
              "      <td>0.0567</td>\n",
              "      <td>126.793</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9a835e9-fb0e-4976-ab2f-29a95e767a66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9a835e9-fb0e-4976-ab2f-29a95e767a66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9a835e9-fb0e-4976-ab2f-29a95e767a66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6e81cd12-4ecd-42a2-8cba-91b69f3958c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e81cd12-4ecd-42a2-8cba-91b69f3958c5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6e81cd12-4ecd-42a2-8cba-91b69f3958c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        valence  acousticness  danceability  energy  id  liveness  loudness  \\\n",
              "156550    0.480        0.8730         0.720   0.793   1    0.4750   -10.372   \n",
              "35110     0.412        0.4710         0.558   0.687   2    0.0958    -8.634   \n",
              "28426     0.429        0.0898         0.240   0.546   3    0.0898   -10.026   \n",
              "6753      0.411        0.8540         0.374   0.208   4    0.4560   -14.159   \n",
              "40460     0.565        0.9770         0.453   0.622   5    0.5050    -7.977   \n",
              "\n",
              "        speechiness    tempo  \n",
              "156550       0.0476  127.200  \n",
              "35110        0.0381   94.989  \n",
              "28426        0.0548  181.373  \n",
              "6753         0.0367  151.867  \n",
              "40460        0.0567  126.793  "
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_data_filter.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz9EzGgACL44"
      },
      "outputs": [],
      "source": [
        "# save data raw by pickle\n",
        "feature_data_filter.to_pickle('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/data_spotify_track_feature_raw.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l4NMegnvCQjj",
        "outputId": "af3b3517-9f50-41df-b5ef-b2f548e5882b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5e7d3128-97dd-4c2a-bbc0-0664f294dd5f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valence</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>id</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>156550</th>\n",
              "      <td>0.480</td>\n",
              "      <td>0.8730</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.793</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4750</td>\n",
              "      <td>-10.372</td>\n",
              "      <td>0.0476</td>\n",
              "      <td>127.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35110</th>\n",
              "      <td>0.412</td>\n",
              "      <td>0.4710</td>\n",
              "      <td>0.558</td>\n",
              "      <td>0.687</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>-8.634</td>\n",
              "      <td>0.0381</td>\n",
              "      <td>94.989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28426</th>\n",
              "      <td>0.429</td>\n",
              "      <td>0.0898</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.546</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0898</td>\n",
              "      <td>-10.026</td>\n",
              "      <td>0.0548</td>\n",
              "      <td>181.373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6753</th>\n",
              "      <td>0.411</td>\n",
              "      <td>0.8540</td>\n",
              "      <td>0.374</td>\n",
              "      <td>0.208</td>\n",
              "      <td>4</td>\n",
              "      <td>0.4560</td>\n",
              "      <td>-14.159</td>\n",
              "      <td>0.0367</td>\n",
              "      <td>151.867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40460</th>\n",
              "      <td>0.565</td>\n",
              "      <td>0.9770</td>\n",
              "      <td>0.453</td>\n",
              "      <td>0.622</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5050</td>\n",
              "      <td>-7.977</td>\n",
              "      <td>0.0567</td>\n",
              "      <td>126.793</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e7d3128-97dd-4c2a-bbc0-0664f294dd5f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e7d3128-97dd-4c2a-bbc0-0664f294dd5f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e7d3128-97dd-4c2a-bbc0-0664f294dd5f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c2b93b1-bda9-4edb-808d-519021c2a251\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c2b93b1-bda9-4edb-808d-519021c2a251')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c2b93b1-bda9-4edb-808d-519021c2a251 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        valence  acousticness  danceability  energy  id  liveness  loudness  \\\n",
              "156550    0.480        0.8730         0.720   0.793   1    0.4750   -10.372   \n",
              "35110     0.412        0.4710         0.558   0.687   2    0.0958    -8.634   \n",
              "28426     0.429        0.0898         0.240   0.546   3    0.0898   -10.026   \n",
              "6753      0.411        0.8540         0.374   0.208   4    0.4560   -14.159   \n",
              "40460     0.565        0.9770         0.453   0.622   5    0.5050    -7.977   \n",
              "\n",
              "        speechiness    tempo  \n",
              "156550       0.0476  127.200  \n",
              "35110        0.0381   94.989  \n",
              "28426        0.0548  181.373  \n",
              "6753         0.0367  151.867  \n",
              "40460        0.0567  126.793  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data raw from pkl file\n",
        "feature_data_filter = pd.read_pickle('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/data_spotify_track_feature_raw.pkl')\n",
        "feature_data_filter.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p7gWHT5CHqOV",
        "outputId": "3fdbe857-ff7e-4bf2-bdf8-32768e154698"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-020811bb-4cbf-42ee-b0c7-047e74c27de6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valence</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>id</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>156550</th>\n",
              "      <td>-0.1877</td>\n",
              "      <td>0.9820</td>\n",
              "      <td>1.0387</td>\n",
              "      <td>1.1645</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5556</td>\n",
              "      <td>0.1899</td>\n",
              "      <td>-0.3149</td>\n",
              "      <td>0.3312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35110</th>\n",
              "      <td>-0.4466</td>\n",
              "      <td>-0.0832</td>\n",
              "      <td>0.1167</td>\n",
              "      <td>0.7675</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.6288</td>\n",
              "      <td>0.4973</td>\n",
              "      <td>-0.3740</td>\n",
              "      <td>-0.7169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28426</th>\n",
              "      <td>-0.3819</td>\n",
              "      <td>-1.0933</td>\n",
              "      <td>-1.6932</td>\n",
              "      <td>0.2394</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.6634</td>\n",
              "      <td>0.2511</td>\n",
              "      <td>-0.2702</td>\n",
              "      <td>2.0938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6753</th>\n",
              "      <td>-0.4504</td>\n",
              "      <td>0.9316</td>\n",
              "      <td>-0.9305</td>\n",
              "      <td>-1.0266</td>\n",
              "      <td>4</td>\n",
              "      <td>1.4461</td>\n",
              "      <td>-0.4799</td>\n",
              "      <td>-0.3827</td>\n",
              "      <td>1.1338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40460</th>\n",
              "      <td>0.1359</td>\n",
              "      <td>1.2575</td>\n",
              "      <td>-0.4809</td>\n",
              "      <td>0.5240</td>\n",
              "      <td>5</td>\n",
              "      <td>1.7284</td>\n",
              "      <td>0.6135</td>\n",
              "      <td>-0.2583</td>\n",
              "      <td>0.3179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-020811bb-4cbf-42ee-b0c7-047e74c27de6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-020811bb-4cbf-42ee-b0c7-047e74c27de6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-020811bb-4cbf-42ee-b0c7-047e74c27de6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a4eae4a-72bc-4ee1-a62f-beff04afb1f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a4eae4a-72bc-4ee1-a62f-beff04afb1f6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a4eae4a-72bc-4ee1-a62f-beff04afb1f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        valence  acousticness  danceability  energy  id  liveness  loudness  \\\n",
              "156550  -0.1877        0.9820        1.0387  1.1645   1    1.5556    0.1899   \n",
              "35110   -0.4466       -0.0832        0.1167  0.7675   2   -0.6288    0.4973   \n",
              "28426   -0.3819       -1.0933       -1.6932  0.2394   3   -0.6634    0.2511   \n",
              "6753    -0.4504        0.9316       -0.9305 -1.0266   4    1.4461   -0.4799   \n",
              "40460    0.1359        1.2575       -0.4809  0.5240   5    1.7284    0.6135   \n",
              "\n",
              "        speechiness   tempo  \n",
              "156550      -0.3149  0.3312  \n",
              "35110       -0.3740 -0.7169  \n",
              "28426       -0.2702  2.0938  \n",
              "6753        -0.3827  1.1338  \n",
              "40460       -0.2583  0.3179  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Scaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "feature_data_filter[['danceability', 'energy', 'valence', 'acousticness', 'tempo', 'loudness', 'liveness', 'speechiness']] = std_scaler.fit_transform(feature_data_filter[['danceability', 'energy', 'valence', 'acousticness', 'tempo', 'loudness', 'liveness', 'speechiness']])\n",
        "\n",
        "feature_data_filter=feature_data_filter.round(4)\n",
        "feature_data_filter.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l6izCNOLZGt"
      },
      "outputs": [],
      "source": [
        "# Save data processed\n",
        "feature_data_filter.to_pickle('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/data_spotify_track_feature_processed.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "V5CB7eS0LzqE",
        "outputId": "dcfdfcbe-2d3a-47cf-f43b-a7c172c9ab65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cea06310-8bdb-431f-9f95-7b8bff45e325\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valence</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>id</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>156550</th>\n",
              "      <td>-0.1877</td>\n",
              "      <td>0.9820</td>\n",
              "      <td>1.0387</td>\n",
              "      <td>1.1645</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5556</td>\n",
              "      <td>0.1899</td>\n",
              "      <td>-0.3149</td>\n",
              "      <td>0.3312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35110</th>\n",
              "      <td>-0.4466</td>\n",
              "      <td>-0.0832</td>\n",
              "      <td>0.1167</td>\n",
              "      <td>0.7675</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.6288</td>\n",
              "      <td>0.4973</td>\n",
              "      <td>-0.3740</td>\n",
              "      <td>-0.7169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28426</th>\n",
              "      <td>-0.3819</td>\n",
              "      <td>-1.0933</td>\n",
              "      <td>-1.6932</td>\n",
              "      <td>0.2394</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.6634</td>\n",
              "      <td>0.2511</td>\n",
              "      <td>-0.2702</td>\n",
              "      <td>2.0938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6753</th>\n",
              "      <td>-0.4504</td>\n",
              "      <td>0.9316</td>\n",
              "      <td>-0.9305</td>\n",
              "      <td>-1.0266</td>\n",
              "      <td>4</td>\n",
              "      <td>1.4461</td>\n",
              "      <td>-0.4799</td>\n",
              "      <td>-0.3827</td>\n",
              "      <td>1.1338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40460</th>\n",
              "      <td>0.1359</td>\n",
              "      <td>1.2575</td>\n",
              "      <td>-0.4809</td>\n",
              "      <td>0.5240</td>\n",
              "      <td>5</td>\n",
              "      <td>1.7284</td>\n",
              "      <td>0.6135</td>\n",
              "      <td>-0.2583</td>\n",
              "      <td>0.3179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cea06310-8bdb-431f-9f95-7b8bff45e325')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cea06310-8bdb-431f-9f95-7b8bff45e325 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cea06310-8bdb-431f-9f95-7b8bff45e325');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dc548f23-4c60-457a-9e12-a702d797c2ae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc548f23-4c60-457a-9e12-a702d797c2ae')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dc548f23-4c60-457a-9e12-a702d797c2ae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        valence  acousticness  danceability  energy  id  liveness  loudness  \\\n",
              "156550  -0.1877        0.9820        1.0387  1.1645   1    1.5556    0.1899   \n",
              "35110   -0.4466       -0.0832        0.1167  0.7675   2   -0.6288    0.4973   \n",
              "28426   -0.3819       -1.0933       -1.6932  0.2394   3   -0.6634    0.2511   \n",
              "6753    -0.4504        0.9316       -0.9305 -1.0266   4    1.4461   -0.4799   \n",
              "40460    0.1359        1.2575       -0.4809  0.5240   5    1.7284    0.6135   \n",
              "\n",
              "        speechiness   tempo  \n",
              "156550      -0.3149  0.3312  \n",
              "35110       -0.3740 -0.7169  \n",
              "28426       -0.2702  2.0938  \n",
              "6753        -0.3827  1.1338  \n",
              "40460       -0.2583  0.3179  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data processed from pkl file\n",
        "feature_data_filter = pd.read_pickle('/content/drive/MyDrive/Đồ án model recommendation/data_youchoose/data_spotify_track_feature_processed.pkl')\n",
        "feature_data_filter.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tWsnkZDE021",
        "outputId": "cd199ad8-ace2-4db1-c16e-f26f0d667032"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: [-0.1877, 0.982, 1.0387, 1.1645, 1.5556, 0.1899, -0.3149, 0.3312],\n",
              " 2: [-0.4466, -0.0832, 0.1167, 0.7675, -0.6288, 0.4973, -0.374, -0.7169],\n",
              " 3: [-0.3819, -1.0933, -1.6932, 0.2394, -0.6634, 0.2511, -0.2702, 2.0938],\n",
              " 4: [-0.4504, 0.9316, -0.9305, -1.0266, 1.4461, -0.4799, -0.3827, 1.1338],\n",
              " 5: [0.1359, 1.2575, -0.4809, 0.524, 1.7284, 0.6135, -0.2583, 0.3179],\n",
              " 6: [0.8022, 1.3052, 0.0484, -1.0041, 0.5417, -0.4445, 0.5769, 1.8741],\n",
              " 7: [-1.8043, 1.0376, -2.5685, -1.1877, -0.774, -1.2786, -0.3821, 1.6316],\n",
              " 8: [-0.1001, 0.7488, 0.1963, 0.1307, -0.1668, 0.0404, -0.425, -1.3084],\n",
              " 9: [0.6423, -1.1001, -0.4183, 0.8087, 0.1673, 0.6067, -0.351, -0.3659],\n",
              " 10: [-1.0367, 1.3052, -1.1297, -1.5659, 0.6281, -2.6494, -0.3411, -0.2733],\n",
              " 11: [0.49, 1.284, -0.3045, 0.2056, -0.0286, 0.16, -0.4088, 0.2518],\n",
              " 12: [1.6588, -1.3299, 1.3858, 0.7338, -0.827, 0.3936, -0.2129, -1.3335],\n",
              " 13: [0.1968, -1.3306, 1.346, 0.1644, -0.907, -1.0391, -0.0214, 1.0112],\n",
              " 14: [-1.1624, 0.513, 0.7655, -0.8393, -0.5873, -0.3175, -0.4325, 0.0254],\n",
              " 15: [-0.4885, 0.7276, 0.0142, -0.4985, -0.5009, -1.0508, -0.3952, -0.2962],\n",
              " 16: [0.5585, 1.2099, 0.1281, -1.0229, -0.4952, -0.687, -0.2136, -1.1292],\n",
              " 17: [1.6931, -0.7112, 1.3574, 0.4603, -0.4318, 0.1692, -0.4082, -0.033],\n",
              " 18: [1.3695, 1.2734, 1.0614, -0.4348, -0.3166, -1.0117, 1.8642, -1.6646],\n",
              " 19: [-0.1534, 1.3052, 0.5378, -1.2925, -0.6202, -1.7702, 0.2846, -0.08],\n",
              " 20: [-1.505, -0.8887, -0.4752, -0.9479, -0.017, -0.2027, -0.4263, -1.4144],\n",
              " 21: [-0.2296, -1.2106, 0.7939, 0.2169, 3.6869, -0.5294, -0.221, -0.7128],\n",
              " 22: [0.9545, 0.3249, 1.6533, -0.0378, -0.7014, 0.3347, 2.4177, -0.4295],\n",
              " 23: [-1.2233, 1.1913, -1.494, -1.0079, -0.2763, 0.0334, -0.435, -0.9153],\n",
              " 24: [-0.9758, -0.8384, 0.5435, 0.936, -0.4318, 0.8243, -0.1713, 0.3106],\n",
              " 25: [0.1816, 0.5024, 0.3216, -1.1015, -0.6109, -0.9988, -0.4064, -0.7971],\n",
              " 26: [1.4266, -1.1685, 1.3232, 0.2656, -0.5873, -0.3867, -0.4443, -0.6077],\n",
              " 27: [0.3872, 1.2867, 0.9078, -0.7195, -0.3972, 0.3929, -0.2049, 0.2394],\n",
              " 28: [-1.3299, 1.292, -0.8907, -1.2513, -0.5124, -1.1289, -0.2583, -0.8284],\n",
              " 29: [0.7793, 0.1579, 0.1907, 0.9435, -0.547, 0.6672, -0.3467, 1.2484],\n",
              " 30: [0.3263, 0.6481, 1.0956, -0.1614, -0.6115, 0.2797, -0.2322, 0.4252],\n",
              " 31: [1.3162, -1.0053, -0.4866, 1.9023, -0.7907, 1.525, -0.2851, 1.1417],\n",
              " 32: [0.7832, -1.0477, 1.7614, 0.4528, -0.57, 1.2095, -0.3641, -0.0969],\n",
              " 33: [0.0293, 1.3052, -0.8679, -1.3113, 0.1039, -2.3752, -0.1725, -0.9304],\n",
              " 34: [1.4418, 0.5077, 0.5378, -0.8955, 2.4657, -0.8253, -0.3902, 0.1262],\n",
              " 35: [0.6727, -0.3323, -0.9476, -0.0902, 0.2883, 0.64, -0.4095, 2.691],\n",
              " 36: [1.1639, 1.1648, -0.5208, 0.1045, 1.1005, 0.1887, -0.0749, -0.2436],\n",
              " 37: [-0.0316, -0.3217, -1.0956, -0.5097, 1.5325, 0.1077, -0.4188, -0.2491],\n",
              " 38: [1.2324, 1.3052, 1.4541, -1.5622, -0.3339, -1.4791, 0.8754, -0.1988],\n",
              " 39: [1.3619, 0.8309, 0.5606, 1.3405, 1.2675, 0.4387, -0.3529, 0.8088],\n",
              " 40: [-1.671, 1.2443, -1.7785, -1.6543, -0.4088, -1.9147, -0.3877, -0.8982],\n",
              " 41: [1.0839, 1.186, 0.7541, -0.0865, -0.524, 1.1584, -0.346, -0.8261],\n",
              " 42: [1.6436, 1.3026, -1.5452, -0.5135, -0.259, -1.0352, -0.3753, 1.6541],\n",
              " 43: [-0.9377, -0.4409, -0.7996, -0.6371, 0.9334, 0.2387, -0.4213, -0.2225],\n",
              " 44: [1.1829, 1.3079, -0.5947, -0.3786, 0.3862, -0.4624, -0.3566, 0.8669],\n",
              " 45: [-0.4047, 1.284, 0.7143, -1.4416, -0.5528, -0.7349, -0.3578, 0.6142],\n",
              " 46: [1.004, -1.0344, 0.3102, 0.6738, -0.5067, 0.933, -0.4493, -0.2919],\n",
              " 47: [0.5166, -0.5707, 0.4695, 0.5352, 0.6281, 0.7088, 2.8282, 1.6558],\n",
              " 48: [1.3961, -1.2774, 0.9305, 0.7113, 1.8033, 0.8657, -0.412, -0.0017],\n",
              " 49: [-0.854, 0.8786, 0.589, -1.0491, -0.0689, -1.0626, 5.3594, 1.5326],\n",
              " 50: [0.4976, -1.3282, -0.3443, 0.8873, -0.4721, 0.8485, -0.1731, -1.2265],\n",
              " 51: [-0.7816, 1.2443, -1.2322, -1.0266, -0.1783, -1.3574, -0.2745, -0.3882],\n",
              " 52: [-0.1458, 1.2999, -0.9874, -1.315, -0.6294, -1.0274, 0.1975, -1.7179],\n",
              " 53: [-1.73, 1.3026, -1.1809, -1.7869, -0.5528, -4.1017, -0.3006, -1.0398],\n",
              " 54: [1.0611, 0.5209, 0.6403, 0.6514, -0.1092, 0.3024, -0.4331, 0.4119],\n",
              " 55: [-0.4085, -1.3307, -1.3118, 1.8911, -0.38, 1.1279, -0.1818, 2.0933],\n",
              " 56: [-1.1091, 1.2072, -0.3045, -1.6547, -0.3051, -1.5085, -0.2901, -0.0299],\n",
              " 57: [-0.1496, 1.2628, 0.259, -1.2438, -0.0458, -1.6791, 4.5509, 1.7313],\n",
              " 58: [1.2591, -0.9417, 0.2248, 1.539, -0.683, 1.12, -0.0699, 0.8265],\n",
              " 59: [-0.321, -0.6953, -0.8395, 0.0334, -0.5931, 0.4202, -0.4331, -0.1079],\n",
              " 60: [-0.4352, 0.7382, -0.1736, -0.5884, 0.7433, -0.3844, 0.7759, -1.2178],\n",
              " 61: [-1.6192, -1.3309, -0.7427, 1.6701, -0.0516, 0.9498, -0.1787, -0.1023],\n",
              " 62: [1.6284, -1.1977, 0.6573, 0.0858, -0.57, -1.1602, -0.1576, -0.2309],\n",
              " 63: [1.1753, -1.3269, -1.107, 1.4566, -0.6518, 0.119, -0.2758, 1.7257],\n",
              " 64: [0.7451, 0.195, 0.0199, 0.9398, 2.8805, 0.4255, -0.3056, -0.3348],\n",
              " 65: [0.5738, -0.7721, 0.5834, 0.4828, -0.638, 0.288, -0.4343, 1.0657],\n",
              " 66: [-0.4504, -1.2872, 0.2419, 0.6663, -0.1783, 0.7146, -0.3442, 0.2206],\n",
              " 67: [1.3276, 0.3673, -0.2305, -0.3824, 1.665, 0.4635, -0.4306, 1.9045],\n",
              " 68: [-0.5875, -0.4859, -0.646, 1.0634, 0.8355, 0.7472, -0.2092, 0.3302],\n",
              " 69: [0.9849, -1.3196, 1.3061, 0.4379, -0.7694, 1.1088, -0.3597, 0.6512],\n",
              " 70: [1.0649, 1.2575, 0.572, 0.524, -0.5355, 0.8011, 1.1553, -1.1111],\n",
              " 71: [-0.005, -0.1812, -0.3273, 0.3892, 4.4531, -0.2547, 0.1478, -1.1822],\n",
              " 72: [1.4951, -1.3097, 2.3135, 0.2918, -0.8275, 1.0593, -0.0705, 0.3569],\n",
              " 73: [1.5141, 1.2946, -0.1281, 0.5914, 0.1961, -0.1071, -0.3802, 0.8366],\n",
              " 74: [0.2349, 0.354, -0.2476, -0.4198, 0.847, -0.3806, -0.2328, 0.7065],\n",
              " 75: [-1.5888, 1.1251, -1.1696, -1.285, -0.4664, -0.8891, -0.3815, 0.2575],\n",
              " 76: [0.6385, 0.6746, -0.5151, 0.1345, -0.8592, 0.5974, -0.3336, 1.758],\n",
              " 77: [-1.189, -1.2642, 0.4183, 0.8948, -0.4548, 0.9396, -0.3597, -0.003],\n",
              " 78: [0.9088, -1.2917, 0.2248, 1.3143, -1.0228, 1.1035, -0.3019, 0.2668],\n",
              " 79: [-0.6065, -1.284, 0.4297, 0.569, -0.7665, 1.4102, -0.4001, 0.9088],\n",
              " 80: [-1.1281, 0.6932, -1.7444, -0.1127, -0.5412, -0.9622, -0.351, -0.5555],\n",
              " 81: [-0.9644, -1.2922, -1.1923, 1.8836, -0.3569, 1.1329, -0.0351, 0.8912],\n",
              " 82: [0.3187, 1.141, -1.2379, -0.5622, -0.3512, 0.0712, -0.4026, -0.7208],\n",
              " 83: [-0.0354, 0.3726, 0.0256, -0.1389, 1.7917, 0.414, -0.4225, -0.7737],\n",
              " 84: [-0.2753, -1.3188, -0.7769, 1.4566, 4.5164, 0.504, -0.3249, -0.098],\n",
              " 85: [-1.0177, 0.5845, -0.3785, -0.0303, -0.6254, 0.9003, -0.3734, 0.1182],\n",
              " 86: [0.8821, -1.1017, 0.0085, 1.4379, -0.6317, 0.5379, -0.3106, 0.4335],\n",
              " 87: [0.6804, -1.1979, 0.6346, -0.6333, -0.683, -0.9171, -0.4001, -0.0498],\n",
              " 88: [1.2096, -0.6396, 0.7484, 0.1907, -0.282, -0.4687, -0.4412, -0.8053],\n",
              " 89: [1.4075, -0.841, 1.0387, 0.8873, 1.8263, 1.2158, -0.0624, -0.9122],\n",
              " 90: [-0.7778, -1.3062, 1.2435, -0.0528, -0.3627, -0.0446, -0.328, -0.5862],\n",
              " 91: [-1.872, -1.2565, -1.2549, -0.5921, -0.2475, -0.0607, -0.4057, -1.068],\n",
              " 92: [0.49, -1.239, 1.4314, 0.569, 0.559, 1.1821, -0.4101, -0.001],\n",
              " 93: [1.042, -0.2687, 0.8053, -1.1427, -0.2244, -0.6058, 5.2474, 1.0093],\n",
              " 94: [0.2311, 0.248, -0.202, 0.1158, -0.933, 0.6768, -0.4325, 0.7617],\n",
              " 95: [-0.6826, -0.1415, -0.1736, -0.0078, -0.3339, 1.066, -0.4455, -1.0079],\n",
              " 96: [-0.9149, -1.3253, 1.7444, 0.142, 2.8517, 0.145, 2.7038, 1.0729],\n",
              " 97: [0.391, -1.3309, 0.3671, 0.6364, -0.3166, 0.2847, -0.4182, 0.7461],\n",
              " 98: [-1.8629, -1.3072, 1.6818, -1.0453, -0.4664, -0.1787, 0.7013, -0.5531],\n",
              " 99: [-0.4656, 0.1738, 0.185, -0.6183, 0.1442, -0.0223, -0.3274, 0.2937],\n",
              " 100: [1.3504, 0.0387, -0.3329, 0.3442, -0.2532, -0.1265, 0.8941, 1.2836],\n",
              " 101: [1.6398, 0.3169, 1.198, -0.1389, -0.426, -0.4696, -0.3777, -0.2006],\n",
              " 102: [1.3619, 0.8044, 1.6818, -0.2138, -0.2014, -0.3336, -0.3411, -0.0638],\n",
              " 103: [-0.8425, -0.894, -0.589, -0.3749, -0.6271, -0.2673, -0.4263, -1.5622],\n",
              " 104: [-1.3261, 1.0482, -1.2777, -0.9367, -0.6392, 0.0343, -0.4138, 0.5649],\n",
              " 105: [1.457, 0.2745, 0.6744, 1.1944, -0.4433, 0.9833, -0.2111, -0.8905],\n",
              " 106: [0.4938, -1.2265, 1.585, 1.3443, 0.5878, 1.0084, 1.6093, -0.8279],\n",
              " 107: [1.6398, -0.9099, 0.424, 1.6551, -0.5873, 1.3386, -0.4144, -0.0348],\n",
              " 108: [0.1511, -1.1272, 1.2208, 0.348, -0.4606, 1.095, -0.2695, -1.0093],\n",
              " 109: [1.6512, 0.1394, 1.033, 0.4079, -0.9589, -0.3058, -0.4095, 0.7586],\n",
              " 110: [-0.1953, -1.1113, 0.5264, 0.6027, 0.7721, 0.5286, -0.4486, 0.9409],\n",
              " 111: [-0.0773, -0.796, 1.3346, 0.142, -0.2705, 0.8015, 1.0682, 1.7902],\n",
              " 112: [-0.5913, -1.2591, -1.3517, 1.3817, -0.547, 0.9969, 1.4973, -0.0617],\n",
              " 113: [-0.7931, 1.2867, 0.2988, -1.0266, -0.1265, -0.1263, -0.3193, -0.2382],\n",
              " 114: [0.4557, 1.1569, 1.0102, -0.7195, -0.5412, 0.4271, -0.2216, 0.5806],\n",
              " 115: [0.6423, 1.3026, 0.6972, -1.2775, -0.3454, -0.1536, 2.1006, 0.6316],\n",
              " 116: [-1.8781, 0.6004, -1.7785, -1.2701, -0.5355, -1.1282, -0.356, 0.0728],\n",
              " 117: [0.174, -0.1574, 1.5736, -0.7007, -0.5297, 1.1248, -0.4008, 0.2604],\n",
              " 118: [-1.269, -0.3323, -0.1167, 1.2993, -0.6133, 0.8506, -0.3355, 0.0979],\n",
              " 119: [-1.1014, 1.2046, -0.7256, -1.6566, -0.3051, -1.2563, -0.3802, -0.8191],\n",
              " 120: [-1.7928, 1.2681, -1.6249, -1.2401, -0.3051, -1.2984, -0.2932, -1.1939],\n",
              " 121: [-0.8464, -1.313, 1.9037, -0.2588, -0.6974, -0.45, 0.496, -0.514],\n",
              " 122: [-0.2715, -0.6953, 0.2191, 0.8236, -0.524, 0.9688, -0.2789, 0.9468],\n",
              " 123: [0.0103, 0.2454, -0.0541, -0.7157, 2.2814, -0.6336, -0.4368, -1.007],\n",
              " 124: [-0.6065, 0.0016, 0.1907, 0.0334, -0.6161, 0.0167, -0.4362, -0.6831],\n",
              " 125: [1.4875, -1.3039, 1.3005, 0.0633, -0.5124, 0.4801, -0.3989, 0.4215],\n",
              " 126: [1.5141, 0.3699, 0.6915, 1.2918, 1.0141, 0.9323, -0.3634, 1.8221],\n",
              " 127: [1.7159, 0.8203, 1.9265, -0.5022, 0.559, 0.5058, 0.2224, 0.4397],\n",
              " 128: [0.4938, -0.1468, -0.646, 1.3293, -0.3051, 0.2661, 0.3468, -0.4029],\n",
              " 129: [-0.4809, 1.1224, 0.811, 0.0633, -0.5067, 0.7661, -0.3522, 0.223],\n",
              " 130: [1.3162, 0.9449, 1.272, -0.0865, -0.4433, 0.3567, -0.4113, 0.7688],\n",
              " 131: [-1.0291, 1.0111, -1.2663, -0.6333, -0.5989, 0.3726, -0.4263, -1.2581],\n",
              " 132: [0.8365, 1.2681, -1.8184, -0.3299, 1.7284, -1.423, -0.3697, -1.1302],\n",
              " 133: [0.2577, -1.33, -0.1622, 1.2544, -0.6351, 1.0565, -0.2988, 1.2422],\n",
              " 134: [-0.5227, -1.0885, 1.0899, -0.4723, -0.8811, -0.4063, -0.3952, -0.7157],\n",
              " 135: [0.1626, -1.3288, -0.4581, 1.6064, 0.9507, 1.048, -0.1445, 0.9557],\n",
              " 136: [-1.17, -1.3285, 0.6232, 0.0184, -0.3857, 0.2346, -0.1825, 0.2089],\n",
              " 137: [-1.8697, 1.1834, -1.5964, -0.9854, -0.6046, -1.2317, -0.2838, -0.6289],\n",
              " 138: [-0.2334, 0.8309, 0.3329, -0.521, 0.9277, -0.1695, -0.3106, -0.1447],\n",
              " 139: [-1.1966, 0.46, 0.0825, -0.4985, -0.5758, -0.0087, -0.4082, -1.4348],\n",
              " 140: [0.5814, 1.027, 0.589, -1.1577, -0.3742, -0.8911, 5.3967, 1.5234],\n",
              " 141: [0.2958, -1.053, 0.5151, 0.2731, -0.7734, 0.4824, -0.4325, -0.3553],\n",
              " 142: [1.3276, -0.4489, 2.2566, -0.2363, -0.4894, -0.3216, 0.4463, 0.1285],\n",
              " 143: [1.0154, -0.3535, -1.1525, -0.2738, -0.2935, -0.4185, -0.3547, 2.3023],\n",
              " 144: [-0.8349, 1.1145, -0.2191, -1.6779, -0.426, -1.9214, -0.3516, -1.1482],\n",
              " 145: [0.8403, -1.2313, 0.7143, 0.097, -0.3281, 0.6925, -0.4474, -0.4299],\n",
              " 146: [-1.6763, 1.1993, -1.7444, -0.8955, -0.5931, -0.1302, -0.369, -1.5473],\n",
              " 147: [-0.2562, 0.2056, 1.05, 0.2281, -0.5528, 0.4695, -0.4524, -0.4754],\n",
              " 148: [0.8288, -1.3005, 1.3061, 1.4304, -0.6294, 1.6976, 0.2162, -1.0265],\n",
              " 149: [-0.9073, -0.7377, -1.4086, -0.8843, -0.5989, -0.598, -0.3908, 1.6577],\n",
              " 150: [0.5738, 0.6879, -0.2419, 0.9323, 4.4646, 0.2458, -0.2975, -0.7764],\n",
              " 151: [1.6664, -0.266, 1.3403, 0.0746, -0.6415, 0.3715, -0.3423, -0.1723],\n",
              " 152: [0.0027, 1.2999, 0.1793, -1.3, -0.5297, -0.757, 0.1602, -1.3505],\n",
              " 153: [-1.4517, 1.1489, -0.4354, -1.2626, -0.4491, -0.8859, -0.2813, 0.3267],\n",
              " 154: [-1.7011, 0.8442, -1.2037, -1.0041, 0.2019, -1.6568, -0.2702, 0.1246],\n",
              " 155: [-1.8785, 1.3052, -1.9606, -1.56, -0.4952, -1.3783, -0.318, 0.3889],\n",
              " 156: [1.3428, -0.5416, 0.0541, 1.1308, 0.5014, 0.8989, -0.4306, 0.471],\n",
              " 157: [-0.1687, 1.1887, -0.7826, 0.0146, 0.0521, 0.1915, 0.1291, 0.7724],\n",
              " 158: [1.4532, 0.0996, 0.6972, -0.3412, -0.2014, 0.006, -0.0842, -0.1953],\n",
              " 159: [-1.2004, -1.3305, -0.9419, 1.76, -0.8477, 1.3773, -0.1072, -0.666],\n",
              " 160: [0.1435, -1.2594, 0.1167, 1.6551, 1.9127, 1.2565, -0.2129, 1.1378],\n",
              " 161: [-1.3146, 0.6958, -0.4923, 0.142, -0.6801, 0.5217, -0.4095, 0.2635],\n",
              " 162: [1.5218, -1.2626, 0.9647, 0.5727, -0.7694, 0.8772, -0.4549, -0.3154],\n",
              " 163: [1.4494, 1.141, 0.3216, -0.3861, 1.4403, -0.5345, -0.4443, -0.9502],\n",
              " 164: [-0.0697, 0.8627, -0.2305, -1.079, -0.5931, -1.0242, -0.3846, -0.3698],\n",
              " 165: [0.0978, -0.5469, 1.3801, 1.2506, -0.38, 1.0837, 1.1801, 0.0961],\n",
              " 166: [1.6779, -1.244, 0.2874, 0.8049, -0.1092, -0.4418, -0.4138, 0.3953],\n",
              " 167: [0.2311, -1.1068, -0.202, 1.1345, -0.5412, 0.8499, -0.4399, -0.6517],\n",
              " 168: [1.221, -1.1447, 0.7769, 0.951, -0.3166, 1.0611, -0.3715, 0.3385],\n",
              " 169: [1.0002, -1.0636, 1.198, 1.0821, -0.403, 1.2892, 0.3219, 0.8155],\n",
              " 170: [0.4329, -0.7403, 0.4354, 1.1757, -0.282, 0.8176, -0.2223, -0.6643],\n",
              " 171: [0.8212, -0.5972, -0.0598, 1.3068, -0.5124, 0.6895, -0.2503, -0.5654],\n",
              " 172: [-1.3794, 1.2681, 0.2874, -1.7281, -0.5758, -1.7143, -0.1172, -0.0046],\n",
              " 173: [-0.3133, 0.505, -0.7712, 1.172, 1.4922, 1.1492, -0.2658, -0.3963],\n",
              " 174: [-0.3933, -0.8357, -0.2988, 0.5502, -0.8834, 1.3227, -0.4474, 1.65],\n",
              " 175: [-1.5507, 0.6508, -0.0996, -1.5255, -0.5931, -2.3047, -0.3019, -0.3155],\n",
              " 176: [-1.5773, -0.5098, -1.6192, -0.461, 0.8873, 0.5241, -0.4138, -0.0545],\n",
              " 177: [-1.6154, 1.2019, -0.4525, -1.3637, -0.1899, -0.7943, -0.4263, -1.6535],\n",
              " 178: [-1.1091, -0.3164, -0.2476, -0.8131, -0.6254, -0.9645, -0.4026, 0.6679],\n",
              " 179: [1.2134, -1.2917, -0.0768, 1.6364, -0.426, 1.0507, -0.3398, -0.9466],\n",
              " 180: [-1.1091, -1.0885, -0.3671, 1.3106, -0.5989, 0.9912, -0.435, -0.5252],\n",
              " 181: [-1.2613, -1.331, -1.1866, 1.8836, 0.2825, 0.7042, 0.0358, 0.4381],\n",
              " 182: [-0.2182, 1.2575, -0.5492, -1.0416, -0.672, 0.2608, -0.3435, -1.4396],\n",
              " 183: [0.1473, -1.2077, 0.9647, 0.0184, -0.8103, 0.4417, -0.3871, -1.2349],\n",
              " 184: [-0.1116, -1.3221, -2.3021, 1.6664, -0.6536, 1.0743, -0.1501, 2.6253],\n",
              " 185: [0.2273, 1.0138, 0.7313, -1.1914, 0.7837, -1.1599, 5.3842, -1.0955],\n",
              " 186: [0.4024, -0.0302, 0.0541, 0.9323, 1.5671, 0.7716, -0.3031, 0.4948],\n",
              " 187: [0.9887, 1.2681, 0.8793, -0.9217, 2.7249, 0.6579, -0.2036, 0.8197],\n",
              " 188: [1.556, -0.054, 0.5207, 0.0446, 0.991, 0.7097, -0.3964, 0.0814],\n",
              " 189: [0.5699, 0.815, 0.7484, -0.5285, 1.2791, -0.3333, -0.3467, -0.8157],\n",
              " 190: [1.1372, 0.9104, -1.2891, -0.1989, -0.5297, -0.6882, -0.3479, 1.0307],\n",
              " 191: [-1.1281, 0.3779, -0.7882, -0.7644, -0.6144, 0.1191, -0.4157, 0.4678],\n",
              " 192: [0.3149, -1.2353, 1.0443, 0.2394, -0.524, 0.8137, -0.4437, -0.0532],\n",
              " 193: [-1.6306, -1.181, -1.3232, -0.3786, -0.6207, -0.4806, -0.4051, -0.0369],\n",
              " 194: [1.2667, -0.5495, 0.6516, -0.2063, -0.8638, -0.2418, -0.2471, 0.9476],\n",
              " 195: [1.2933, 0.7276, 1.3574, 0.2431, 0.9449, 0.1549, -0.305, -0.446],\n",
              " 196: [-1.0025, -0.9788, 0.9988, -0.4461, 1.3194, -0.4533, 5.1479, -0.1637],\n",
              " 197: [-1.4289, -1.1632, -0.35, 0.5128, 0.3055, 0.7472, -0.3634, 0.0029],\n",
              " 198: [1.1258, 1.1913, -0.0256, -0.2962, 2.4542, 0.2935, 0.3157, 2.0842],\n",
              " 199: [0.3796, -1.0238, -0.3842, 0.9398, -0.6507, 0.3436, -0.2453, -0.8264],\n",
              " 200: [1.5218, 0.8309, 1.1013, -0.5771, -0.691, 0.6188, -0.1818, -0.4488],\n",
              " 201: [0.5928, 1.3052, 1.2094, -1.1989, 0.0233, -0.9714, 0.7883, 0.3301],\n",
              " 202: [-0.6293, -1.2753, 0.1736, 0.6514, 0.0463, 1.0669, -0.3417, -0.5523],\n",
              " 203: [-0.6864, -1.2194, -1.7216, -0.521, -0.5873, -0.5837, -0.4163, 1.7028],\n",
              " 204: [0.292, 0.4388, 0.6118, -0.4947, -0.4376, -0.933, -0.2869, -1.0917],\n",
              " 205: [0.0407, -1.1243, -0.0541, 1.4454, 1.3367, 1.0057, -0.2496, 0.5648],\n",
              " 206: [0.0065, 0.1871, -1.2094, -0.3262, -0.426, -0.0466, -0.4275, 0.9593],\n",
              " 207: [-0.5494, -0.9973, 0.3272, 0.3255, 0.029, 0.6216, -0.4406, -1.1088],\n",
              " 208: [-1.7186, 1.2681, -1.5907, -1.4873, -0.0343, -1.4724, -0.3753, -0.9153],\n",
              " 209: [1.6779, -1.3071, 1.8468, 1.4604, 0.847, 0.7935, -0.392, 0.1098],\n",
              " 210: [-0.1953, -0.531, -0.2646, 0.0596, -0.7578, 0.6699, -0.1004, 0.8687],\n",
              " 211: [0.5928, -1.2387, 0.5094, 1.6739, 0.438, 1.604, -0.1072, -0.066],\n",
              " 212: [-0.2029, -1.2801, 0.4183, 0.8049, 0.7318, 0.5001, 0.2162, 0.1864],\n",
              " 213: [1.5903, -1.0503, 1.7102, 1.348, -0.683, 1.0073, -0.3952, 0.3774],\n",
              " 214: [1.655, -1.0702, 0.6858, -0.0341, -0.6622, -0.6542, -0.221, -0.8913],\n",
              " 215: [-0.4428, -1.3295, -0.2191, 1.8387, 0.5705, 1.3011, 0.042, -0.4671],\n",
              " 216: [-1.0443, 1.3052, -0.4866, -1.3337, 2.8805, -1.6897, -0.295, 0.7822],\n",
              " 217: [0.6727, -1.2684, 0.8452, 0.8686, -0.8005, 0.3383, -0.3715, -0.0137],\n",
              " 218: [-0.6941, 1.0615, -0.6972, -0.4985, 2.2295, -0.1396, 0.4027, 1.0972],\n",
              " 219: [-1.0329, 1.2893, 0.4354, -1.3562, -0.5528, -1.9469, 5.0484, -1.5335],\n",
              " 220: [-1.5697, 1.2443, -1.585, -1.0378, -0.7486, -0.7248, -0.3641, 0.0312],\n",
              " 221: [-0.8997, -1.3309, -0.0313, 1.0371, -0.7601, 1.3448, -0.4126, -0.7162],\n",
              " 222: [0.5319, -0.062, 0.4126, -0.0977, -0.2244, 0.9102, -0.4424, -0.7662],\n",
              " 223: [1.4304, 0.2189, 1.7728, 0.1457, -0.57, 0.6543, -0.4014, -0.3729],\n",
              " 224: [0.7298, -1.3066, -0.6744, 1.4004, -0.4664, 1.0616, -0.4256, 1.1384],\n",
              " 225: [-0.7474, -1.1054, -1.4997, 0.0109, -0.4376, 0.3662, -0.425, 0.958],\n",
              " 226: [0.4291, -0.8225, 1.0045, -0.697, -0.0747, -1.1914, 5.2661, 0.2652],\n",
              " 227: [-0.0278, -1.1362, 0.0199, 1.4267, 1.4864, 0.7864, -0.1738, 0.8397],\n",
              " 228: [-0.3095, -0.0991, -1.1525, -0.3637, 0.7491, -0.5465, -0.3933, 0.9204],\n",
              " 229: [0.2387, -1.3221, 0.1963, 1.3892, -0.3684, 0.5045, -0.3958, 0.2206],\n",
              " 230: [1.5979, -0.319, -0.0996, 0.5839, -0.8736, 0.2348, -0.1153, 2.2951],\n",
              " 231: [-0.3666, 0.5421, -0.6004, -0.4498, 0.1558, -0.3697, -0.3578, 0.7699],\n",
              " 232: [0.7946, -1.3312, 1.4883, 1.2768, 0.7088, 0.447, -0.3212, 0.4865],\n",
              " 233: [0.8136, 0.8283, 1.5395, -0.6071, -0.7279, -1.6761, -0.3672, 0.2169],\n",
              " 234: [0.4177, 0.4255, 0.5207, -0.933, 0.415, -0.3264, -0.3653, 0.5561],\n",
              " 235: [0.2387, -0.8755, 0.8338, -1.2476, -0.3742, -1.4169, 5.0235, 0.8679],\n",
              " 236: [1.4608, 0.8468, 0.1451, 0.2581, 1.1638, 0.2514, -0.3031, -0.3483],\n",
              " 237: [-1.7087, 0.6667, 0.498, 0.6926, -0.403, 0.9852, 0.2037, -1.2031],\n",
              " 238: [-0.0164, -1.3312, -0.5492, 1.7188, 0.9219, 1.2127, -0.3728, -0.4963],\n",
              " 239: [0.1588, -0.1388, 0.3272, 0.76, -0.7671, 0.6267, -0.3355, -1.2208],\n",
              " 240: [0.1397, 0.4388, -0.202, -0.1839, -0.2187, -0.5612, -0.4001, -0.4411],\n",
              " 241: [1.5256, -0.9523, 1.4427, 0.2806, -0.8149, 0.2053, -0.2795, 0.2742],\n",
              " 242: [-1.1852, 0.8256, -0.3102, -1.6379, -0.5124, -0.6702, -0.3833, -0.1376],\n",
              " 243: [-0.5113, -1.0962, 0.4638, 0.8199, -0.6507, 1.042, -0.4157, -0.4065],\n",
              " 244: [0.8555, -1.1765, 1.7273, 0.8723, -0.7083, -0.1748, -0.0805, -0.1179],\n",
              " 245: [-0.7626, 0.1235, 0.5378, 0.7637, -0.0286, 0.6686, 0.9003, -0.8809],\n",
              " 246: [-1.1547, -1.3229, 0.5777, 1.3817, 0.3113, 0.1176, -0.2503, 0.9373],\n",
              " 247: [-1.486, 0.7833, -1.4086, -0.4535, -0.5124, -0.5916, -0.3485, 0.6359],\n",
              " 248: [-0.656, -0.9125, -0.5264, -1.1015, -0.6288, -0.4314, -0.402, -0.5631],\n",
              " 249: [1.3961, 1.3079, -0.0598, -1.2738, -0.5297, -1.6369, -0.2304, 0.315],\n",
              " 250: [-1.872, 1.2761, -1.7785, -1.3862, -0.729, -1.6666, -0.3131, -1.5264],\n",
              " 251: [-0.0316, -1.0132, 1.0045, -1.2214, 0.3919, -1.7264, 4.9924, 0.318],\n",
              " 252: [0.1588, -1.2316, 1.1582, 1.6626, 2.1719, 1.3225, 0.0856, -0.3264],\n",
              " 253: [1.655, -1.0265, 1.8867, -0.5022, -0.9698, -0.0611, 0.3841, -1.3119],\n",
              " 254: [1.1525, -1.3269, 1.6135, 1.5091, -0.6904, 0.787, -0.1066, 0.006],\n",
              " 255: [0.6537, -1.1733, 1.7501, -0.1239, -0.6991, -0.2031, 0.1291, -0.5937],\n",
              " 256: [-1.2118, -1.3305, -0.9761, 1.8012, -0.5182, 1.0867, 0.2721, 0.6537],\n",
              " 257: [1.122, 0.4547, -0.1508, -0.2176, 0.7318, 0.091, -0.193, 1.0357],\n",
              " 258: [0.8631, -1.2753, 0.6915, 1.539, 2.9669, 0.5521, -0.1383, -0.6104],\n",
              " 259: [-1.1433, 0.982, -1.198, -1.1539, -0.4433, -1.0615, -0.3286, -1.1453],\n",
              " 260: [-1.2499, 1.0403, 0.185, -0.697, -0.5182, -0.7156, -0.3939, 0.7285],\n",
              " 261: [-0.0088, 1.2946, -0.0882, -1.7244, -0.524, -3.8363, -0.2776, 0.1819],\n",
              " 262: [1.2667, -1.186, 1.1809, 1.0371, -0.6922, 0.8411, -0.2789, 0.214],\n",
              " 263: [-0.005, -0.7536, 0.9988, -0.7682, -0.7504, -0.5563, -0.3442, -0.7617],\n",
              " 264: [-0.3971, -1.0212, -0.4638, -0.2363, -0.1553, 0.1506, -0.4573, 0.9477],\n",
              " 265: [-0.7588, 0.4706, -0.4923, -0.9742, -0.7838, -0.7453, -0.3622, -0.4194],\n",
              " 266: [-1.8678, -0.682, 0.1053, -0.7157, 0.2422, -0.5771, -0.4175, -0.7284],\n",
              " 267: [-0.6522, 1.0853, -0.885, -1.124, -0.5758, -0.6447, -0.4151, -1.3028],\n",
              " 268: [0.2044, 1.2999, -0.3955, -0.5172, -0.3224, 0.2514, -0.3212, -1.0565],\n",
              " 269: [-0.8997, 0.6561, -0.2646, -0.6408, -0.6916, -0.4857, -0.384, 0.3525],\n",
              " 270: [0.6004, 0.8998, 1.0045, -1.0566, -0.403, -1.0239, 5.3718, -0.8136],\n",
              " 271: [-1.4365, 1.0085, -2.046, -1.0041, -0.5067, -0.2659, -0.4213, -0.9511],\n",
              " 272: [-0.3781, -1.296, -0.3329, 1.2956, 0.4035, 1.224, -0.3224, 0.8826],\n",
              " 273: [-0.0126, -0.4621, 0.3842, 1.0109, 0.2422, 1.1769, 0.1478, 1.1363],\n",
              " 274: [1.0078, -1.2952, 1.0216, 1.4791, -0.8258, 1.2698, -0.3777, -0.196],\n",
              " 275: [-0.9758, -1.0503, 1.3801, 0.348, -0.4376, 1.0289, 0.2535, -1.1558],\n",
              " 276: [-1.848, 0.5739, -0.4069, -1.1689, -0.547, -1.8958, -0.2981, 0.0915],\n",
              " 277: [0.4862, -0.2183, 1.1297, 0.8873, 0.8355, 0.3775, -0.4163, -0.1235],\n",
              " 278: [-0.1039, -0.8966, 0.7996, 0.1345, -0.3224, 0.3701, 1.5222, -0.7221],\n",
              " 279: [1.1106, 1.1092, 0.3329, -0.8356, -0.5643, -0.1437, -0.3647, 0.8977],\n",
              " 280: [0.7793, -0.2952, 1.5338, 0.8648, -0.7118, 1.1014, 0.2224, -0.3481],\n",
              " 281: [0.0484, -1.2917, 0.9021, -0.7419, -0.0919, -1.234, 5.2847, -1.4515],\n",
              " 282: [-1.4822, 1.194, -2.2907, -1.5626, -0.5182, -2.0702, -0.3554, -1.8741],\n",
              " 283: [0.9545, -0.2766, 1.4314, 0.1345, -0.6674, 1.0662, -0.3585, -0.7491],\n",
              " 284: [0.707, -0.1918, 0.8622, -0.2213, 0.0463, -0.2484, -0.3771, -0.8875],\n",
              " 285: [-1.8659, 0.6375, -2.2168, -1.5543, -0.8177, -1.6305, -0.379, -0.7487],\n",
              " 286: [-0.6484, 0.9873, -0.6687, -1.4495, -0.7118, -1.7729, -0.3168, -0.9867],\n",
              " 287: [0.4786, -1.2003, 0.276, 1.2394, -0.6398, 0.9, -0.1109, 1.0669],\n",
              " 288: [-0.1268, -1.0344, 0.6346, 1.8836, 0.0521, 0.6066, -0.3541, -0.2993],\n",
              " 289: [1.6664, 0.3328, 0.6858, 0.4791, 0.0406, -0.1925, -0.3802, -0.6275],\n",
              " 290: [0.1017, -1.0318, 0.5264, 1.0559, -0.9001, 1.0369, -0.425, 0.2645],\n",
              " 291: [1.3847, -1.0665, 1.0956, 0.5839, -0.426, 1.0834, -0.402, -0.4547],\n",
              " 292: [0.2349, 0.7382, 0.1167, -0.8356, 0.9853, -1.4803, 0.7448, 0.7851],\n",
              " 293: [0.7298, -0.5204, -0.2419, 1.2731, 1.4346, 0.6158, 0.5023, -0.7202],\n",
              " 294: [-1.2233, 1.3026, -1.4143, -1.7424, -0.5989, -3.2082, -0.3622, -1.4128],\n",
              " 295: [0.4329, -1.0344, -0.3443, 0.0521, 0.4899, -0.3672, -0.448, -1.07],\n",
              " 296: [0.4938, 0.6826, 0.3671, -0.2887, -0.8241, -0.3755, -0.3746, 0.4345],\n",
              " 297: [-0.7702, 1.2178, -0.8395, -0.5622, 0.3286, 0.3086, -0.3995, 0.2685],\n",
              " 298: [1.0382, -1.0371, 1.6192, 0.6663, -0.3569, 1.381, -0.1016, -0.0998],\n",
              " 299: [0.0636, -1.0556, 1.0443, 0.2319, -0.7043, 0.4913, -0.4462, -0.366],\n",
              " 300: [-0.8349, -1.1621, 0.1907, 1.4192, 0.8931, 1.0167, -0.0699, -0.876],\n",
              " 301: [-1.1281, 1.2814, -1.1013, -1.0865, 0.582, -1.0203, -0.3734, -1.4093],\n",
              " 302: [0.6651, -1.0079, 0.3842, 1.4828, 0.1846, 0.9933, 0.0856, -1.0697],\n",
              " 303: [1.4646, -0.9258, 1.6135, -0.3861, -0.6974, -0.7151, -0.4032, -0.257],\n",
              " 304: [-1.4174, 1.2416, -0.7484, -1.3974, -0.5528, -1.1632, -0.4219, -0.5189],\n",
              " 305: [-0.8387, 0.1526, 0.9931, -0.7457, 1.089, -2.2368, 3.6242, -0.0507],\n",
              " 306: [-1.7532, 1.2681, -0.6118, -1.0453, 3.0821, -1.4704, -0.3454, 0.2102],\n",
              " 307: [0.4291, 0.778, -1.198, -0.461, 1.2042, 0.0482, -0.4057, 1.9832],\n",
              " 308: [0.5243, 1.2522, -1.4712, -0.3936, -0.5355, -0.9466, -0.1912, -1.4304],\n",
              " 309: [1.3238, -0.6608, -0.0711, 0.097, -0.801, -0.2896, -0.3137, 2.5518],\n",
              " 310: [1.2743, -1.0636, 1.6135, 0.4866, -0.9687, 0.784, -0.2148, 0.665],\n",
              " 311: [-0.8121, 0.5554, 0.3216, -0.0865, -0.2071, 0.6966, -0.3504, -1.3647],\n",
              " 312: [0.9925, -0.168, 1.0273, 0.8611, -0.3569, 0.4695, -0.3945, -0.7362],\n",
              " 313: [-1.2575, 1.0191, -0.9931, -1.1652, -0.138, -0.4956, -0.4101, -1.4085],\n",
              " 314: [-0.0811, -0.3376, -0.0028, 0.2656, -0.8212, 0.6939, -0.4387, -0.5702],\n",
              " 315: [-0.8159, 1.1065, -1.3403, -0.7457, 0.2825, -0.6251, -0.3672, -0.0396],\n",
              " 316: [-0.9073, 0.1844, -0.0427, -0.4198, -0.74, 0.7127, -0.356, -1.4411],\n",
              " 317: [-1.2994, 1.1728, -1.2549, -0.8094, -0.6334, -0.4463, -0.3709, 0.5339],\n",
              " 318: [-0.7816, 1.3052, -0.9078, -1.6236, -0.0458, -1.9414, -0.142, -1.5049],\n",
              " 319: [0.3187, -0.0434, 0.7769, 0.6139, 0.3286, 0.985, -0.443, 1.0112],\n",
              " 320: [-1.4251, 0.9051, -1.4997, -1.0603, 1.0947, -0.0825, -0.407, 1.1743],\n",
              " 321: [1.655, -1.1969, 1.5566, 1.0671, -0.7187, 0.4078, -0.3983, 0.8743],\n",
              " 322: [1.2933, -0.4171, 1.4314, 0.7263, -0.5355, 0.5875, -0.397, -0.8464],\n",
              " 323: [-1.7452, -1.3213, 0.7825, 0.0671, -0.524, 0.857, -0.2901, -0.8783],\n",
              " 324: [-1.7601, 1.1542, -2.5252, -0.9479, -0.5528, -1.2534, -0.3498, -0.9741],\n",
              " 325: [-1.5545, 1.231, -0.3785, -1.7322, -0.6046, -1.8632, -0.3908, -1.3362],\n",
              " 326: [-1.0862, 1.239, 0.0882, -1.5682, -0.7596, -1.4299, -0.3771, -0.34],\n",
              " 327: [-0.953, -0.4886, 0.5264, -0.0153, -0.638, 0.1515, -0.4399, -0.7982],\n",
              " 328: [0.0141, -0.8251, 1.9094, 0.3892, -0.6916, 1.1074, 0.8878, -0.7847],\n",
              " 329: [0.0712, 0.2268, 1.0557, -1.3525, 1.8033, -1.1325, 5.2972, 0.2304],\n",
              " 330: [0.372, 0.0652, 1.4826, 0.2768, -0.6282, 0.5038, -0.4225, -0.2287],\n",
              " 331: [1.3504, -0.8092, -0.0541, 0.7974, 0.8701, 0.2129, -0.3933, -0.9233],\n",
              " 332: [-0.4999, -1.2578, 0.2988, 0.9472, -0.7095, 1.1534, 1.2361, -0.4863],\n",
              " 333: [-0.7093, 0.3408, 0.2931, -1.1165, -0.7089, -0.1479, -0.3062, -0.6071],\n",
              " 334: [0.471, -1.2382, 0.5549, -0.1015, -0.7895, 0.1941, -0.3653, 0.3199],\n",
              " 335: [-1.8111, 1.2999, -1.2891, -1.4656, -0.8201, -1.4344, -0.2111, -1.5711],\n",
              " 336: [0.5357, -1.3145, -0.3273, 1.2656, 4.4185, 0.169, -0.3417, -0.7656],\n",
              " 337: [0.49, -0.5416, -0.2646, 0.6027, 0.5532, 0.4959, -0.3529, 0.3557],\n",
              " 338: [-0.7626, 0.6534, 0.2931, -0.4273, -0.7215, 0.4134, -0.4001, -0.2124],\n",
              " 339: [-0.4123, 1.1648, 0.0484, -0.8318, -0.4433, -0.1994, 0.1664, 1.2368],\n",
              " 340: [1.0116, 0.6746, -0.0199, -0.3861, -0.2071, 0.197, -0.3697, 0.6515],\n",
              " 341: [0.1511, 0.4123, 0.185, -0.1764, -0.4318, 0.8678, -0.4014, -1.0987],\n",
              " 342: [-1.604, 0.672, -0.1679, 1.4978, 3.8597, 0.3846, 5.2101, 0.5357],\n",
              " 343: [-0.9073, -0.4224, 0.5663, 0.4678, 0.4438, 1.0015, -0.31, -1.1349],\n",
              " 344: [1.1182, 0.5766, 0.6289, -0.4947, 0.0866, 0.1354, -0.1159, 1.7194],\n",
              " 345: [-0.8806, -0.0832, 0.1394, -0.888, -0.6968, -0.5991, -0.3498, -1.8476],\n",
              " 346: [1.24, -0.3005, 1.9493, -0.2775, -0.6213, -0.5398, -0.2459, -0.0257],\n",
              " 347: [0.9392, -1.2957, -0.6004, 1.0072, -0.4548, 1.118, -0.3479, 1.784],\n",
              " 348: [-0.3971, 1.2893, -1.9322, -1.5034, -0.6351, -2.7677, -0.3746, -1.7024],\n",
              " 349: [-0.4047, -1.1696, 0.2077, 1.6139, -0.282, 1.1766, 0.2162, -0.0421],\n",
              " 350: [-0.222, 1.1542, 0.6858, -1.1539, -0.5816, -0.6806, -0.4207, -0.7343],\n",
              " 351: [1.3771, -1.2787, 0.8452, 1.0746, -0.5297, 0.3682, -0.3908, -0.3441],\n",
              " 352: [0.7565, -0.743, 0.1679, 1.4641, 0.5417, 0.7259, 3.5869, 2.2457],\n",
              " 353: [1.0573, 0.566, 1.8923, -0.8768, 0.8182, -0.4583, -0.3666, -0.3924],\n",
              " 354: [1.122, 1.292, 0.9874, -0.5697, -0.5124, -0.6693, -0.3255, -0.0164],\n",
              " 355: [-0.8349, 0.9634, -0.5663, -0.2251, 0.6742, -0.5464, -0.3877, -0.2003],\n",
              " 356: [-0.5532, 1.284, -1.4484, -1.0528, 0.5936, -1.2338, -0.2789, -0.6458],\n",
              " 357: [0.4671, -1.324, 0.5777, 1.157, 1.1235, 1.1071, -0.4493, -0.1387],\n",
              " 358: [0.2387, -1.3303, -1.7102, 1.7226, 0.6396, 1.1863, -0.1818, 2.0658],\n",
              " 359: [1.4342, 0.248, 0.3045, 0.3742, 3.3355, 1.2188, 0.1913, 0.6572],\n",
              " 360: [-1.0063, 1.2469, -0.2476, -1.7472, -0.7054, -1.5088, -0.3653, -0.2019],\n",
              " 361: [0.6765, 0.5077, 1.3289, -0.0902, -0.729, 0.6709, -0.407, -0.2583],\n",
              " 362: [0.1207, -1.2361, 0.8679, 1.4566, -0.9808, 1.0544, -0.4064, 0.1614],\n",
              " 363: [0.4862, -1.2721, 0.6915, 1.5091, -0.0055, 1.1081, 2.3493, -0.0379],\n",
              " 364: [1.2248, -0.1521, 0.811, 0.7899, 0.0175, 0.7449, -0.3404, -0.0675],\n",
              " 365: [1.3162, -1.2363, 1.0557, 1.4342, 0.7491, 0.1642, -0.3305, -0.0559],\n",
              " 366: [0.0864, -0.5204, -1.7728, 0.4154, -0.4376, 0.4237, -0.3721, 1.8797],\n",
              " 367: [-0.1725, -1.2522, -0.7541, 1.8387, -0.0804, 1.456, 0.0296, -1.3486],\n",
              " 368: [1.122, 0.4573, -0.8053, 0.509, -0.615, 0.5724, -0.4175, -1.5354],\n",
              " 369: [-0.6217, -1.331, -1.0842, 1.539, -0.7964, 0.2939, -0.0152, 0.3081],\n",
              " 370: [-0.7854, -1.3308, 0.9248, -0.0228, -0.7066, 0.3981, -0.2925, 2.7575],\n",
              " 371: [-0.0697, 0.2507, -0.2305, 1.73, -0.9641, 1.4389, 0.0296, 0.1809],\n",
              " 372: [-1.1014, -1.292, -0.5606, 1.8312, 0.2883, 0.9888, 0.4898, 0.0438],\n",
              " 373: [0.1131, -1.1643, 1.807, 0.6326, -0.736, 0.6016, 0.8505, -0.1635],\n",
              " 374: [0.7413, 0.2798, 0.572, -0.8843, -0.4606, -0.8771, 5.0919, -0.7178],\n",
              " 375: [1.2552, 0.8919, 1.1639, 0.0446, -0.3281, -0.9397, 0.2659, -0.4216],\n",
              " 376: [-1.5697, 1.2708, -0.1394, -1.3075, -0.7855, -1.1528, -0.2297, 0.0319],\n",
              " 377: [-1.0253, 1.2734, 0.1281, -1.7236, -0.3051, -1.5919, -0.2316, -1.1826],\n",
              " 378: [0.3263, -1.1314, 0.5094, 0.6963, 0.3574, 0.29, -0.4374, 0.09],\n",
              " 379: [0.6309, -0.4542, 0.4297, 0.2094, -0.2935, 0.7113, -0.2975, 1.8542],\n",
              " 380: [1.1182, -0.4595, 1.4598, 0.4903, -0.7406, 0.4836, -0.4275, -0.2045],\n",
              " 381: [0.4215, 1.2628, -0.1679, -1.4124, -0.5873, -2.4118, -0.1333, 0.4292],\n",
              " 382: [0.2311, 0.6375, 0.7256, -0.255, -0.4376, -0.095, -0.3286, 0.6105],\n",
              " 383: [-0.7626, 1.0403, -0.0768, -0.7157, -0.5873, 0.1248, -0.4325, 0.5513],\n",
              " 384: [-1.722, 0.8018, -1.807, -1.442, 0.9449, -0.9324, -0.4082, -1.1067],\n",
              " 385: [-1.8149, -1.1741, -2.0802, -0.873, -0.0919, -0.3803, -0.4175, -0.5764],\n",
              " 386: [-0.1572, 0.0731, 0.1508, 0.082, -0.5355, 0.533, -0.3958, 0.5257],\n",
              " 387: [-0.2829, -1.3081, -1.3631, 1.9023, 1.5383, 1.4305, 0.1851, 0.577],\n",
              " 388: [-1.4327, 0.7223, 0.1281, 0.0221, -0.5009, 0.9123, -0.4188, 0.0386],\n",
              " 389: [0.2121, 1.2973, -1.1411, -0.2026, 0.6512, 0.8651, -0.328, 1.8233],\n",
              " 390: [-0.7055, 0.2798, -0.2817, 0.3405, -0.3915, 0.4203, -0.42, 1.662],\n",
              " 391: [0.8365, -0.7244, 0.5094, 0.5989, 0.0002, 0.9948, -0.2851, 1.9697],\n",
              " 392: [-0.0506, -0.0593, 1.5623, 0.1644, -0.4664, 0.3712, -0.2248, 0.8772],\n",
              " 393: [1.6169, 1.3052, -0.0996, -0.491, -0.38, -0.2818, -0.2801, -0.3182],\n",
              " 394: [-0.3057, -1.3127, 0.2476, 0.3143, -0.623, 0.5795, -0.3889, -1.0776],\n",
              " 395: [1.0839, 1.2416, -0.111, -0.8655, -0.4318, -0.2031, 0.3219, 1.7434],\n",
              " 396: [0.2044, -0.0223, -0.8395, 0.6251, 0.9104, 0.6129, -0.3411, 1.0077],\n",
              " 397: [1.6169, -0.319, 1.659, 0.5427, -0.7694, 0.8347, -0.3933, 0.4511],\n",
              " 398: [0.8098, -1.3042, 1.6476, 0.6663, 0.2998, 0.6731, 0.0022, 0.0516],\n",
              " 399: [-1.2157, 0.3699, -0.1964, 0.2019, -0.5412, 0.7458, -0.4499, -0.8478],\n",
              " 400: [1.1791, -1.3165, 0.1793, 1.569, -0.259, 1.1051, -0.2726, 0.5262],\n",
              " 401: [0.3758, -1.1804, 1.9663, 0.333, -0.4548, 0.5367, -0.2241, -1.0748],\n",
              " 402: [-0.3628, 1.2575, 0.8281, -1.315, -0.1265, -2.2442, 3.363, -0.0465],\n",
              " 403: [-0.4618, -0.062, -0.1167, -0.6258, -0.5643, -0.2238, -0.3, 0.4388],\n",
              " 404: [-0.9339, -0.9178, -0.0028, 0.7637, -0.2705, 0.8333, 2.2436, 1.0326],\n",
              " 405: [1.141, -1.3224, 0.1565, 0.3442, 0.4956, 0.6557, -0.1203, 2.2464],\n",
              " 406: [1.6664, -1.1653, 1.2777, 0.8911, -0.7521, -0.0927, -0.2813, -0.4398],\n",
              " 407: [-1.1814, 0.0705, -0.276, -0.5996, 0.1961, -0.0248, -0.4486, -1.3511],\n",
              " 408: [-1.6958, 1.3026, -1.4029, -1.6483, -0.4491, -2.4212, -0.3622, -1.3678],\n",
              " 409: [-0.222, -1.3302, -1.1866, 0.4079, -0.2244, -0.8233, -0.2851, 1.1661],\n",
              " 410: [0.7679, 1.292, -0.0199, -0.5547, -0.2071, 0.3797, -0.3703, -1.3009],\n",
              " 411: [-0.3628, 0.6614, -0.35, -0.7719, -0.0977, -0.1702, -0.4343, 0.4385],\n",
              " 412: [1.1486, 0.5077, 0.7029, -0.491, -0.668, -0.4486, -0.3858, 0.2575],\n",
              " 413: [0.2006, 1.2946, 0.0199, -1.7618, -0.687, -1.6901, 0.1415, -1.3921],\n",
              " 414: [-1.0101, 0.5368, -0.3955, -1.2775, -0.5758, -0.9606, -0.3522, 0.7745],\n",
              " 415: [-0.1116, -1.1953, -1.5452, 0.966, -0.2475, 0.6143, -0.1209, -2.227],\n",
              " 416: [-0.321, -1.2801, -0.959, 0.082, 1.6132, -0.5731, -0.3255, 0.3075],\n",
              " 417: [1.0992, 1.3079, 0.4126, -1.0004, -0.259, -0.4275, 1.6466, 2.0516],\n",
              " 418: [-1.3032, 0.9661, -1.4883, -1.1839, -0.4779, -0.8835, -0.3827, 1.8971],\n",
              " 419: [1.6588, 0.1367, 0.424, 0.5989, -1.0171, 0.3897, -0.3796, 0.7147],\n",
              " 420: [1.2172, 1.3026, 1.7159, -0.7569, -0.5124, 0.3105, 0.3095, 0.0472],\n",
              " 421: [-1.7997, -1.3266, -0.5834, 0.8911, 0.2134, 1.2698, -0.3765, -1.274],\n",
              " 422: [-1.0862, -1.3158, -0.0882, 1.1532, 0.4784, 0.9203, -0.4542, -0.682],\n",
              " 423: [-1.8237, 1.0959, -2.0574, -1.6131, 1.1523, -2.53, -0.3634, -1.2519],\n",
              " 424: [-1.6657, -1.3307, -2.1086, 1.8462, -0.1899, 1.2675, 0.7324, 2.6693],\n",
              " 425: [-1.6424, -0.4171, 1.033, 1.0708, -0.5816, 1.0236, 0.5707, 0.6789],\n",
              " 426: [0.3453, 1.2973, -0.0313, -0.5884, -0.4721, -0.7938, -0.3367, 0.5418],\n",
              " 427: [0.3834, 1.292, 0.4581, -1.1202, -0.3454, -2.5753, 1.1304, -0.5893],\n",
              " 428: [-1.7312, 1.1065, -1.5338, -1.2101, -0.547, -0.9874, -0.4039, 0.1614],\n",
              " 429: [-0.3781, 0.2692, 0.589, -0.4498, -0.6611, 0.51, -0.1731, -0.0216],\n",
              " 430: [1.518, -0.0514, 0.5435, 0.082, -0.9865, -1.4566, -0.3939, -0.4998],\n",
              " 431: [-0.3819, 0.2454, -0.7996, 0.1307, -0.5182, 1.1028, -0.4045, 0.36],\n",
              " 432: [0.2958, 1.2867, -0.5549, -1.0715, -0.6213, 0.505, -0.3765, -0.7133],\n",
              " 433: [0.5852, -0.0461, 0.0313, 0.4978, -0.5528, 0.1892, -0.4126, 0.4091],\n",
              " 434: [1.4875, 0.2851, -0.259, 1.6701, 0.9392, 1.3103, -0.1694, 2.5072],\n",
              " 435: [-0.7245, -1.3246, -2.0005, 1.76, 1.953, 1.4228, 0.608, 1.9822],\n",
              " 436: [1.3352, -1.2854, 0.959, 1.745, 0.294, 1.2816, -0.4132, 0.0325],\n",
              " 437: [-1.4365, -1.0371, 1.0899, 0.0783, -0.4721, 0.5689, -0.1072, 0.5826],\n",
              " 438: [0.7755, 0.8256, -1.2663, -0.7494, 0.3689, 0.0061, -0.3578, 2.9914],\n",
              " 439: [-0.2524, -0.5522, -0.5094, 1.2806, 2.6328, 1.0501, -0.3137, 2.2189],\n",
              " 440: [-0.9187, -0.6873, -0.6175, -0.7007, 0.3228, -0.5338, -0.4294, -1.3243],\n",
              " 441: [1.2743, 1.2814, 1.0899, -1.0079, -0.6599, -0.4236, -0.3554, 0.8707],\n",
              " 442: [1.0268, 0.5792, -0.9248, 0.2319, -0.7717, 0.4548, -0.0743, -1.1316],\n",
              " 443: [0.8022, -0.4224, 0.2134, 0.7038, -0.4376, 0.1867, -0.4132, 0.7213],\n",
              " 444: [0.3872, -1.2204, 0.424, -0.6595, -0.57, -0.6408, 0.2473, 2.3446],\n",
              " 445: [1.4494, 0.1367, 0.4752, 0.8311, -0.8684, 0.2069, -0.3746, -0.8812],\n",
              " 446: [1.6626, 0.4335, 1.6135, 0.2319, -0.8385, -1.1102, -0.2192, -0.5666],\n",
              " 447: [-1.2347, 1.2125, -1.3574, -0.6858, -0.57, -0.0268, -0.3684, 0.5333],\n",
              " 448: [-0.972, -0.9788, -0.0825, -0.3749, -0.547, 0.5411, -0.4406, -1.2722],\n",
              " 449: [-0.0735, 0.0599, 1.659, 0.3742, -0.7434, 1.0124, -0.3529, -0.2927],\n",
              " 450: [-0.557, -1.1203, 0.1224, 0.509, -0.8368, 0.5843, -0.4207, 0.8832],\n",
              " 451: [0.8593, 1.1012, 0.7143, -0.5809, 0.6454, 0.3216, -0.1651, 1.2725],\n",
              " 452: [0.9697, 0.8203, 0.3557, -0.3711, -0.6432, -0.4013, -0.3777, -0.787],\n",
              " 453: [-1.0177, -0.221, 0.7199, -1.2139, -0.3339, -1.9315, 5.3469, -1.3868],\n",
              " 454: [0.3644, -0.2793, 0.9704, 1.3518, 3.4219, 1.5538, 1.3418, 1.0125],\n",
              " 455: [-1.8012, 1.2575, -2.4444, -1.0079, -0.2071, -0.5603, -0.3802, -1.2581],\n",
              " 456: [0.1055, 0.5501, 0.7655, -0.1726, -0.5067, -0.0526, -0.4082, -0.3911],\n",
              " 457: [-0.005, -1.2883, 0.9647, 0.2618, -0.0804, 0.7893, -0.4281, 0.7485],\n",
              " 458: [0.2083, 0.2348, 0.1224, -0.888, -0.4779, -0.4901, 0.2597, -1.4145],\n",
              " 459: [-0.9111, -1.3288, 0.0028, 1.4004, 0.8355, 1.013, -0.361, 0.6268],\n",
              " 460: [0.4291, 0.3884, 0.1337, -0.3487, -0.7239, -0.5847, -0.2198, 2.6957],\n",
              " 461: [0.4519, -0.7324, 1.8411, 0.6888, -0.57, 0.8761, 0.4712, -0.5352],\n",
              " 462: [0.6765, -0.2236, 0.5264, -0.0004, -0.3512, 0.0475, -0.3404, 0.3329],\n",
              " 463: [-0.2296, 0.6534, 0.9476, -1.0041, -0.1438, -1.2483, 5.3158, 0.474],\n",
              " 464: [-0.0544, 0.0784, -0.202, -0.6933, -0.3569, -0.201, -0.392, 1.2153],\n",
              " 465: [-1.0748, -1.3124, 0.1281, 1.2282, 0.2076, 0.6043, -0.0687, 1.7252],\n",
              " 466: [0.5319, -1.3264, 2.359, 0.157, -0.5412, 0.9523, 0.0109, 0.4215],\n",
              " 467: [0.9697, -0.0699, 1.3403, 0.3854, -0.668, 1.0112, -0.0519, 1.0105],\n",
              " 468: [-0.0392, 1.2893, -0.3273, -0.3337, 2.3044, -0.7047, -0.3056, -0.3418],\n",
              " 469: [0.0484, -1.2726, -0.0142, 1.4828, 0.9104, 1.1852, -0.3703, 0.9159],\n",
              " 470: [-0.4276, 1.1145, -0.111, -1.0416, -0.4606, -1.2462, -0.3927, -1.3069],\n",
              " 471: [0.5014, 0.7647, 0.6858, -0.2251, 3.18, -0.124, -0.2832, 0.1132],\n",
              " 472: [-0.538, -0.115, -0.4866, 0.5053, -0.1265, 0.1338, 0.6453, -1.2793],\n",
              " 473: [0.9583, 0.8866, -0.7996, -0.2663, -0.3857, -0.1081, -0.3759, 1.7539],\n",
              " 474: [1.2819, 1.2867, 0.2533, -1.1165, -0.2878, -1.8731, -0.1539, -1.1692],\n",
              " 475: [-0.9758, 0.5713, -1.9208, -0.6745, -0.7331, -0.5559, -0.3616, -1.0626],\n",
              " 476: [1.6436, -0.3111, 1.3005, 1.4641, 0.0406, 1.3571, -0.236, -0.3077],\n",
              " 477: [1.457, 0.5209, 1.0785, 0.0483, -0.4952, 0.8367, -0.4045, 0.1723],\n",
              " 478: [-0.5456, 0.2719, 0.6175, 1.3705, -0.0574, 0.2806, -0.3467, 0.4852],\n",
              " 479: [-1.4631, -1.2249, -1.3915, 1.2544, -0.4318, 1.0636, -0.0811, 1.5611],\n",
              " 480: [1.6664, 1.0323, 0.9931, -0.1801, 0.029, 0.0781, -0.2042, -0.6117],\n",
              " 481: [0.9621, -0.1017, 0.0541, 0.5839, -0.5009, -0.1739, -0.1016, -0.897],\n",
              " 482: [-1.8762, 1.1622, -2.2794, -1.5716, 0.415, -2.0028, -0.3622, -0.9547],\n",
              " 483: [0.509, -1.1062, -1.5623, 1.5465, -0.6403, 1.0034, -0.2944, 0.3905],\n",
              " 484: [1.6969, 1.292, -0.6744, -1.4809, 0.5993, -2.2251, -0.0668, -1.037],\n",
              " 485: [0.589, 1.1754, -0.2817, -0.491, -0.1611, -0.9057, -0.2957, -1.0929],\n",
              " 486: [1.0839, -0.8569, 0.5435, 0.9997, -0.7296, 1.1467, -0.0133, 2.045],\n",
              " 487: [-0.0697, 1.3052, -0.5492, -1.5645, -0.4779, -0.7239, 0.0172, 2.0546],\n",
              " 488: [-0.4542, 1.2973, -0.811, -1.1951, -0.6876, -1.8659, -0.3236, 1.2738],\n",
              " 489: [-0.675, 1.2946, 0.7029, -1.4502, -0.6046, -1.9205, -0.3703, -1.2857],\n",
              " 490: [1.5446, -0.4462, 1.7842, 0.363, -0.547, 0.3501, -0.3075, -0.6067],\n",
              " 491: [1.5484, -1.053, 0.0939, 0.7038, -0.8074, -0.1424, -0.4057, 1.0166],\n",
              " 492: [-1.0786, -1.0026, -1.2492, 0.5203, -0.6559, 0.4133, -0.3554, -0.3629],\n",
              " 493: [0.2806, -0.6317, 0.498, -0.0041, 1.7629, 0.4026, -0.2608, 0.8498],\n",
              " 494: [-0.2334, -1.053, -0.4809, 0.3929, 0.3862, 0.0657, -0.4088, 0.1658],\n",
              " 495: [-0.4961, 0.2692, -0.185, -0.0153, -0.5182, -0.1474, -0.4101, 0.5101],\n",
              " 496: [-0.9644, -1.3053, -2.0403, 0.363, -0.3454, 0.9272, -0.3927, 2.3161],\n",
              " 497: [0.0598, -0.9814, 0.2817, 1.3293, 1.1638, 1.0259, -0.4505, -0.716],\n",
              " 498: [-1.4327, 1.2761, -0.8224, -1.6487, -0.5643, -1.9628, -0.2366, -0.9142],\n",
              " 499: [-1.8667, 0.7488, -1.3175, -1.633, -0.547, -1.9152, -0.4138, 0.7069],\n",
              " 500: [-1.4707, 0.0307, 0.1793, 0.1457, -0.6265, 0.2233, -0.0892, -0.064],\n",
              " 501: [-1.2233, -1.3297, -1.5224, 0.9435, -0.7388, 0.9994, -0.3398, 1.4265],\n",
              " 502: [0.7489, -1.31, -0.6061, 1.1757, 4.0959, 0.6667, -0.3896, -0.1448],\n",
              " 503: [-0.3666, -0.0064, -0.4411, -0.1389, 0.68, -0.2531, 0.2659, 1.5788],\n",
              " 504: [1.2933, 1.3052, 0.8281, -0.9367, -0.4894, -0.3041, 1.2672, 0.073],\n",
              " 505: [-1.0177, 1.2708, 0.5492, -1.3749, -0.6628, -1.0601, -0.328, -1.2074],\n",
              " 506: [0.825, -1.0238, -0.1907, 1.2581, 0.173, -0.3587, -0.3554, 1.4581],\n",
              " 507: [1.0953, -0.6635, 0.0654, 1.0371, 1.0256, 0.4745, -0.3522, 0.9448],\n",
              " 508: [-0.5837, -0.1256, -0.3159, -0.5959, -0.3627, -0.036, -0.3174, 0.2063],\n",
              " 509: [-1.7171, 1.2205, -1.2379, -0.7157, -0.5931, -0.2699, -0.3659, -0.4797],\n",
              " 510: [1.4456, 1.0774, -0.1736, 0.0596, -0.5009, 0.5756, -0.3591, -0.2131],\n",
              " 511: [1.3619, -1.0477, 0.424, 0.2543, 1.5268, -0.2938, 0.1291, 0.863],\n",
              " 512: [-0.1344, -1.3307, -1.1468, 1.9098, -0.2014, 1.341, -0.2876, -0.4163],\n",
              " 513: [-0.161, 1.3052, -0.3671, -1.5888, -0.3339, -2.2532, -0.2316, -1.493],\n",
              " 514: [-1.4251, 0.9608, -0.3728, -1.5135, -0.5067, -0.9001, -0.4132, 1.0546],\n",
              " 515: [-1.5393, -1.3198, -1.2834, 0.3218, -0.2935, 0.9284, -0.3995, -0.0185],\n",
              " 516: [0.1283, -0.9814, -0.4638, 0.2356, -0.7457, 0.3936, -0.3398, 0.4079],\n",
              " 517: [1.0725, -1.217, 0.5264, 1.599, 0.1442, 0.7611, -0.3697, -0.0597],\n",
              " 518: [1.5903, -0.1627, 0.737, 0.7, 0.0578, 0.9164, -0.4082, -0.6104],\n",
              " 519: [-0.4276, 1.0058, 0.3102, -0.2475, -0.5355, 0.2921, -0.458, -0.684],\n",
              " 520: [0.707, 0.1261, 1.3574, -0.2813, -0.5009, 0.5855, 0.2597, -0.6194],\n",
              " 521: [1.2933, 0.1129, 0.3329, 0.157, -0.5758, 0.0442, -0.3666, 1.4395],\n",
              " 522: [-0.953, -0.2952, 0.9476, -1.1989, -0.1899, -1.8845, 5.1355, -0.3597],\n",
              " 523: [-0.8997, -0.6476, 0.037, 0.8124, -0.3512, 1.2906, -0.3989, 0.8076],\n",
              " 524: [1.5789, -0.2157, -0.6517, 0.4191, -0.6046, -0.4263, -0.3131, 0.3528],\n",
              " 525: [0.3415, 1.2125, 0.2703, -1.1614, -0.7048, -0.2457, -0.2397, 0.0878],\n",
              " 526: [-0.7359, -1.3199, 0.259, 0.4791, -0.3742, 1.027, -0.3734, -0.0964],\n",
              " 527: [-0.7207, 0.8495, -1.033, -1.4431, -0.2532, -1.833, -0.2944, -1.5444],\n",
              " 528: [-0.8273, 0.9873, -0.0313, -1.1764, 0.703, 0.0297, -0.4306, -1.1434],\n",
              " 529: [1.1182, 0.5474, -0.9647, -0.3524, 1.544, -1.3189, 0.353, 1.628],\n",
              " 530: [-0.7055, -1.3306, -0.1053, 1.7937, -0.0574, 1.4558, -0.2117, -0.7665],\n",
              " 531: [-1.7776, 1.1913, -1.7785, -0.4498, -0.38, -0.4185, -0.3454, -0.3973],\n",
              " 532: [0.1626, 0.8044, 0.1907, 1.1982, -0.8396, 0.7088, -0.2633, 0.9937],\n",
              " 533: [0.0103, 1.0588, -0.0655, -1.1053, 0.1097, 0.0419, -0.1949, 0.6259],\n",
              " 534: [1.0192, -1.0159, 0.6573, 0.7225, 1.6016, 0.9086, 0.7137, -0.7871],\n",
              " 535: [0.7679, -1.2745, 0.4468, 1.1008, -0.1553, 0.622, -0.3833, 1.041],\n",
              " 536: [0.6385, -0.2766, 0.3216, -0.7794, 0.5417, 0.302, 1.2175, 1.3673],\n",
              " 537: [-0.6598, 0.8786, 0.0142, -0.0303, -0.3512, 0.0979, -0.3945, -0.3678],\n",
              " 538: [1.2819, -1.2199, 0.8508, 0.5352, -0.3108, 0.7965, -0.4343, -0.4228],\n",
              " 539: [-0.1268, 0.9157, -0.1053, -1.315, -0.38, -1.7407, -0.2994, -0.4503],\n",
              " 540: [-1.2271, -1.1757, 0.9476, 1.8948, -0.524, 1.38, 0.1229, 0.3585],\n",
              " 541: [-0.8806, -0.3561, 0.5094, -0.2887, -0.6207, 0.7528, -0.4026, -0.1689],\n",
              " 542: [-2.0152, -1.3312, -3.0591, -1.8057, -1.1807, -8.5871, -0.611, -3.8077],\n",
              " 543: [0.7565, -1.3279, -1.2663, 1.8312, -0.7573, 1.1265, 0.0041, -0.9221],\n",
              " 544: [-1.1776, -0.6476, 0.8736, 0.7038, -0.5067, 1.2335, -0.2105, 1.7259],\n",
              " 545: [-1.5583, 1.2522, -1.7273, -1.285, -0.7118, -0.9565, -0.3983, -0.4666],\n",
              " 546: [0.5509, -1.2875, 0.8395, 0.3143, -0.5643, -0.4033, -0.3753, 0.2816],\n",
              " 547: [-0.8273, 0.1579, -0.111, -0.5172, -0.1783, -0.4873, -0.3566, 0.2093],\n",
              " 548: [-0.1496, 1.2999, -0.7199, -0.5846, -0.5124, -0.3573, -0.3417, -0.5375],\n",
              " 549: [-1.7696, 1.1728, -1.3005, -1.7057, 0.3228, -2.6426, -0.2596, -1.5235],\n",
              " 550: [0.2996, 1.3052, -0.1565, -1.2813, -0.3108, -0.3913, -0.2683, 1.9572],\n",
              " 551: [-0.4809, -1.3005, 0.4012, 1.7113, -0.8028, 1.189, -0.2509, 1.8874],\n",
              " 552: [-1.8366, 1.1913, -2.2168, -1.6124, -0.3684, -1.1716, -0.3821, -1.0228],\n",
              " 553: [-0.6255, 1.284, -0.9704, -0.6783, -0.6628, 0.6234, -0.2571, -0.9301],\n",
              " 554: [1.674, 0.9396, -0.1451, 0.1607, -0.1207, 0.1375, -0.0544, -1.3808],\n",
              " 555: [-0.1877, -0.4144, -0.7655, 0.745, -0.3281, 0.6911, -0.3417, 1.225],\n",
              " 556: [-1.3108, 0.1367, -1.2379, -0.4873, -0.6328, 0.6669, -0.3983, 0.0841],\n",
              " 557: [-0.8121, 1.2443, -1.898, -1.2026, -0.4836, -0.6624, -0.402, -1.1393],\n",
              " 558: [1.3542, -0.5363, 1.0216, 1.5091, 1.1638, 0.9861, -0.1906, 0.3591],\n",
              " 559: [1.2933, 1.3052, 1.5964, -1.5993, -0.5182, -1.6588, 0.0794, 0.0761],\n",
              " 560: [1.3961, 1.035, 0.646, 0.0895, 1.0198, 0.8094, -0.2938, 0.7142],\n",
              " 561: [-0.123, 0.8813, 0.2931, -0.079, -0.4606, -0.2176, -0.3964, -1.2951],\n",
              " 562: [-0.9187, 1.186, -0.5321, -1.0303, 1.4519, -0.0312, -0.4088, -1.2039],\n",
              " 563: [0.6042, -0.7377, 1.5167, 0.142, -0.6369, 0.5418, -0.3933, -1.1711],\n",
              " 564: [-0.5456, 0.558, -0.3899, -0.1389, -0.7918, -0.3062, 0.0109, -0.7477],\n",
              " 565: [0.7908, 0.9184, 0.276, -0.4648, -0.5355, -0.0934, -0.361, 0.8034],\n",
              " 566: [-1.4745, 0.9608, -1.6647, -0.6034, -0.282, -0.5009, -0.3753, -0.003],\n",
              " 567: [-1.0748, 1.2628, -0.9135, -1.3599, -0.0574, -2.2164, -0.4175, -0.5303],\n",
              " 568: [-1.6938, 1.2867, -1.6021, -0.5734, -0.6138, 0.0933, -0.3454, -1.2291],\n",
              " 569: [1.3847, -1.0972, 1.1752, 0.4753, -0.8356, 0.0431, -0.1396, -0.8557],\n",
              " 570: [1.1791, -1.1855, 0.424, 1.6327, -0.1265, 0.9539, -0.4014, -0.5041],\n",
              " 571: [-0.5684, 0.4361, 1.3744, 1.112, 0.6051, 1.0855, 0.5396, -0.9443],\n",
              " 572: [0.2806, 0.5607, 1.5053, -0.2326, -0.547, 0.4094, 0.0172, 0.4261],\n",
              " 573: [-1.4898, 0.4467, -0.3614, -0.7307, 0.8701, 0.3558, -0.4343, 0.7599],\n",
              " 574: [-0.8349, -1.3098, 1.4541, 0.2618, 0.0406, 0.6004, 1.3356, -0.9888],\n",
              " 575: [1.4723, -0.0832, 1.0159, 1.0896, -0.8967, 0.9049, -0.3815, 0.0011],\n",
              " 576: [-0.0011, -1.3294, -0.4866, 0.6364, 0.6684, 0.5562, -0.3821, -0.8383],\n",
              " 577: [0.726, 1.3079, -0.0427, -1.0715, -0.5585, -1.2724, 0.7572, -1.3648],\n",
              " 578: [0.1283, -0.9364, 1.124, -0.7157, -0.7809, -0.13, -0.3336, -0.1087],\n",
              " 579: [0.7717, -1.23, 0.9078, 1.2169, 1.5325, 1.485, -0.2459, 0.325],\n",
              " 580: [0.8898, -1.3149, 0.885, 1.2731, 0.6339, 1.062, -0.3379, 0.2933],\n",
              " 581: [0.2463, 1.2072, 1.1013, 0.4528, -0.6616, 0.7024, 0.5147, 0.113],\n",
              " 582: [0.0788, -0.7562, -0.185, 0.2955, -0.6323, 0.6497, -0.1116, -1.0386],\n",
              " 583: [-1.0938, 1.2205, -0.7882, -1.1951, -0.6709, -0.8826, -0.3734, -0.7487],\n",
              " 584: [-1.5964, 1.3079, -1.3631, -1.7195, -0.6444, -2.9976, -0.3398, -1.8825],\n",
              " 585: [0.4595, -0.7324, 0.8508, 0.4229, -0.7538, 0.1121, -0.4312, -0.2893],\n",
              " 586: [-1.5583, -0.9735, -0.0427, -0.3936, -0.547, 0.1642, -0.4542, 0.8168],\n",
              " 587: [-0.2372, -0.8887, 1.0956, 0.9248, 0.8297, 1.4169, -0.0618, -0.1305],\n",
              " 588: [-1.0976, -0.3561, 0.3614, -0.8019, 0.0233, -0.1175, -0.43, -1.3028],\n",
              " 589: [1.023, 0.4202, 0.3159, -0.0753, -0.3684, -0.5089, -0.4182, -0.4406],\n",
              " 590: [-0.4428, 1.3079, -0.498, -1.6101, -0.2705, -3.1677, -0.2484, -1.4519],\n",
              " 591: [-0.1077, 0.5898, -0.9248, 0.2019, 0.7376, 0.23, -0.3522, -0.0963],\n",
              " 592: [-1.1357, 0.8468, 0.7996, -0.8243, -0.6277, 0.6216, -0.2272, -1.1736],\n",
              " 593: [0.5433, 0.1261, 0.35, -0.3711, 0.9449, -0.5676, -0.3417, -0.0708],\n",
              " 594: [0.2806, -1.133, 0.185, 1.5765, -0.0343, 1.1691, -0.0481, -0.751],\n",
              " 595: [0.1245, 0.7303, 0.4012, -1.1877, -0.4491, -0.2816, -0.2266, 0.3542],\n",
              " 596: [1.1372, -1.129, 0.7939, -0.3524, -0.57, -0.1858, -0.318, -0.0906],\n",
              " 597: [-0.477, -0.0646, 0.5663, 0.0558, -0.0631, 0.2076, -0.3386, 0.7474],\n",
              " 598: [-0.6065, -1.1335, -0.5264, 1.6701, 0.7952, 1.3996, 1.2796, -0.3074],\n",
              " 599: [-1.7334, -1.2838, -0.7769, 1.3892, -0.57, 0.1665, -0.0201, -0.0305],\n",
              " 600: [-0.6674, 1.3026, -0.3159, -0.5659, -0.5124, -0.6512, -0.435, 0.4406],\n",
              " 601: [-1.5012, 0.513, -1.2891, -0.9292, 4.4531, -0.8102, -0.4238, -1.326],\n",
              " 602: [0.1854, 0.8813, 0.0996, -0.9966, -0.5124, -1.4574, -0.4126, 0.9336],\n",
              " 603: [-1.8321, 1.3052, -1.6533, -1.7637, -0.6991, -3.971, -0.3392, -1.6142],\n",
              " 604: [0.7603, 0.6402, 1.198, -0.2962, -0.6046, -0.0395, -0.1837, -0.8288],\n",
              " 605: [-1.6451, 1.0588, -0.9248, -1.2551, -0.2935, -0.9989, -0.3622, 0.9543],\n",
              " 606: [-1.4784, 0.9449, -2.0972, -1.3637, -0.524, -1.3228, -0.3989, -0.1557],\n",
              " 607: [0.5205, 0.9475, -0.0711, -1.0566, -0.138, -0.0308, -0.361, -0.3422],\n",
              " 608: [0.6423, 0.4123, 1.3346, 0.4079, -0.7498, -0.1667, 2.9339, -1.3401],\n",
              " 609: [0.2044, -0.7244, 0.8679, 1.1383, -0.7215, 1.5009, -0.1806, -0.5523],\n",
              " 610: [-0.321, 0.5315, 0.4638, -0.3075, -0.3742, 0.2307, 1.2983, -1.2593],\n",
              " 611: [0.0674, 0.3275, -0.3329, -0.0715, 2.7422, -0.266, -0.2739, -0.03],\n",
              " 612: [-0.8007, 1.133, -0.5151, -0.4723, 1.7802, -0.6143, -0.3547, 0.0247],\n",
              " 613: [1.2019, -1.2888, 0.8964, 0.5989, -0.3512, -0.1461, -0.443, 0.0224],\n",
              " 614: [-1.2918, 1.2999, -0.9704, -1.3599, -0.5758, -2.4394, -0.2932, 0.2664],\n",
              " 615: [-0.6179, 0.9078, -2.3135, -1.3637, 0.2307, -2.1977, -0.3759, -1.3104],\n",
              " 616: [1.5065, -0.433, 0.0996, -0.1314, 0.2134, -0.2588, -0.3566, 0.0942],\n",
              " 617: [1.0382, 1.1516, 0.3272, -0.8955, -0.547, 0.0056, -0.351, 0.1851],\n",
              " 618: [-1.735, 1.0588, -1.7045, -1.0566, -0.7273, -1.3643, -0.3404, -0.5691],\n",
              " 619: [-0.2486, 0.2454, -1.5907, -0.8768, -0.4376, -0.7809, -0.397, 2.8725],\n",
              " 620: [-1.1966, 0.6667, -0.6118, -0.2475, -0.6645, 0.5118, -0.3809, 0.1564],\n",
              " 621: [-1.1662, 0.9952, -2.2168, -0.6708, -0.3742, -0.12, -0.4107, -1.3181],\n",
              " 622: [-0.043, 1.08, -0.7143, -1.5176, -0.5297, -1.538, -0.412, 1.7618],\n",
              " 623: [0.7146, -1.279, 0.5663, 0.5914, -0.7936, -0.0496, -0.4188, 0.411],\n",
              " 624: [-1.5355, 0.9767, -0.9704, -1.6233, -0.6858, -0.5462, -0.4169, -0.3509],\n",
              " 625: [0.1055, 1.2787, -0.646, -0.9891, -0.2647, -0.0089, -0.3765, -0.0407],\n",
              " 626: [0.9925, 0.3487, 0.8053, 0.348, -0.2302, 0.6029, -0.1663, -0.4697],\n",
              " 627: [-0.2486, 0.9714, 0.2305, -0.6595, 3.9289, -0.7443, -0.3777, -0.94],\n",
              " 628: [0.1245, -1.3178, -0.3159, 1.7375, 1.0429, 0.8727, -0.3784, -0.4338],\n",
              " 629: [1.3047, -1.119, 1.2492, 0.8349, -0.7872, 0.5631, -0.3087, -0.4337],\n",
              " 630: [-1.0596, 1.1834, -1.6533, -1.1053, -0.6081, -0.5225, -0.3833, -0.4106],\n",
              " 631: [1.0344, -0.6158, 1.5224, -0.4386, -1.032, -0.3707, -0.2782, -0.2882],\n",
              " 632: [-0.656, -1.0636, 1.0387, 0.9697, 0.4841, 0.8695, -0.4325, 0.0935],\n",
              " 633: [1.2591, -1.2371, 1.3403, 0.5764, 0.6339, -0.2671, -0.407, 0.1061],\n",
              " 634: [-1.1471, 1.2708, -1.955, -1.6405, -0.0862, -1.4556, -0.4014, -1.0902],\n",
              " 635: [-0.5608, -0.8039, -1.6021, 0.5952, -0.6893, 0.2056, -0.2677, 2.7977],\n",
              " 636: [-1.7475, -1.3293, -2.0745, 1.6626, 0.4956, 1.312, 0.21, 2.74],\n",
              " 637: [-1.4898, -0.6423, -0.4012, -1.1951, -0.547, -1.6648, -0.3678, 0.9366],\n",
              " 638: [0.0217, -0.8145, 0.3443, 0.2918, 0.2076, 0.924, -0.4704, -0.9452],\n",
              " 639: [0.6232, -1.2096, 0.4468, 1.6027, 0.7952, 1.493, -0.3709, 0.8802],\n",
              " 640: [-0.5875, -0.3164, 1.6476, 0.7637, -0.5355, 1.0703, 0.5582, 1.0078],\n",
              " 641: [1.3086, -0.5257, 0.4297, 0.2581, 1.2099, 0.423, -0.4039, 0.4683],\n",
              " 642: [-1.0519, -1.3294, -0.4297, 1.584, -0.6974, 1.3478, -0.3386, 0.1921],\n",
              " 643: [1.5446, -0.523, 0.2476, 1.2169, -0.7694, 0.7427, -0.407, 0.166],\n",
              " 644: [-1.09, -1.3312, -1.3858, 1.8536, 4.165, 1.3642, -0.1563, -0.802],\n",
              " 645: [-1.2766, -1.2779, 0.3386, -0.0078, -0.7239, 0.4156, -0.3889, 0.2589],\n",
              " 646: [0.1245, -1.3197, -0.3329, 1.2731, -0.6951, 0.8902, -0.3348, 0.4234],\n",
              " 647: [1.3009, 1.2973, 1.4883, -0.3786, -0.5989, 0.5171, 0.8132, 0.1039],\n",
              " 648: [1.6055, 0.3037, 0.7256, -0.4461, -0.2244, 0.013, -0.3603, 0.1555],\n",
              " 649: [1.3428, -0.5124, 1.3915, 1.0971, 0.6742, 1.2302, -0.0046, 0.6164],\n",
              " 650: [-1.3489, 0.8468, -1.6078, -0.0528, 0.7721, 0.8871, -0.4138, -0.1742],\n",
              " 651: [-1.4136, 1.1224, -1.6419, -1.5345, -0.8166, -1.1424, -0.3013, 1.7029],\n",
              " 652: [-0.3819, -1.3301, -0.5378, 0.7487, -0.7008, 0.9649, -0.4163, -0.6772],\n",
              " 653: [0.8898, 0.5501, 1.0045, 0.1158, -0.547, -0.3262, -0.4032, 0.2343],\n",
              " 654: [-1.2652, 1.2946, -0.8224, -1.6645, -0.7371, -1.2745, -0.1725, -1.2862],\n",
              " 655: [-1.1319, -1.2954, -0.3728, -0.5472, 0.0406, -0.6622, -0.4536, 1.7827],\n",
              " 656: [-1.3413, 1.2019, -0.2533, -1.5581, -0.57, -1.5718, -0.3467, 0.0815],\n",
              " 657: [0.8479, -0.6423, -0.0199, 0.6588, 0.4784, 0.2495, -0.3653, 0.0569],\n",
              " 658: [1.2362, 0.3328, 0.1793, 0.4379, -0.3281, 0.1549, -0.3429, 2.2581],\n",
              " 659: [0.5281, -1.3034, -0.589, 1.3892, 0.0521, 1.308, -0.3423, 0.6499],\n",
              " 660: [-0.8502, -0.4489, 1.1582, -1.2026, -0.1726, -2.0394, 5.2225, -0.4966],\n",
              " 661: [-1.8755, 1.2893, -2.2054, -1.6982, -0.2935, -2.475, -0.3013, -1.6185],\n",
              " 662: [-1.4136, 1.0827, -1.1354, -1.3375, 0.68, -1.2671, -0.2484, -1.3515],\n",
              " 663: [1.7121, 1.2787, -2.0005, -0.6034, 0.6915, -1.561, -0.3628, 0.6566],\n",
              " 664: [1.419, -0.5177, 0.1622, 1.6851, 0.7894, 0.8131, -0.18, 1.2378],\n",
              " 665: [-0.9872, 1.2734, -1.1866, -1.4704, -0.57, -1.1793, -0.3765, -0.7707],\n",
              " 666: [-0.6408, -1.0424, -0.9248, -0.2026, -0.5758, 0.7178, -0.4306, -1.2529],\n",
              " 667: [-1.1052, 0.7064, -0.9248, -0.9217, 0.8931, -0.4776, -0.4306, -0.2231],\n",
              " 668: [0.2463, 0.6481, -0.3329, -1.4086, 0.6396, -0.3702, -0.0799, 2.8708],\n",
              " 669: [-1.1547, -1.3095, -0.3045, 1.7638, -0.2475, 1.5646, -0.2148, 2.0556],\n",
              " 670: [0.2654, 0.0864, 1.4427, 0.112, -0.4952, -0.3295, -0.1551, -0.5902],\n",
              " 671: [-0.7131, 0.8627, -0.7256, -0.9517, -0.4491, 0.3057, -0.4294, -1.0341],\n",
              " 672: [-0.3133, -1.2954, -0.3102, 0.7937, -0.8857, 0.5512, -0.4051, 0.8292],\n",
              " 673: [0.9507, -0.1945, 0.3671, -0.1015, 2.7941, -0.5964, -0.3379, -0.0914],\n",
              " 674: [1.0725, -0.1441, 0.4012, 0.1457, -0.5758, -0.2278, -0.3205, -0.0481],\n",
              " 675: [-0.9986, 0.4123, -1.0557, -0.3824, -0.6962, -0.3831, -0.3871, -0.7831],\n",
              " 676: [-0.6903, 1.2946, -1.6818, 0.082, -0.5412, 0.524, -0.3709, -1.3707],\n",
              " 677: [0.5509, -0.4965, -0.6517, 0.936, -0.3627, 1.5103, -0.3361, 2.8222],\n",
              " 678: [0.1093, 1.2973, 0.6289, -1.615, -0.6294, -0.413, -0.2689, 0.6288],\n",
              " 679: [-0.9263, -1.3297, -1.4598, 1.3443, 0.3286, 0.7452, -0.1943, 0.0974],\n",
              " 680: [-0.6217, 0.3805, -0.7029, 0.8986, -0.3512, 0.5657, -0.3187, 0.0157],\n",
              " 681: [0.7755, 1.292, -0.2533, -0.8543, 0.7203, -0.9818, -0.4312, -0.5688],\n",
              " 682: [0.3948, -1.0951, 0.1622, 1.7113, -0.2475, 1.3345, 0.1105, -0.5552],\n",
              " 683: [0.8669, 0.301, -0.8224, 0.1532, -0.4548, -0.6288, -0.4207, -0.7776],\n",
              " 684: [0.589, -0.8092, 0.5947, 0.2656, -0.0055, 0.979, -0.3566, 0.1005],\n",
              " 685: [0.3986, 0.3567, 0.0256, -0.1052, 0.0751, 0.4239, 0.3281, -0.407],\n",
              " 686: [1.5751, -0.7642, -0.4069, 1.0708, -0.7244, 0.739, 0.0483, 1.6732],\n",
              " 687: [-1.8267, -0.1547, -1.7501, -0.5434, 1.4576, 0.1506, -0.2969, 0.4458],\n",
              " 688: [0.174, -0.4621, -0.1679, 0.73, -0.8978, 1.0169, -0.203, 0.1596],\n",
              " 689: [-1.09, 1.2734, -0.4638, -1.5697, -0.7918, -2.1015, -0.2745, 0.2759],\n",
              " 690: [0.3986, -0.4038, 0.4183, 1.4791, -0.5873, 1.0178, 1.1304, 1.6105],\n",
              " 691: [0.292, -0.4303, 1.3574, -0.1577, -0.888, -0.7855, -0.2297, 0.2842],\n",
              " 692: [-0.0468, -1.2178, 1.6761, -0.1389, -0.6951, -0.2178, 1.9637, -0.6835],\n",
              " 693: [0.5699, -0.7907, 0.5834, 1.1046, -0.8039, 0.7762, -0.4008, -0.3384],\n",
              " 694: [1.6474, 0.0678, -0.2134, 1.6963, 0.1846, 0.9452, -0.4256, 1.2199],\n",
              " 695: [1.0915, -1.0933, 1.1354, 0.6401, -0.6818, 1.224, -0.31, 1.2054],\n",
              " 696: [-1.3908, 0.8495, -0.5208, 0.2918, -0.1668, -0.7115, 0.8008, 0.5698],\n",
              " 697: [0.5852, -0.3588, 0.2248, 0.73, 1.6592, 0.1978, -0.4586, -0.814],\n",
              " 698: [-0.8806, 1.3026, -0.1337, -1.6648, -0.5758, -2.8671, -0.3753, -0.7979],\n",
              " 699: [-0.0126, -1.3268, 0.1394, 1.554, 1.0026, 1.1608, -0.216, 0.42],\n",
              " 700: [0.6271, 1.3052, 0.7825, -1.3974, -0.5528, -1.4002, -0.2832, -0.0132],\n",
              " 701: [0.5966, 1.1012, 0.3386, -1.2401, -0.1035, -0.7826, -0.3429, 0.4043],\n",
              " 702: [-1.7909, 1.2814, -1.9151, -1.4577, -0.3224, -0.9966, -0.402, -0.9444],\n",
              " 703: [0.5623, -0.8198, -0.2874, -0.2925, -0.6686, 0.0939, -0.4101, -0.0752],\n",
              " 704: [0.8479, 0.9714, 0.4354, 0.0596, -0.5067, 1.3136, -0.2509, 0.0376],\n",
              " 705: [-1.4174, 0.8442, -0.0313, 0.2131, -0.5412, 0.0229, 0.1975, -1.0593],\n",
              " 706: [-0.6979, -1.3064, 1.4655, 0.6851, -0.6184, 0.7555, -0.2503, -0.6022],\n",
              " 707: [-1.7125, 1.2814, 0.9078, -1.697, -0.7504, -1.9446, -0.0519, -0.0239],\n",
              " 708: [-1.7449, 1.2893, -0.2988, -1.0416, 2.3505, -1.494, -0.3168, 0.2723],\n",
              " 709: [1.3162, -0.4091, 0.2646, 0.4379, -0.6144, 0.6472, -0.3075, 0.083],\n",
              " 710: [-0.5151, -1.1518, -0.3045, 0.9735, 0.8009, 0.962, -0.1961, -0.2574],\n",
              " 711: [0.6651, 1.2973, -1.3574, -1.2363, -0.3915, -2.8248, -0.323, -0.5296],\n",
              " 712: [-0.8083, 0.3249, 1.4427, -1.109, -0.85, 0.0139, -0.4039, -0.0964],\n",
              " 713: [0.5357, -1.3292, 0.1281, 1.7862, 0.0233, 1.594, 0.0234, 1.528],\n",
              " 714: [-0.576, 1.2549, -0.8964, -1.1315, -0.5758, -1.3153, -0.3299, 0.5595],\n",
              " 715: [-0.9644, 0.1579, -2.2452, -0.6783, -0.7578, 0.0496, -0.4032, -0.8437],\n",
              " 716: [-0.9149, -1.3274, 0.8793, 0.745, -0.6271, 0.9081, -0.1147, 1.1402],\n",
              " 717: [-0.892, 0.8309, -0.8452, -0.3037, 0.3343, -0.0282, -0.3634, 0.6961],\n",
              " 718: [1.6855, -0.1415, 2.046, 0.6064, -0.38, 0.8858, -0.3411, -0.2293],\n",
              " 719: [1.5103, 0.2109, 1.05, 1.0371, 3.4565, 0.2585, 0.297, 0.1192],\n",
              " 720: [0.155, 0.4335, -0.3557, -0.6708, -0.5355, -0.3439, -0.4163, -1.2306],\n",
              " 721: [-0.1915, 1.0429, 1.4143, -0.476, -0.5412, 0.003, -0.4319, -0.5546],\n",
              " 722: [0.5814, 1.3079, 0.0768, -1.3412, -0.5297, -0.5667, 0.751, -1.5395],\n",
              " 723: [-0.8007, 1.1145, -0.8053, -1.3562, 2.483, -0.8964, -0.3989, 0.2555],\n",
              " 724: [0.9811, -0.0567, 1.6192, 0.363, -0.547, 0.4405, -0.193, -1.0127],\n",
              " 725: [0.4177, 1.2522, -0.3102, -0.3037, 1.3079, 0.1602, -0.3796, -0.7484],\n",
              " 726: [-0.7245, 1.2205, 0.3898, -1.7799, 0.029, -4.6914, -0.3572, -1.2068],\n",
              " 727: [-0.321, 0.7515, 0.7541, -1.0154, 0.5993, -0.7844, -0.1091, -0.1767],\n",
              " 728: [1.4685, -1.0397, 0.0768, 1.7188, 0.3516, 1.262, -0.3243, -1.0898],\n",
              " 729: [-0.0963, -1.3268, -0.4695, 1.4604, -0.017, 0.0792, -0.1414, -0.2693],\n",
              " 730: [1.1106, -0.478, 0.0654, 0.7824, -0.7463, -0.0547, -0.3491, -0.8726],\n",
              " 731: [0.7527, 0.3567, -0.3955, 0.2319, 1.6708, 0.2665, -0.3423, -0.0288],\n",
              " 732: [1.4875, -1.293, -0.6232, 0.4716, 3.0129, -0.4038, -0.2036, 2.3304],\n",
              " 733: [0.1588, -1.2973, -0.646, 1.4304, -0.3224, 1.2227, -0.384, -0.1039],\n",
              " 734: [-1.3832, -0.4436, 0.9191, -0.1614, -0.0516, -2.1738, 2.368, -2.2385],\n",
              " 735: [0.9925, -0.6714, 0.8508, 1.4117, 0.6915, 0.6531, -0.3945, -0.1501],\n",
              " 736: [-1.0215, -1.3264, -0.3899, 1.7825, -0.5643, 1.4261, -0.083, -1.3036],\n",
              " 737: [-0.8235, 1.2628, -0.8224, -1.5371, -0.6421, -1.8652, -0.2677, -0.5814],\n",
              " 738: [0.8288, -0.4939, 1.0159, -0.0453, 0.2998, 0.0928, -0.1831, 0.3111],\n",
              " 739: [1.5598, 0.8654, 0.4183, -0.697, -0.5989, -0.9238, 0.9252, -1.0085],\n",
              " 740: [1.3999, 0.142, 0.1963, 0.4716, 0.6569, 0.1775, 0.3406, 0.6273],\n",
              " 741: [-1.3756, 0.9714, 0.3443, -0.4685, 0.3747, -0.1164, -0.305, -1.3668],\n",
              " 742: [0.4595, 1.1834, 2.1029, -0.7981, -0.3569, -0.5672, -0.3013, 0.0595],\n",
              " 743: [-0.7017, 1.035, 0.7769, -0.5771, -0.6887, -0.0864, -0.3896, -0.2226],\n",
              " 744: [-1.2309, 0.8945, -0.572, -1.4847, -0.6634, -1.182, -0.3721, -1.4272],\n",
              " 745: [-0.5532, 0.77, -0.737, -0.9629, 0.0233, -0.6417, -0.3721, 2.2659],\n",
              " 746: [1.1258, 0.1314, -0.2134, 0.8386, -0.653, 0.9893, -0.3933, 0.8624],\n",
              " 747: [-1.2233, 1.2443, -1.7045, -0.8805, -0.5124, -0.8021, -0.3858, -1.0596],\n",
              " 748: [0.471, 0.5607, 0.9021, -1.3075, -0.547, -1.6607, -0.3703, -0.0184],\n",
              " 749: [-0.4085, -1.2035, -0.0484, 1.0184, -0.5585, 1.4641, 0.5209, -1.2221],\n",
              " 750: [-1.3108, -1.3305, -1.1297, 1.9061, 0.3228, 1.135, 0.2908, -0.3337],\n",
              " 751: [0.9964, 0.4679, 0.6175, -1.0229, -0.7388, -1.0249, -0.2534, 0.0396],\n",
              " 752: [-0.953, 1.2973, -1.1923, -1.6225, 0.0348, -2.6087, -0.3025, -1.7786],\n",
              " 753: [-1.0139, 1.2893, -1.2606, -0.5172, -0.3684, -0.4739, -0.2148, -0.7927],\n",
              " 754: [-1.2385, 0.6243, -0.8395, -0.7682, -0.7728, -0.1833, -0.4281, -0.6176],\n",
              " 755: [-1.1281, 1.1913, -0.2362, -1.6881, -0.5355, -1.2483, -0.1968, -1.7547],\n",
              " 756: [-0.7283, -0.4197, 0.8053, 0.2131, -0.7043, 0.0261, -0.267, -0.7245],\n",
              " 757: [-0.5722, 0.9979, -0.4012, -1.5023, -0.4664, -2.1798, -0.425, -0.7989],\n",
              " 758: [1.0877, -1.2342, 1.4086, 1.1532, -0.6939, 0.8153, -0.2658, -0.8222],\n",
              " 759: [1.6474, 1.2257, 1.3972, -0.8393, -0.0862, -0.6824, -0.0071, -0.6894],\n",
              " 760: [-0.8121, -0.2501, -0.4297, -0.6446, -0.4779, 0.3568, -0.4368, 0.5527],\n",
              " 761: [-0.0506, -1.3089, -1.2322, 1.1832, 0.2191, 0.003, -0.18, 1.7305],\n",
              " 762: [-0.6598, 0.6243, -1.4029, -1.3038, -0.861, -0.3396, -0.4169, -0.7183],\n",
              " 763: [0.174, 1.2973, -0.4581, -1.5997, -0.4318, -1.8678, -0.3641, -1.4814],\n",
              " 764: [0.6271, -0.6688, 1.3232, 0.2543, 0.2825, 0.7633, -0.3149, -0.0912],\n",
              " 765: [-0.0887, 0.982, 1.05, 0.7225, 0.5763, 1.0321, -0.1284, 0.0973],\n",
              " 766: [0.5623, -1.3301, 0.0768, 0.8311, -0.6086, 1.1757, -0.397, 0.1896],\n",
              " 767: [-0.8349, -0.2316, -0.9817, 1.7375, 4.4415, 0.7723, 0.0607, 0.1388],\n",
              " 768: [0.6956, -0.1521, 0.6004, 0.363, -0.5528, 0.4034, -0.2658, 0.4841],\n",
              " 769: [-0.7055, 1.292, -0.7826, -1.1502, -0.7302, -0.2761, -0.3547, -0.1438],\n",
              " 770: [0.3491, 0.5024, -0.9248, -0.5622, -0.5989, -1.176, -0.1489, 2.0121],\n",
              " 771: [0.1435, -1.3309, -0.0825, 1.745, 1.953, 1.2059, 0.1353, 1.0738],\n",
              " 772: [0.0902, -0.9125, -0.885, 0.8536, -0.7717, 0.7518, 0.2037, 1.2578],\n",
              " 773: [1.6436, 0.4255, 1.437, 0.0334, -0.5355, 1.2735, -0.4051, -0.1281],\n",
              " 774: [-1.0139, 1.08, -0.9931, -0.2813, -0.5873, -0.867, -0.4306, 1.973],\n",
              " 775: [-0.8273, 1.2787, -1.2777, -1.4236, -0.5931, -3.286, -0.3398, -1.6089],\n",
              " 776: [1.0687, -0.0037, 0.0313, 0.5727, -0.6305, 0.4384, -0.3927, 1.6717],\n",
              " 777: [-1.2994, 1.292, -0.3557, -1.457, -0.6628, -1.6492, -0.2801, 0.5595],\n",
              " 778: [-0.359, 1.2496, 0.0825, -1.4367, -0.4952, -0.1371, -0.3784, -0.3043],\n",
              " 779: [-0.1077, -1.1823, -1.2549, -0.6446, -0.259, -1.1379, -0.4045, 1.8152],\n",
              " 780: [1.4075, -1.1455, 1.494, 0.76, 0.4207, 0.9912, -0.1271, -0.6519],\n",
              " 781: [-0.1496, 0.9449, 0.646, -0.6483, -0.6778, -0.3094, -0.3995, -1.3445],\n",
              " 782: [-0.6065, -0.2077, 0.6915, -1.3187, -0.3742, -1.7348, 5.291, -1.3349],\n",
              " 783: [-0.6179, 1.3079, -0.9704, -0.727, 0.582, 0.4309, -0.4014, -1.4592],\n",
              " 784: [1.6017, -1.0697, -0.1508, 0.4903, -0.3512, 0.8975, 1.3854, -0.8082],\n",
              " 785: [-0.5075, -1.3153, -0.663, 1.1345, -0.6386, 0.351, -0.0201, 0.0],\n",
              " 786: [-0.1839, -1.3311, -0.5151, 1.6252, 0.8701, 1.0843, -0.3852, -0.5712],\n",
              " 787: [0.2387, -1.0874, 0.1508, 0.4566, -0.657, 0.0774, -0.4001, -0.4495],\n",
              " 788: [0.2083, -0.7509, 1.1468, 1.599, -0.3281, 1.3071, 0.6266, -1.0758],\n",
              " 789: [-1.4593, 1.2734, -1.881, -0.7345, -0.5989, -0.1122, -0.3721, -0.9061],\n",
              " 790: [0.3453, -0.2925, 1.0387, 1.3443, -0.6207, 1.325, -0.3684, -0.8792],\n",
              " 791: [0.9735, 1.2681, 0.202, -1.1652, -0.7475, -0.005, -0.3361, 1.0028],\n",
              " 792: [-0.8578, 1.0721, -0.8338, -1.3787, -0.2532, -0.9003, -0.3815, 0.5497],\n",
              " 793: [-1.0862, 1.2734, 0.0882, -1.5266, -0.6144, -1.4276, -0.3019, 0.8793],\n",
              " 794: [-0.9491, 1.2787, -0.8565, -1.7034, 0.1961, -2.0495, -0.2614, -1.6104],\n",
              " 795: [-1.8477, 1.186, -2.5651, -0.9067, -0.6305, 0.1073, -0.3666, -1.4919],\n",
              " 796: [-0.9149, -0.6211, 0.1565, 0.1195, -0.5816, 0.8961, -0.4343, 0.8119],\n",
              " 797: [-0.6217, -0.7774, 0.8508, -0.2775, -0.3224, -0.2828, -0.407, 0.7633],\n",
              " 798: [-1.7841, -0.7483, -2.4729, -1.4236, -0.3972, -1.6848, -0.3809, -1.0945],\n",
              " 799: [0.4177, 0.5951, -0.2817, 1.4117, -0.2935, 0.5259, -0.3498, -0.473],\n",
              " 800: [-0.26, 1.2708, -0.6517, -1.6704, 0.0463, -1.2103, -0.3827, -0.1123],\n",
              " 801: [1.4646, 1.1728, 1.346, -0.2438, -0.6207, -0.1399, -0.3292, -0.0367],\n",
              " 802: [1.1448, 1.3052, 0.0882, -1.4086, 0.824, -1.8367, 1.6341, -0.9481],\n",
              " 803: [-0.0621, 1.2946, -0.1964, -1.2101, -0.259, -0.717, -0.2944, -1.2341],\n",
              " 804: [-0.8958, 1.0933, -1.3517, -0.9629, -0.2647, 0.0649, -0.4468, -0.9542],\n",
              " 805: [1.6702, -1.1258, 1.0671, 0.4641, -0.2071, 0.3416, -0.4393, -0.7221],\n",
              " 806: [-0.26, 1.1463, -0.5094, -0.7532, -0.2475, 0.0397, -0.3616, 2.2794],\n",
              " 807: [-0.5075, 0.7541, -0.9362, -0.9667, 0.5993, -0.9768, -0.4231, -0.8928],\n",
              " 808: [1.6436, -0.4436, 1.1525, 0.4978, 0.7088, -0.3722, -0.4275, 0.0087],\n",
              " 809: [-0.1458, -1.2997, -0.3728, 0.6851, 0.6627, 0.3351, 1.858, 1.3885],\n",
              " 810: [-1.7963, 1.3026, -0.9419, -1.6229, -0.4548, -2.657, -0.4051, 0.605],\n",
              " 811: [1.1258, 1.2708, 0.6175, -0.3075, -0.6184, 0.2069, -0.2832, -0.2792],\n",
              " 812: [1.4113, -0.425, 1.0102, 1.3368, -0.5816, 1.5467, -0.3193, -0.3239],\n",
              " 813: [0.8403, 0.5183, 0.1793, 0.524, -0.259, 0.6879, -0.4032, -0.3085],\n",
              " 814: [-0.5989, -1.1123, -0.1907, -0.0416, -0.2302, 0.7456, -0.4281, 0.8429],\n",
              " 815: [1.6436, 0.5236, 0.2077, 0.303, -0.3454, 0.8222, -0.129, -0.5108],\n",
              " 816: [-0.7321, -1.288, -0.2476, 1.745, -0.2878, 1.4804, -0.3392, -0.9439],\n",
              " 817: [-1.0443, 1.1622, -1.881, -0.4873, 0.7721, 0.2495, -0.4039, -1.1811],\n",
              " 818: [0.1207, -1.32, -1.1183, 1.5203, 4.3321, -0.1635, -0.2745, 0.8381],\n",
              " 819: [-1.0177, 1.2999, -0.2703, -1.5195, -0.6109, -1.8033, 0.0731, 1.2882],\n",
              " 820: [-1.5812, -0.796, -0.1224, 0.0034, -0.5816, 0.2422, -0.3516, 0.2924],\n",
              " 821: [-0.3857, -0.1441, -0.589, -1.2888, -0.5585, -1.637, -0.1862, -0.57],\n",
              " 822: [-0.9568, -0.6873, -1.5281, 1.363, 4.0383, -0.344, -0.3709, -1.0382],\n",
              " 823: [1.2591, 0.6614, 1.2606, 0.2281, -0.5124, -0.1647, -0.2353, -0.8197],\n",
              " 824: [0.094, 1.3052, -1.2379, -1.3375, -0.57, -1.176, -0.4008, -0.4497],\n",
              " 825: [1.0382, -0.0858, 1.1809, 0.3555, -0.774, 1.1782, -0.425, -1.0406],\n",
              " 826: [-0.6065, 0.7833, 0.4752, -0.7195, -0.2763, -0.4098, -0.448, -1.0759],\n",
              " 827: [-0.4237, 1.3079, -0.3842, -1.4933, -0.5297, -1.5999, -0.1912, -1.4886],\n",
              " 828: [0.3491, -0.8702, -0.4638, 0.1982, -0.3857, 0.6237, 1.9389, -1.172],\n",
              " 829: [-1.0025, 0.3434, 0.5321, -0.4461, -0.6968, -0.5103, -0.402, 0.6945],\n",
              " 830: [-0.3324, -0.531, 0.9647, -1.1502, -0.5528, -1.5475, -0.328, -1.3923],\n",
              " 831: [1.3009, -0.9205, 0.8452, 1.2506, 0.271, 0.9714, -0.4132, -0.1003],\n",
              " 832: [-1.5964, -1.3262, -2.6419, 1.4641, -0.4318, 1.2744, 0.1291, 2.3556],\n",
              " 833: [-0.6674, -1.1447, 0.5492, 0.8611, 2.6385, 0.6085, 0.297, 0.036],\n",
              " 834: [-0.4999, -1.331, -1.2037, 1.4566, -0.2993, 1.0533, -0.3336, -0.8195],\n",
              " 835: [-1.3756, -1.3207, -0.9191, 1.4791, -0.259, 1.3156, -0.2664, -1.3688],\n",
              " 836: [-0.5532, 0.4971, -1.2151, -1.5476, -0.3972, -2.1237, -0.3454, 0.128],\n",
              " 837: [1.1296, -0.3879, 0.2305, 0.3218, -0.5989, 0.0969, -0.4611, -0.6243],\n",
              " 838: [0.1702, 0.1871, -0.7541, 0.6514, -0.4606, 0.076, -0.1563, -1.373],\n",
              " 839: [-1.8614, 1.239, -2.3533, -1.6854, -0.7463, -1.7907, -0.3709, -0.8823],\n",
              " 840: [0.9735, 1.2708, 0.0028, -0.0266, 0.0348, 0.2633, -0.2857, 0.6717],\n",
              " 841: [0.2235, 1.2867, 0.4638, -0.8356, 0.847, -1.6698, 5.0298, -1.3415],\n",
              " 842: [-0.9568, 1.2946, 0.7598, -1.3599, -0.38, -0.7736, -0.2459, -0.9218],\n",
              " 843: [-0.557, 0.7939, -0.4695, 0.1607, 0.1212, 0.3927, 0.3157, -1.0993],\n",
              " 844: [0.8174, 0.7992, 0.0199, 0.1008, -0.725, -0.6486, -0.3846, -0.7177],\n",
              " 845: [0.8365, 0.3408, -0.4069, -0.3487, 0.5187, -0.2439, -0.4536, -0.7936],\n",
              " 846: [1.4228, 0.1579, 0.1508, 1.6551, 1.1408, 1.3902, -0.3964, -0.3579],\n",
              " 847: [1.4685, -0.8675, 0.1281, -0.0828, -0.426, 0.5914, -0.3554, -1.2226],\n",
              " 848: [0.3758, -1.3199, -0.4923, 1.8387, -0.6484, 1.5625, -0.2913, 1.1344],\n",
              " 849: [0.2882, -0.6502, 0.8452, 0.8199, -0.6737, 1.0158, -0.009, 1.8537],\n",
              " 850: [0.7337, 0.3328, 0.1394, 0.8012, -0.1899, 0.678, -0.3641, -0.7556],\n",
              " 851: [1.4723, -0.4489, 0.3443, 0.5315, 0.703, 0.2406, -0.4294, 0.6562],\n",
              " 852: [-0.0963, 0.2825, -0.0085, 0.1457, -0.899, 0.1646, -0.3628, -0.637],\n",
              " 853: [1.4456, 1.2893, -0.1964, -0.7981, 1.8263, -0.9356, 1.2921, 1.8286],\n",
              " 854: [1.6626, -0.0885, 0.6061, 0.8648, -0.9047, 0.6992, -0.3983, 0.7189],\n",
              " 855: [0.0902, 1.3052, -1.6078, -0.6558, -0.4548, -0.7084, -0.4064, 1.604],\n",
              " 856: [-0.7588, -1.3289, 0.2988, -0.6183, -0.7515, -0.6311, -0.42, -0.5601],\n",
              " 857: [0.0674, 1.3079, -0.3728, -1.0903, -0.1668, -1.8104, -0.3255, 0.2779],\n",
              " 858: [0.174, -0.0064, 1.7159, -0.2962, -0.7279, 0.0684, -0.4194, -0.62],\n",
              " 859: [-1.7593, 0.2215, -0.2988, -1.1202, -0.7048, 0.5178, -0.4468, -1.4643],\n",
              " 860: [1.4228, -1.3274, 1.6875, 1.6139, -0.5585, 0.7367, -0.3908, 0.7471],\n",
              " 861: [1.0839, -0.47, -0.1622, 1.539, -0.2935, 0.8161, -0.1738, 0.3111],\n",
              " 862: [-0.892, 0.6296, -1.2606, -0.6933, 0.2364, -0.8281, -0.4244, -0.5166],\n",
              " 863: [-0.9187, 0.1871, 1.5679, -0.9479, -0.7671, -0.8422, -0.1526, -0.0317],\n",
              " 864: [0.5395, -1.3248, -0.2419, 1.378, -0.6565, 0.1172, 0.5582, -1.1802],\n",
              " 865: [-0.6179, -1.331, -1.6875, 1.8087, 0.7145, 1.4636, 0.1913, 1.393],\n",
              " 866: [0.9126, -0.8331, 1.6988, 1.2356, -0.615, 0.7889, 0.7261, -0.8139],\n",
              " 867: [0.6347, 1.2999, -0.9362, -0.5771, 0.4956, -0.5897, -0.31, -1.508],\n",
              " 868: [-1.3375, 0.0069, -0.6858, -0.3262, -0.5297, 0.0053, -0.4306, -0.3638],\n",
              " 869: [-0.4618, -0.4542, -0.3899, 0.0446, -0.6766, 0.345, -0.3379, 0.7072],\n",
              " 870: [0.7793, -1.0344, 0.4752, -0.0153, -0.3915, 0.2665, -0.1489, 0.9685],\n",
              " 871: [1.32, -0.6661, -0.6346, 1.6664, -0.4318, 1.3552, -0.3062, -0.7863],\n",
              " 872: [0.8174, -0.5018, 0.4866, -0.3412, 0.6569, -0.0117, -0.4605, -0.7128],\n",
              " 873: [-1.3565, 1.2681, -1.5224, -1.1352, -0.5182, -0.8201, -0.3815, -1.4842],\n",
              " 874: [0.0864, 1.2602, 0.1736, -0.6071, 0.0866, 0.126, -0.244, -0.019],\n",
              " 875: [-0.6255, -1.33, 0.2874, 1.4416, 0.1097, 1.2928, -0.4188, 0.3561],\n",
              " 876: [1.419, 0.2454, 0.1679, 0.4004, -0.3972, 1.0575, -0.4281, -0.1303],\n",
              " 877: [0.3225, -1.331, -0.2646, 1.8124, 0.5878, 1.2673, -0.2764, -0.3735],\n",
              " 878: [1.1068, 0.1447, 1.5395, 0.097, -0.8477, 0.8872, -0.3566, 0.4548],\n",
              " 879: [0.0141, -1.2011, -1.2151, 1.7712, 0.8182, 0.6097, -0.2758, 2.4478],\n",
              " 880: [0.6194, -0.2236, 0.5321, 0.1345, -0.0286, 0.8963, -0.3566, -0.4716],\n",
              " 881: [1.1563, -1.1362, 0.9021, 1.7263, 2.5809, 1.5004, -0.3429, 0.3898],\n",
              " 882: [0.5052, -0.6529, -0.3443, 1.2956, 0.8816, -0.2676, -0.2571, 1.1471],\n",
              " 883: [0.4595, 1.2549, 1.3972, -1.1127, 1.0602, -1.0141, -0.0842, 0.0582],\n",
              " 884: [0.2425, 1.1701, -1.6192, -1.7603, 3.7503, -2.1588, -0.3653, 0.345],\n",
              " 885: [0.5205, 1.2867, 0.3898, -0.5285, -0.0862, 0.6798, -0.1172, -1.1099],\n",
              " 886: [-0.3971, 1.2257, -0.811, -1.33, -0.7158, -1.0808, -0.397, -0.7998],\n",
              " 887: [1.4075, -1.3283, 0.5606, 1.6064, -0.8039, 0.88, -0.3218, 0.5025],\n",
              " 888: [1.3847, -0.4436, 1.3915, 0.2019, -0.7578, 0.1165, -0.3112, 0.0623],\n",
              " 889: [0.509, -1.324, 1.5509, 0.9285, -0.6565, 0.4078, -0.0998, 0.1989],\n",
              " 890: [1.3504, 1.2973, 0.2646, -0.6708, -0.6098, -0.7319, -0.2509, -0.193],\n",
              " 891: [-0.4694, -0.2316, 0.663, 0.2206, 0.7664, 0.2635, -0.4661, -0.4043],\n",
              " 892: [0.8936, -1.2872, 1.7102, -0.0341, 0.2767, 0.064, -0.0233, -0.2646],\n",
              " 893: [-0.5342, -0.5442, -0.9248, -0.1464, 0.2422, 0.1306, -0.3566, 1.5588],\n",
              " 894: [1.4875, 1.2178, 0.2533, -0.3187, 3.4853, -1.1364, -0.4014, -0.4343],\n",
              " 895: [0.6689, -1.1362, 0.959, -1.0004, 0.6742, -1.2876, 5.291, -1.6051],\n",
              " 896: [-0.2943, 0.7409, 0.1679, -0.3524, 0.2479, 0.3301, -0.3721, -0.0215],\n",
              " 897: [0.5814, 0.0148, -0.3216, 0.8686, 1.0659, 0.5574, -0.1514, 0.9212],\n",
              " 898: [0.7565, 1.2046, -0.2248, -0.0603, 0.8873, 0.3996, -0.3865, 0.3162],\n",
              " 899: [-0.9491, -1.3302, -1.0671, -0.3262, -0.1899, -0.6744, -0.4151, -0.7381],\n",
              " 900: [0.9659, -0.0382, 1.6761, 0.6476, -0.5873, 0.9286, -0.1906, -0.7166],\n",
              " 901: [-1.3223, 0.2639, -0.663, -0.4198, -0.6133, 0.614, -0.4275, 0.242],\n",
              " 902: [-1.3185, -1.3082, -1.4484, 0.2581, -0.2417, -0.2942, -0.3342, -0.4413],\n",
              " 903: [0.8821, 1.2257, 0.9704, -0.4873, 3.0706, 0.5427, 2.7536, -0.2406],\n",
              " 904: [-1.6268, -1.3187, -0.5151, 1.1195, -0.6184, 1.1752, -0.4157, -0.6839],\n",
              " 905: [-0.8464, 1.2681, 0.2248, -1.1277, -0.5528, -0.4295, -0.208, -1.2589],\n",
              " 906: [1.5256, 1.3052, -0.0768, -0.4049, 0.7318, 0.3015, 0.5458, 0.42],\n",
              " 907: [-0.991, 0.8044, -1.3118, -0.3674, -0.5355, 0.163, -0.4244, 0.0921],\n",
              " 908: [1.1715, 0.3567, 1.1468, 0.4379, 1.0429, 0.7781, -0.4381, -0.5275],\n",
              " 909: [-0.1534, 0.921, -0.2134, -0.7494, 1.4173, -0.1638, -0.4449, -0.4286],\n",
              " 910: [0.8783, -1.3281, -0.959, 1.4454, -0.6616, 1.1736, -0.259, 1.5943],\n",
              " 911: [1.6436, 0.4759, 0.9078, 0.2394, -0.9019, 0.5291, -0.4356, -0.1758],\n",
              " 912: [-1.8248, -1.2438, -0.1622, 1.4716, -0.7112, 0.8266, -0.3093, 0.5678],\n",
              " 913: [1.4646, -0.4833, 1.2606, 0.363, 0.5878, 0.9154, -0.3777, -0.3244],\n",
              " 914: [0.4671, -0.7827, 0.8793, 1.1158, 0.582, 0.9042, 1.8829, -0.9121],\n",
              " 915: [-0.8159, 0.6375, 0.589, -0.2738, -0.5009, -0.178, -0.3945, 0.1348],\n",
              " 916: [-0.7436, 1.1436, -0.4297, -0.9554, -0.3512, -0.1214, -0.3672, -0.3043],\n",
              " 917: [0.0484, -1.3106, -0.9078, 1.5428, -0.0343, 1.3435, 0.5396, -0.3132],\n",
              " 918: [1.24, 0.8733, -0.5037, 0.2955, 1.0314, 0.5701, -0.4057, 0.3851],\n",
              " 919: [-0.2258, 1.0403, 0.3557, -1.0753, 0.6166, -0.7338, -0.4113, -1.0819],\n",
              " 920: [-1.5164, 1.1489, -1.9493, -1.1652, -0.3051, -1.1728, -0.3858, 0.8313],\n",
              " 921: [1.4989, -1.2811, 0.7313, 1.1158, -0.8149, 0.9902, -0.3124, 1.205],\n",
              " 922: [-1.2499, 1.2999, -0.6061, -1.7154, -0.5758, -2.4087, -0.3547, -0.6376],\n",
              " 923: [-0.1496, -1.1836, 1.0899, -1.5262, -0.5816, -1.9271, 5.1417, -1.7404],\n",
              " 924: [0.0864, -1.3209, 0.9419, 1.3255, -0.259, 1.2073, -0.435, 0.4218],\n",
              " 925: [-1.3108, -1.3311, -1.511, 1.2656, -0.5009, 1.1179, -0.0568, 0.3505],\n",
              " 926: [1.6512, -0.0302, 1.5964, 1.4978, -1.0315, 1.0774, -0.2739, 0.515],\n",
              " 927: [1.3657, -1.1086, 1.4541, 0.745, 1.8839, -0.0577, -0.0979, -0.3182],\n",
              " 928: [1.1486, -0.1653, 0.0598, -0.2288, 0.9104, 0.139, -0.3858, 0.9031],\n",
              " 929: [-1.2004, 1.2416, -1.8354, -1.315, -0.1207, -1.2676, -0.346, -0.7113],\n",
              " 930: [-0.8045, 0.6614, -0.111, -1.5045, -0.6421, -1.6728, -0.3411, 0.5424],\n",
              " 931: [-0.7398, -1.1219, 2.3704, -0.4723, -0.6507, -1.1548, 0.8567, -0.2268],\n",
              " 932: [-0.4961, -0.1574, 0.0313, -1.0154, 1.0659, -1.0817, -0.254, -0.7722],\n",
              " 933: [0.3567, 0.8124, 0.4468, -0.9255, 0.4323, -1.249, 5.3905, -1.4677],\n",
              " 934: [0.6575, -1.2673, 1.2891, 0.7899, -0.0458, 0.4702, -0.3771, 0.3017],\n",
              " 935: [-0.3019, 1.3052, -0.589, -0.727, -0.5412, -0.9342, -0.3684, -1.1511],\n",
              " 936: [-0.9377, 1.0694, -0.3443, -0.5771, 0.3286, 0.5284, -0.2017, 1.8586],\n",
              " 937: [-0.6941, -0.2634, -0.1793, -0.27, -0.115, 0.7491, -0.453, -1.3046],\n",
              " 938: [0.787, -0.4621, 0.4866, -0.0828, 0.6396, -0.3978, 0.9065, -0.2077],\n",
              " 939: [0.41, -1.0318, 1.0899, -1.2738, -0.0228, -1.3794, 4.9862, -0.561],\n",
              " 940: [-0.6293, -1.1987, -1.1923, 0.0596, 0.4784, 0.1023, -0.4275, 0.7217],\n",
              " 941: [-0.1458, 1.2999, 0.2703, -0.9517, 0.9968, -0.384, -0.3429, -0.0943],\n",
              " 942: [0.3872, -0.3508, 1.1525, -0.2438, -0.5124, -0.3414, -0.4393, -0.4276],\n",
              " 943: [-1.09, 1.0482, -1.0785, -0.3899, -0.5412, 0.1064, -0.3784, -0.0168],\n",
              " 944: [1.6588, 0.4865, 0.6858, 0.8386, -0.2244, 0.4191, -0.3908, 0.7865],\n",
              " 945: [1.2514, -1.2292, 0.3329, 1.7038, -0.2071, 1.0846, 1.8269, 1.5074],\n",
              " 946: [0.5014, -0.6794, 1.42, 1.6402, -0.1553, 1.082, -0.0425, 0.0177],\n",
              " 947: [1.1753, 0.9687, 0.3728, -1.1727, -0.3454, -0.5702, -0.3156, 0.1932],\n",
              " 948: [-0.774, -1.3275, -1.5736, 1.805, -0.1265, 0.8474, -0.2142, 1.4928],\n",
              " 949: [-1.2157, 0.6932, -0.6972, -0.7045, -0.5297, -0.0213, -0.4188, -0.6112],\n",
              " 950: [0.0217, 0.7992, -0.1053, -0.5135, -0.755, 0.3427, -0.3709, 0.5306],\n",
              " 951: [0.4633, 0.1791, 1.0443, -0.7382, -0.57, -0.9011, -0.3392, -1.2069],\n",
              " 952: [-1.1091, 0.6587, 0.8907, 0.3292, 0.4553, 0.6326, -0.4095, 0.426],\n",
              " 953: [-0.2943, 1.3052, -1.4598, -0.5509, -0.524, -0.2599, -0.3771, -0.2089],\n",
              " 954: [-0.9986, 0.2984, -0.811, -0.6858, -0.1495, -0.1359, -0.4449, 1.8624],\n",
              " 955: [0.1968, 0.7647, -0.2134, 0.3555, 2.6788, -0.19, 3.1205, -2.0526],\n",
              " 956: [0.3111, 0.6693, -0.7086, 0.0708, 1.7111, 0.71, -0.3212, -0.7665],\n",
              " 957: [-0.4085, -1.1878, 1.6362, 0.4266, 0.0002, 0.3303, -0.2322, -0.6519],\n",
              " 958: [-1.3375, 1.08, -0.9362, -1.0229, 0.8182, 0.2072, -0.4175, 0.9281],\n",
              " 959: [0.7413, -1.3099, -0.3955, 0.2206, -0.5873, 0.3908, -0.4039, -0.4365],\n",
              " 960: [1.4608, -0.7271, 0.7655, 0.9323, -0.7999, 0.4695, -0.4356, 0.5647],\n",
              " 961: [-1.4441, -0.6926, -0.572, -0.4873, -0.4145, -0.448, -0.3883, 0.0362],\n",
              " 962: [-1.7776, 1.2999, -1.5736, -1.7027, -0.63, -3.014, -0.3572, 0.7094],\n",
              " 963: [0.5243, 0.3779, -1.2435, -0.5809, -0.5067, -0.5515, -0.4306, -0.5519],\n",
              " 964: [-0.4999, 1.3052, -0.498, -1.2289, 0.9161, 0.0412, -0.2316, 0.5716],\n",
              " 965: [-1.8709, 1.2681, -1.3061, -1.2176, -0.2129, -1.1622, -0.2975, -1.3176],\n",
              " 966: [-1.6002, -0.4647, -1.0614, -0.506, 4.3148, -0.4786, -0.3037, 0.7674],\n",
              " 967: [0.3301, 1.186, 0.3955, -1.5498, -0.4203, -0.7563, 0.3157, 1.7542],\n",
              " 968: [-0.3476, 0.8866, 0.6972, -0.6858, -0.4779, -0.4776, -0.3541, 0.0235],\n",
              " 969: [-0.7588, 0.2507, 0.4012, -0.4198, -0.6121, -0.6383, -0.3995, -0.1454],\n",
              " 970: [-0.0963, -0.8198, 0.1565, 0.6326, -0.8235, 0.5013, -0.4623, -0.8133],\n",
              " 971: [0.2996, -0.8808, 0.4012, 0.5989, -0.2244, 0.6133, -0.4549, -0.954],\n",
              " 972: [0.7984, -0.4515, 0.9931, -1.2476, 1.3309, -1.064, 5.1604, -1.137],\n",
              " 973: [-0.359, -0.4992, -0.4923, 1.3106, -0.7648, 1.0743, -0.3442, 1.2716],\n",
              " 974: [-0.5265, -1.3218, 0.8281, 0.7075, 0.7664, 1.1902, -0.055, 0.3592],\n",
              " 975: [1.655, -0.478, 0.6004, 0.9622, -0.8408, 0.1505, -0.3995, 0.5335],\n",
              " 976: [0.8441, -0.7032, 1.3061, 0.0521, -0.6893, 0.0083, -0.42, -0.1982],\n",
              " 977: [-0.9073, 0.9025, -0.737, -1.0715, -0.0343, -0.1493, -0.4393, -1.3607],\n",
              " 978: [1.636, -1.3105, 2.1712, 1.3705, 0.7664, 0.1653, 0.4152, -0.2551],\n",
              " 979: [-0.755, 1.2125, -1.033, -1.6832, -0.6847, -0.4671, -0.3529, -1.0162],\n",
              " 980: [0.4824, -1.0397, 1.1354, 1.4154, -0.85, 1.5552, -0.2415, -0.7495],\n",
              " 981: [-0.7892, 1.0959, -0.6573, -1.7221, -0.6634, -2.1699, -0.351, 0.4166],\n",
              " 982: [-0.538, 0.2613, 0.8736, -0.9405, 0.847, -1.2549, 5.3656, -1.281],\n",
              " 983: [-1.524, 1.2681, -0.35, -1.554, -0.282, -1.8723, -0.3659, -0.0544],\n",
              " 984: [1.6436, 0.4361, 0.6004, 0.4491, 0.4092, 0.383, -0.3386, -1.0817],\n",
              " 985: [1.2895, -0.9576, 1.3346, 1.0446, -0.7123, 0.5615, -0.3883, 0.0988],\n",
              " 986: [0.2958, -0.478, 0.6289, -0.3, -0.6703, -0.6237, -0.4611, -0.4666],\n",
              " 987: [-1.1509, 1.2708, -1.6306, -1.5521, 0.559, -2.4331, -0.3423, 0.2837],\n",
              " 988: [-1.2918, 0.7886, -1.2208, -0.1539, 0.3689, -0.0931, -0.1377, -1.1684],\n",
              " 989: [-1.0634, 0.8389, 0.2419, -1.4952, -0.6927, -0.624, -0.2664, 2.0081],\n",
              " 990: [0.7755, -1.3284, 0.5549, 1.0334, 0.1961, 0.7557, -0.0201, 1.2371],\n",
              " 991: [1.24, -0.5628, 2.4273, 0.2693, -0.6559, 0.2177, -0.2391, 0.0358],\n",
              " 992: [-1.7228, 1.3026, -1.6249, -1.4697, -0.2705, -2.2605, -0.3547, -1.5487],\n",
              " 993: [-0.9415, -1.1195, 1.0216, 0.1532, 0.006, 0.8736, -0.231, 0.3262],\n",
              " 994: [0.3986, 0.089, 1.3631, 0.6738, 2.2353, 0.5399, 1.0682, -0.1917],\n",
              " 995: [-0.576, 0.1685, -0.6175, -0.0378, -0.3051, -0.289, -0.3952, 0.9917],\n",
              " 996: [-0.9872, 0.8044, -0.9305, 0.082, 3.1973, 0.5374, -0.3672, -0.2602],\n",
              " 997: [1.2514, -1.1688, 0.6801, 1.7525, -0.6196, 1.2296, -0.3323, -0.0888],\n",
              " 998: [0.7413, 0.7859, -0.1167, -0.7007, -0.6156, -0.065, -0.4406, 1.2501],\n",
              " 999: [1.5827, 0.3884, 0.7143, 1.0296, -0.7555, 1.0179, 0.6018, 1.5453],\n",
              " 1000: [1.2629, -1.3225, 0.5037, 0.9547, -0.259, 0.11, -0.4014, 0.4828],\n",
              " ...}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get feature data dict: {id: feature_data}\n",
        "feature_data = feature_data_filter.set_index('id').T.to_dict('list')\n",
        "feature_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGONtAQX7ajp"
      },
      "outputs": [],
      "source": [
        "# convert item id to 0 -> n\n",
        "num_items = dataset_filter['ItemId'].unique().shape[0]\n",
        "\n",
        "sorted_list = np.sort(dataset_filter['ItemId'].unique())\n",
        "sorted_list\n",
        "\n",
        "dataset_filter['ItemId'] = dataset_filter['ItemId'].apply(lambda x: np.where(sorted_list == x)[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTeU0lJh9qhl"
      },
      "source": [
        "# Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cMipwjA5BAc"
      },
      "outputs": [],
      "source": [
        "def load_data(root='', valid_portion=0.1, maxlen=19, sort_by_len=False, train_set=None, test_set=None):\n",
        "    \"\"\"Load dataset từ root\n",
        "    root: folder dữ liệu train, trong trường hợp train_set, test_set tồn tại thì không sử dụng train_set và test_set\n",
        "    valid_portion: tỷ lệ phân chia dữ liệu validation/train\n",
        "    maxlen: độ dài lớn nhất của sequence\n",
        "    sort_by_len: có sort theo chiều dài các session trước khi chia hay không?\n",
        "    train_set: training dataset\n",
        "    test_set:  test dataset\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the dataset\n",
        "    if train_set is None and test_set is None:\n",
        "        path_train_data = os.path.join(root, 'train.pkl')\n",
        "        path_test_data = os.path.join(root, 'test.pkl')\n",
        "        with open(path_train_data, 'rb') as f1:\n",
        "            train_set = pickle.load(f1)\n",
        "\n",
        "        with open(path_test_data, 'rb') as f2:\n",
        "            test_set = pickle.load(f2)\n",
        "\n",
        "    if maxlen:\n",
        "        new_train_set_x = []\n",
        "        new_train_set_y = []\n",
        "        # Lọc dữ liệu sequence đến maxlen\n",
        "        for x, y in zip(train_set[0], train_set[1]): # x = [214652220], y = 214840483\n",
        "            if len(x) < maxlen:\n",
        "                new_train_set_x.append(x)\n",
        "                new_train_set_y.append(y)\n",
        "            else:\n",
        "                new_train_set_x.append(x[:maxlen])\n",
        "                new_train_set_y.append(y)\n",
        "        train_set = (new_train_set_x, new_train_set_y)\n",
        "        del new_train_set_x, new_train_set_y\n",
        "\n",
        "        new_test_set_x = []\n",
        "        new_test_set_y = []\n",
        "        for xx, yy in zip(test_set[0], test_set[1]):\n",
        "            if len(xx) < maxlen:\n",
        "                new_test_set_x.append(xx)\n",
        "                new_test_set_y.append(yy)\n",
        "            else:\n",
        "                new_test_set_x.append(xx[:maxlen])\n",
        "                new_test_set_y.append(yy)\n",
        "        test_set = (new_test_set_x, new_test_set_y)\n",
        "        del new_test_set_x, new_test_set_y\n",
        "\n",
        "    # phân chia tập train thành train và validation\n",
        "    train_set_x, train_set_y = train_set\n",
        "    n_samples = len(train_set_x)\n",
        "    sidx = np.arange(n_samples, dtype='int32')\n",
        "    np.random.shuffle(sidx)\n",
        "    n_train = int(np.round(n_samples * (1. - valid_portion)))\n",
        "    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n",
        "    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n",
        "    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n",
        "    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n",
        "\n",
        "    (test_set_x, test_set_y) = test_set\n",
        "\n",
        "    # Trả về indices thứ tự độ dài của mỗi phần tử trong seq\n",
        "    def len_argsort(seq):\n",
        "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
        "    '''\n",
        "        len_argsort([[1, 2, 3, 4], [1], [1, 2, 3, 4, 5, 6]])\n",
        "        ==> [1, 0, 2]\n",
        "    '''\n",
        "\n",
        "    # Sắp xếp session theo độ dài tăng dần\n",
        "    if sort_by_len:\n",
        "        sorted_index = len_argsort(test_set_x)\n",
        "        test_set_x = [test_set_x[i] for i in sorted_index]\n",
        "        test_set_y = [test_set_y[i] for i in sorted_index]\n",
        "\n",
        "        sorted_index = len_argsort(valid_set_x)\n",
        "        valid_set_x = [valid_set_x[i] for i in sorted_index]\n",
        "        valid_set_y = [valid_set_y[i] for i in sorted_index]\n",
        "\n",
        "    train = (train_set_x, train_set_y)\n",
        "    valid = (valid_set_x, valid_set_y)\n",
        "    test = (test_set_x, test_set_y)\n",
        "    return train, valid, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmCF6GX6sHiP"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class RecSysDataset(Dataset):\n",
        "    \"\"\"define the pytorch Dataset class for yoochoose and diginetica datasets.\n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        print('-'*50)\n",
        "        print('Dataset info:')\n",
        "        print('Number of sessions: {}'.format(len(data[0])))\n",
        "        print('-'*50)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        session_items = self.data[0][index]\n",
        "        target_item = self.data[1][index]\n",
        "        return session_items, target_item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm6Tz941201n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(data):\n",
        "    \"\"\"\n",
        "    Hàm số này sẽ được sử dụng để pad session về max length\n",
        "    Args:\n",
        "      data: batch truyền vào\n",
        "    return:\n",
        "      batch data đã được pad length có shape maxlen x batch_size\n",
        "    \"\"\"\n",
        "    # Sort batch theo độ dài của input_sequence từ cao xuống thấp\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    lens = [len(sess) for sess, label in data]\n",
        "    labels = []\n",
        "    # Padding batch size\n",
        "    # padded_sesss = torch.zeros(len(data), max(lens)).long()\n",
        "    # for i, (sess, label) in enumerate(data):\n",
        "    #     padded_sesss[i,:lens[i]] = torch.LongTensor(sess)\n",
        "    #     labels.append(label)\n",
        "\n",
        "    # print(padded_sesss)\n",
        "    inputs = []\n",
        "    for s, l in data:\n",
        "      inputs.append(torch.LongTensor(s))\n",
        "      labels.append(l)\n",
        "    padded_sesss = pad_sequence(inputs)\n",
        "\n",
        "\n",
        "    # Transpose dữ liệu từ batch_size x maxlen --> maxlen x batch_size\n",
        "    # padded_sesss = padded_sesss.transpose(0,1)\n",
        "    return padded_sesss, torch.tensor(labels).long(), lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJkYfgVGJBWR"
      },
      "outputs": [],
      "source": [
        "def add_dense_feature(input_seq, embeddings, num_features):\n",
        "  \"\"\"\n",
        "  input_seq: (maxlen x batch_size)\n",
        "  embeddings:  embeddings to add dense feature ==> (max_length , batch_size , hidden_size)\n",
        "  \"\"\"\n",
        "\n",
        "  input_expand = input_seq.view(-1, 1).expand(-1, num_features).clone().float()\n",
        "  # print(\"input_expand = \", input_expand)\n",
        "  for i, input_item in enumerate(input_seq.flatten()):\n",
        "    if input_item.item() == 0:\n",
        "        # print(\"input_item = \", input_item)\n",
        "        # print(type(input_item.item()))\n",
        "        continue\n",
        "    input_expand[i] = torch.tensor(feature_data.get(input_item.item(), [0]*num_features))\n",
        "    # print(\"get feature:\", input_expand[i])\n",
        "\n",
        "  input_expand = input_expand.view(input_seq.shape[0], input_seq.shape[1], num_features)\n",
        "  outputs = torch.cat((input_expand, embeddings), 2)\n",
        "  new_hidden_size = embeddings.shape[2] + num_features\n",
        "\n",
        "  return outputs, new_hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coyR7f1BdCFk"
      },
      "outputs": [],
      "source": [
        "# item_embs = self.embedding(item_indices) # n_items x embedding_dim\n",
        "# # reduce dimension by bi-linear projection\n",
        "# B = self.b(item_embs).permute(1, 0) # (2*hidden_size) x n_items\n",
        "# scores = torch.matmul(c_t, B) # batch_size x n_items\n",
        "# # scores = self.sf(scores)\n",
        "# return scores\n",
        "\n",
        "i_seq = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 92737])\n",
        "\n",
        "i_seq=i_seq.unsqueeze(1)\n",
        "print(i_seq)\n",
        "print(i_seq.shape)\n",
        "\n",
        "embed = torch.ones(10, 1, 1)\n",
        "print(embed)\n",
        "print(\"---------\")\n",
        "o, n = add_dense_feature(i_seq, embed, 8)\n",
        "print(o)\n",
        "print(o.dtype)\n",
        "print(o.shape)\n",
        "print(n)\n",
        "\n",
        "print(o.squeeze(1)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-CGEnB4llMW",
        "outputId": "008eea96-be29-4c48-cfd7-4585b9fdee77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------\n",
            "input_seq: tensor([[1, 1],\n",
            "        [2, 0],\n",
            "        [3, 0]])\n",
            "torch.Size([3, 2])\n",
            "input_seq.view(-1, 1):  tensor([[1],\n",
            "        [1],\n",
            "        [2],\n",
            "        [0],\n",
            "        [3],\n",
            "        [0]])\n",
            "torch.Size([6, 1])\n",
            "---------\n",
            "x1: tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [0, 0, 0],\n",
            "        [3, 3, 3],\n",
            "        [0, 0, 0]])\n",
            "x1: torch.Size([6, 3])\n",
            "for loopp -------\n",
            "x1 after: tensor([[  44,   55,   66],\n",
            "        [  44,   55,   66],\n",
            "        [  34,  445,  665],\n",
            "        [   0,    0,    0],\n",
            "        [1278,   93,   30],\n",
            "        [   0,    0,    0]])\n",
            "x1 after: torch.Size([6, 3])\n",
            "---------\n",
            "x1 after: tensor([[[  44,   55,   66],\n",
            "         [  44,   55,   66]],\n",
            "\n",
            "        [[  34,  445,  665],\n",
            "         [   0,    0,    0]],\n",
            "\n",
            "        [[1278,   93,   30],\n",
            "         [   0,    0,    0]]])\n",
            "torch.Size([3, 2, 3])\n",
            "x1 after cat: tensor([[[  44,   55,   66,  989],\n",
            "         [  44,   55,   66,  888]],\n",
            "\n",
            "        [[  34,  445,  665,  344],\n",
            "         [   0,    0,    0,   33]],\n",
            "\n",
            "        [[1278,   93,   30, 1278],\n",
            "         [   0,    0,    0,    0]]])\n",
            "torch.Size([3, 2, 4])\n",
            "tensor([[[  44,   55,   66,  989],\n",
            "         [  34,  445,  665,  344],\n",
            "         [1278,   93,   30, 1278]],\n",
            "\n",
            "        [[  44,   55,   66,  888],\n",
            "         [   0,    0,    0,   33],\n",
            "         [   0,    0,    0,    0]]])\n"
          ]
        }
      ],
      "source": [
        "data =  [ [[1, 2, 3], [1]], [[1], [3]] ]\n",
        "\n",
        "feature_data={\n",
        "    1: [44, 55, 66],\n",
        "    2: [34, 445, 665],\n",
        "    3: [1278, 93, 30],\n",
        "    4: [22222, 933, 930],\n",
        "    5: [777, 983, 8830],\n",
        "}\n",
        "\n",
        "# print(data)\n",
        "# data.sort(key=lambda x: len(x[0]), reverse=False)\n",
        "\n",
        "# print(data)\n",
        "print(\"---------\")\n",
        "x = collate_fn(data)\n",
        "input_seq = x[0]\n",
        "print(\"input_seq:\",input_seq)\n",
        "print(input_seq.shape)\n",
        "print(\"input_seq.view(-1, 1): \",input_seq.view(-1, 1))\n",
        "print(input_seq.view(-1, 1).shape)\n",
        "print(\"---------\")\n",
        "\n",
        "x1 = input_seq.view(-1, 1).expand(-1, 3).clone()\n",
        "print(\"x1:\", x1)\n",
        "print(\"x1:\", x1.shape)\n",
        "\n",
        "print(\"for loopp -------\")\n",
        "for i, xx1 in enumerate(input_seq.flatten()):\n",
        "    if xx1 == 0:\n",
        "        continue\n",
        "    x1[i] = torch.tensor(feature_data[xx1.item()])\n",
        "\n",
        "print(\"x1 after:\", x1)\n",
        "print(\"x1 after:\", x1.shape)\n",
        "\n",
        "print(\"---------\")\n",
        "x1 = x1.view(3,2, 3)\n",
        "x2 = torch.tensor([[[  989],\n",
        "         [  888]],\n",
        "\n",
        "        [[  344],\n",
        "         [   33]],\n",
        "\n",
        "        [[1278],\n",
        "         [   0]]]\n",
        ")\n",
        "print(\"x1 after:\", x1)\n",
        "print(x1.shape)\n",
        "\n",
        "\n",
        "x1 = torch.cat((x1, x2), 2)\n",
        "print(\"x1 after cat:\", x1)\n",
        "print(x1.shape)\n",
        "\n",
        "print(x1.permute(1,0,2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-zPSwJgngzt"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfWNw2kwnisp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcAZf6B8-4Xa"
      },
      "outputs": [],
      "source": [
        "class NARM(nn.Module):\n",
        "    def __init__(self, hidden_size, n_items, embedding_dim, n_layers=1, dropout=0.25):\n",
        "        super(NARM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_items = n_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(self.n_items, self.embedding_dim, padding_idx = 0)\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        # set bidirectional = True for bidirectional\n",
        "        self.gru = nn.GRU(input_size = hidden_size, # number of expected feature of input x\n",
        "                          hidden_size = hidden_size, # number of expected feature of hidden state\n",
        "                          num_layers = n_layers, # number of GRU layers\n",
        "                          dropout=(0 if n_layers == 1 else dropout), # dropout probability apply in encoder network\n",
        "                          bidirectional=True # one or two directions.\n",
        "                         )\n",
        "        self.emb_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_size, self.n_layers)\n",
        "        self.a_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "        self.a_2 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "        self.v_t = nn.Linear(self.hidden_size, 1, bias=False)\n",
        "        self.ct_dropout = nn.Dropout(0.5)\n",
        "        self.b = nn.Linear(self.embedding_dim, 2 * self.hidden_size, bias=False)\n",
        "        self.sf = nn.Softmax()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        \"\"\"\n",
        "        input_seq: Batch input_sequence. Shape: max_len x batch_size\n",
        "        input_lengths: Batch input lengths. Shape: batch_size\n",
        "        \"\"\"\n",
        "        # Step 1: Convert sequence indexes to embeddings\n",
        "        # shape: (max_length , batch_size , hidden_size)\n",
        "        embedded = self.embedding(input_seq)\n",
        "        print(\"embedded :\", embedded.shape)\n",
        "        print(embedded)\n",
        "        # Pack padded batch of sequences for RNN module. Padding zero when length less than max_length of input_lengths.\n",
        "        # shape: (total_lengths , hidden_size)\n",
        "        packed = pack_padded_sequence(embedded, input_lengths)\n",
        "        print(\"packed :\", packed.data.shape)\n",
        "        print(\"packed :\", packed.batch_sizes)\n",
        "\n",
        "\n",
        "        # Step 2: Forward packed through GRU\n",
        "        # outputs is output of final GRU layer\n",
        "        # hidden is concatenate of all hidden states corresponding with each time step.\n",
        "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
        "        # hidden shape: (n_layers x num_directions , batch_size , hidden_size)\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        print(\"outputs :\", outputs.data.shape)\n",
        "        print(\"hidden :\", hidden.shape)\n",
        "\n",
        "        # Unpack padding. Revert of pack_padded_sequence\n",
        "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
        "        outputs, length = pad_packed_sequence(outputs)\n",
        "        print(\"outputs :\", outputs.shape)\n",
        "        print(\"length :\", length)\n",
        "\n",
        "        # Step 3: Global Encoder & Local Encoder\n",
        "        # num_directions = 1 -->\n",
        "        # outputs shape:(max_length , batch_size , hidden_size)\n",
        "        # hidden shape: (n_layers , batch_size , hidden_size)\n",
        "        # lấy hidden state tại time step cuối cùng\n",
        "        ht = hidden[-1] # (batch_size, hidden_size)\n",
        "        print(\"ht :\", ht.shape)\n",
        "        # reshape outputs\n",
        "        outputs = outputs.permute(1, 0, 2) # [batch_size, max_length, hidden_size]\n",
        "        c_global = ht\n",
        "        # Flatten outputs thành shape: [batch_size * max_length, hidden_size]\n",
        "        gru_output_flatten = outputs.contiguous().view(-1, self.hidden_size)\n",
        "        # Thực hiện một phép chiếu linear projection để tạo các latent variable có shape [batch_size, max_length, hidden_size]\n",
        "        q1 = self.a_1(gru_output_flatten).view(outputs.size())\n",
        "        print(\"q1:\", q1)\n",
        "        # Thực hiện một phép chiếu linear projection để tạo các latent variable có shape [batch_size, max_length, hidden_size]\n",
        "        q2 = self.a_2(ht) # (batch_size, hidden_size)\n",
        "        print(\"q2: \", q2)\n",
        "        # Ma trận mask đánh dấu vị trí khác 0 trên padding sequence.\n",
        "        mask = torch.where(input_seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device)) # batch_size x max_len\n",
        "        # Điều chỉnh shape\n",
        "        q2_expand = q2.unsqueeze(1).expand_as(q1) # shape [batch_size, max_len, hidden_size]\n",
        "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand # batch_size x max_len x hidden_size\n",
        "        print(\"q2_masked :\", q2_masked)\n",
        "        # Tính trọng số alpha đo lường similarity giữa các hidden state\n",
        "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size()) # batch_size x max_len\n",
        "        alpha_exp = alpha.unsqueeze(2).expand_as(outputs) # batch_size x max_len x hidden_size\n",
        "        print(\"alpha_exp :\", alpha_exp)\n",
        "        # Tính linear combinition của các hidden state\n",
        "        c_local = torch.sum(alpha_exp * outputs, 1) # (batch_size x hidden_size)\n",
        "\n",
        "        # Véc tơ combinition tổng hợp\n",
        "        c_t = torch.cat([c_local, c_global], 1) # batch_size x (2*hidden_size)\n",
        "        c_t = self.ct_dropout(c_t)\n",
        "        # Tính scores\n",
        "\n",
        "        # Step 4: Decoder\n",
        "        # embedding cho toàn bộ các item\n",
        "        item_indices = torch.arange(self.n_items).to(device) # n_items\n",
        "        item_embs = self.embedding(item_indices) # n_items x embedding_dim\n",
        "        # reduce dimension by bi-linear projection\n",
        "        B = self.b(item_embs).permute(1, 0) # (2*hidden_size) x n_items\n",
        "        scores = torch.matmul(c_t, B) # batch_size x n_items\n",
        "        # scores = self.sf(scores)\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKr9ze8ORAQx"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE09tStNTKA5",
        "outputId": "fd574807-6476-410f-fb3e-1c073c9a56ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "ab = torch.arange(10)\n",
        "print(ab.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08yWKhbVKmhg",
        "outputId": "c9f20431-1eb3-4622-bcc9-a0a412b73065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([9, 1])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "-----\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[  1,   2,   3],\n",
            "         [  4,   5,   6]],\n",
            "\n",
            "        [[ 11,  22,  33],\n",
            "         [ 44, 551,  16]]])\n",
            "tensor([[  5,   7,   9],\n",
            "        [ 55, 573,  49]])\n",
            "tensor([[[     1,      4,      9],\n",
            "         [    16,     25,     36]],\n",
            "\n",
            "        [[   121,    484,   1089],\n",
            "         [  1936, 303601,    256]]])\n"
          ]
        }
      ],
      "source": [
        "y = torch.tensor([[1],[2],[3],[4],[5],[6],[7],[8],[9] ])\n",
        "print(y.shape)\n",
        "y1 =y.view(3,3)\n",
        "print(y1)\n",
        "print(\"-----\")\n",
        "\n",
        "y2 = torch.tensor([\n",
        "    [\n",
        "      [1, 2, 3], [4, 5, 6]\n",
        "    ],\n",
        "       [[11, 22, 33], [44, 551, 16]\n",
        "]\n",
        "])\n",
        "print(y2.shape)\n",
        "print(y2)\n",
        "y3 = torch.sum(y2, axis=1)\n",
        "print(y3)\n",
        "\n",
        "y4 = torch.tensor([\n",
        "    [\n",
        "      [1, 2, 3], [4, 5, 6]\n",
        "    ],\n",
        "       [[11, 22, 33], [44, 551, 16]\n",
        "]\n",
        "])\n",
        "print(y2*y4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0VYFvV1CmUw",
        "outputId": "293bcbb2-c5cb-4b1c-b51e-4c77ed93be3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[6, 6],\n",
              "        [1, 7]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2], [0, 4]])\n",
        "\n",
        "y = torch.tensor([[5, 4], [1, 3]])\n",
        "\n",
        "(x+y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRc5hZ4R91CF",
        "outputId": "2eb57a74-8e3b-43ee-fe0c-53f0f0e7dd76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "torch.Size([2, 1])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 1, 0]])\n",
            "torch.Size([2, 3])\n",
            "-----\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 0.]])\n",
            "torch.Size([2, 3])\n",
            "-----\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 0., 0., 0.]]])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 1],\n",
        "        [2, 1],\n",
        "        [3, 0]])\n",
        "print(x.shape)\n",
        "print(x[-1].unsqueeze(1).shape)\n",
        "x1 = x.permute(1, 0)\n",
        "print(x1)\n",
        "print(x1.shape)\n",
        "mask = torch.where(x1 > 0, torch.tensor([1.]), torch.tensor([0.]))\n",
        "print(\"-----\")\n",
        "print(mask)\n",
        "print(mask.shape)\n",
        "print(\"-----\")\n",
        "\n",
        "mask_2 = mask.unsqueeze(2).expand(2, 3, 4)\n",
        "print(mask_2)\n",
        "print(mask_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td-DLr4A5yU-",
        "outputId": "29465644-0279-4ac7-e0b2-580b13ed5993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x shape: torch.Size([2, 4, 3])\n",
            "x1 shape: torch.Size([4, 3])\n",
            "tensor([[[ 65,  95,  85]],\n",
            "\n",
            "        [[121,  53,  28]],\n",
            "\n",
            "        [[ 71,  33,  22]],\n",
            "\n",
            "        [[ 10,  30,  60]]])\n",
            "torch.Size([4, 1, 3])\n",
            "------\n",
            "--------\n",
            "tensor([[[ 65,  95,  85],\n",
            "         [ 65,  95,  85]],\n",
            "\n",
            "        [[121,  53,  28],\n",
            "         [121,  53,  28]],\n",
            "\n",
            "        [[ 71,  33,  22],\n",
            "         [ 71,  33,  22]],\n",
            "\n",
            "        [[ 10,  30,  60],\n",
            "         [ 10,  30,  60]]])\n",
            "torch.Size([4, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "x = [\n",
        "    [[6, 9, 8], [12, 5, 8], [7, 3, 2], [0, 0 , 0]],\n",
        "    [[65, 95, 85], [121, 53, 28], [71, 33, 22], [10, 30 , 60]]\n",
        "]\n",
        "\n",
        "x = torch.tensor(x)\n",
        "print(\"x shape:\",x.shape)\n",
        "\n",
        "x1 = x[-1]\n",
        "print(\"x1 shape:\", x1.shape)\n",
        "print(x1.unsqueeze(1))\n",
        "print(x1.unsqueeze(1).shape)\n",
        "\n",
        "print(\"------\")\n",
        "\n",
        "x2 = x1.unsqueeze(1).expand_as(x.permute(1,0,2))\n",
        "print(\"--------\")\n",
        "print(x2)\n",
        "print(x2.shape)\n",
        "\n",
        "# x1 = x.view(-1, 3)\n",
        "\n",
        "# print(x1.shape)\n",
        "# print(x1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVK1dk_JUzHs"
      },
      "source": [
        "## exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96HIYEAJU056",
        "outputId": "2412fdea-c68d-4645-cb94-28b7d78c00f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_seq: \n",
            " tensor([[1, 2, 3, 4],\n",
            "        [5, 1, 2, 3],\n",
            "        [1, 3, 3, 4],\n",
            "        [4, 3, 0, 0],\n",
            "        [1, 0, 0, 0]])\n",
            "input_lengths: \n",
            " tensor([5, 4, 3, 3])\n",
            "model phrase: \n",
            " NARM(\n",
            "  (embedding): Embedding(100000, 100, padding_idx=0)\n",
            "  (emb_dropout): Dropout(p=0.25, inplace=False)\n",
            "  (gru): GRU(108, 3)\n",
            "  (a_1): Linear(in_features=3, out_features=3, bias=False)\n",
            "  (a_2): Linear(in_features=3, out_features=3, bias=False)\n",
            "  (v_t): Linear(in_features=3, out_features=1, bias=False)\n",
            "  (ct_dropout): Dropout(p=0.5, inplace=False)\n",
            "  (b): Linear(in_features=108, out_features=6, bias=False)\n",
            "  (sf): Softmax(dim=None)\n",
            ")\n",
            "embedded:  tensor([[[-0.6149, -1.3129, -0.6125,  ..., -0.9758, -1.1365,  0.6212],\n",
            "         [-1.9414,  1.1400, -0.5760,  ..., -1.0128, -0.7389,  1.4835],\n",
            "         [ 1.1181, -1.4342,  0.7697,  ..., -0.7928,  0.5217, -0.6289],\n",
            "         [ 1.8246, -0.2249,  0.8904,  ..., -1.3440, -0.3484,  0.2367]],\n",
            "\n",
            "        [[-1.5068, -0.8752, -0.5216,  ...,  0.5684,  0.1261, -0.5755],\n",
            "         [-0.6149, -1.3129, -0.6125,  ..., -0.9758, -1.1365,  0.6212],\n",
            "         [-1.9414,  1.1400, -0.5760,  ..., -1.0128, -0.7389,  1.4835],\n",
            "         [ 1.1181, -1.4342,  0.7697,  ..., -0.7928,  0.5217, -0.6289]],\n",
            "\n",
            "        [[-0.6149, -1.3129, -0.6125,  ..., -0.9758, -1.1365,  0.6212],\n",
            "         [ 1.1181, -1.4342,  0.7697,  ..., -0.7928,  0.5217, -0.6289],\n",
            "         [ 1.1181, -1.4342,  0.7697,  ..., -0.7928,  0.5217, -0.6289],\n",
            "         [ 1.8246, -0.2249,  0.8904,  ..., -1.3440, -0.3484,  0.2367]],\n",
            "\n",
            "        [[ 1.8246, -0.2249,  0.8904,  ..., -1.3440, -0.3484,  0.2367],\n",
            "         [ 1.1181, -1.4342,  0.7697,  ..., -0.7928,  0.5217, -0.6289],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.6149, -1.3129, -0.6125,  ..., -0.9758, -1.1365,  0.6212],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "input_expand =  tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
            "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
            "        [4., 4., 4., 4., 4., 4., 4., 4.],\n",
            "        [5., 5., 5., 5., 5., 5., 5., 5.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
            "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
            "        [4., 4., 4., 4., 4., 4., 4., 4.],\n",
            "        [4., 4., 4., 4., 4., 4., 4., 4.],\n",
            "        [3., 3., 3., 3., 3., 3., 3., 3.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "embedded after:  tensor([[[-0.1877,  0.9820,  1.0387,  ..., -0.9758, -1.1365,  0.6212],\n",
            "         [-0.4466, -0.0832,  0.1167,  ..., -1.0128, -0.7389,  1.4835],\n",
            "         [-0.3819, -1.0933, -1.6932,  ..., -0.7928,  0.5217, -0.6289],\n",
            "         [-0.4504,  0.9316, -0.9305,  ..., -1.3440, -0.3484,  0.2367]],\n",
            "\n",
            "        [[ 0.1359,  1.2575, -0.4809,  ...,  0.5684,  0.1261, -0.5755],\n",
            "         [-0.1877,  0.9820,  1.0387,  ..., -0.9758, -1.1365,  0.6212],\n",
            "         [-0.4466, -0.0832,  0.1167,  ..., -1.0128, -0.7389,  1.4835],\n",
            "         [-0.3819, -1.0933, -1.6932,  ..., -0.7928,  0.5217, -0.6289]],\n",
            "\n",
            "        [[-0.1877,  0.9820,  1.0387,  ..., -0.9758, -1.1365,  0.6212],\n",
            "         [-0.3819, -1.0933, -1.6932,  ..., -0.7928,  0.5217, -0.6289],\n",
            "         [-0.3819, -1.0933, -1.6932,  ..., -0.7928,  0.5217, -0.6289],\n",
            "         [-0.4504,  0.9316, -0.9305,  ..., -1.3440, -0.3484,  0.2367]],\n",
            "\n",
            "        [[-0.4504,  0.9316, -0.9305,  ..., -1.3440, -0.3484,  0.2367],\n",
            "         [-0.3819, -1.0933, -1.6932,  ..., -0.7928,  0.5217, -0.6289],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.1877,  0.9820,  1.0387,  ..., -0.9758, -1.1365,  0.6212],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "embedded : torch.Size([5, 4, 108])\n",
            "input_lengths : tensor([5, 4, 3, 3])\n",
            "packed : torch.Size([15, 108])\n",
            "packed : tensor([4, 4, 4, 2, 1])\n",
            "outputs : torch.Size([15, 3])\n",
            "hidden : torch.Size([1, 4, 3])\n",
            "outputs : torch.Size([5, 4, 3])\n",
            "length : tensor([5, 4, 3, 3])\n",
            "ht : torch.Size([4, 3])\n",
            "q1: tensor([[[ 0.1296,  0.1472,  0.2651],\n",
            "         [-0.4270,  0.0423,  0.3562],\n",
            "         [-0.1770,  0.2082,  0.5673],\n",
            "         [-0.3924,  0.1014,  0.3935],\n",
            "         [-0.1996,  0.2264,  0.5673]],\n",
            "\n",
            "        [[-0.6047, -0.0509,  0.1315],\n",
            "         [-0.2104,  0.2032,  0.4562],\n",
            "         [-0.6826, -0.0488,  0.2484],\n",
            "         [-0.7268, -0.0476,  0.2626],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.3560, -0.1069, -0.0252],\n",
            "         [-0.7047, -0.0528,  0.1538],\n",
            "         [-0.7143, -0.0303,  0.1909],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.0950, -0.0009, -0.0435],\n",
            "         [-0.3973, -0.0820, -0.0466],\n",
            "         [-0.3982, -0.0361, -0.0303],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<ViewBackward0>)\n",
            "q2:  tensor([[ 0.0390, -0.0501,  0.4974],\n",
            "        [-0.1530, -0.3741, -0.4000],\n",
            "        [-0.1721, -0.3206, -0.4659],\n",
            "        [-0.1286, -0.1413, -0.4181]], grad_fn=<MmBackward0>)\n",
            "q2_masked : tensor([[[ 0.0390, -0.0501,  0.4974],\n",
            "         [ 0.0390, -0.0501,  0.4974],\n",
            "         [ 0.0390, -0.0501,  0.4974],\n",
            "         [ 0.0390, -0.0501,  0.4974],\n",
            "         [ 0.0390, -0.0501,  0.4974]],\n",
            "\n",
            "        [[-0.1530, -0.3741, -0.4000],\n",
            "         [-0.1530, -0.3741, -0.4000],\n",
            "         [-0.1530, -0.3741, -0.4000],\n",
            "         [-0.1530, -0.3741, -0.4000],\n",
            "         [-0.0000, -0.0000, -0.0000]],\n",
            "\n",
            "        [[-0.1721, -0.3206, -0.4659],\n",
            "         [-0.1721, -0.3206, -0.4659],\n",
            "         [-0.1721, -0.3206, -0.4659],\n",
            "         [-0.0000, -0.0000, -0.0000],\n",
            "         [-0.0000, -0.0000, -0.0000]],\n",
            "\n",
            "        [[-0.1286, -0.1413, -0.4181],\n",
            "         [-0.1286, -0.1413, -0.4181],\n",
            "         [-0.1286, -0.1413, -0.4181],\n",
            "         [-0.0000, -0.0000, -0.0000],\n",
            "         [-0.0000, -0.0000, -0.0000]]], grad_fn=<MulBackward0>)\n",
            "alpha_exp : tensor([[[-0.2068, -0.2068, -0.2068],\n",
            "         [-0.1072, -0.1072, -0.1072],\n",
            "         [-0.1398, -0.1398, -0.1398],\n",
            "         [-0.1150, -0.1150, -0.1150],\n",
            "         [-0.1389, -0.1389, -0.1389]],\n",
            "\n",
            "        [[-0.1471, -0.1471, -0.1471],\n",
            "         [-0.1865, -0.1865, -0.1865],\n",
            "         [-0.1233, -0.1233, -0.1233],\n",
            "         [-0.1164, -0.1164, -0.1164],\n",
            "         [-0.2644, -0.2644, -0.2644]],\n",
            "\n",
            "        [[-0.2031, -0.2031, -0.2031],\n",
            "         [-0.1443, -0.1443, -0.1443],\n",
            "         [-0.1412, -0.1412, -0.1412],\n",
            "         [-0.2644, -0.2644, -0.2644],\n",
            "         [-0.2644, -0.2644, -0.2644]],\n",
            "\n",
            "        [[-0.2740, -0.2740, -0.2740],\n",
            "         [-0.2240, -0.2240, -0.2240],\n",
            "         [-0.2274, -0.2274, -0.2274],\n",
            "         [-0.2644, -0.2644, -0.2644],\n",
            "         [-0.2644, -0.2644, -0.2644]]], grad_fn=<ExpandBackward0>)\n",
            "Step 4\n",
            "input_expand =  tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
            "         1.0000e+00],\n",
            "        [2.0000e+00, 2.0000e+00, 2.0000e+00,  ..., 2.0000e+00, 2.0000e+00,\n",
            "         2.0000e+00],\n",
            "        ...,\n",
            "        [9.9997e+04, 9.9997e+04, 9.9997e+04,  ..., 9.9997e+04, 9.9997e+04,\n",
            "         9.9997e+04],\n",
            "        [9.9998e+04, 9.9998e+04, 9.9998e+04,  ..., 9.9998e+04, 9.9998e+04,\n",
            "         9.9998e+04],\n",
            "        [9.9999e+04, 9.9999e+04, 9.9999e+04,  ..., 9.9999e+04, 9.9999e+04,\n",
            "         9.9999e+04]])\n",
            "item_embs: tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-0.1877,  0.9820,  1.0387,  ..., -0.9758, -1.1365,  0.6212]],\n",
            "\n",
            "        [[-0.4466, -0.0832,  0.1167,  ..., -1.0128, -0.7389,  1.4835]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000,  ..., -0.4535,  0.0215, -0.0140]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000,  ..., -0.8796, -0.1065, -2.3559]],\n",
            "\n",
            "        [[ 0.0000,  0.0000,  0.0000,  ..., -0.4608,  0.9047, -1.4091]]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "torch.Size([100000, 1, 108])\n",
            "108\n",
            "item_embs squeeze : tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.1877,  0.9820,  1.0387,  ..., -0.9758, -1.1365,  0.6212],\n",
            "        [-0.4466, -0.0832,  0.1167,  ..., -1.0128, -0.7389,  1.4835],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4535,  0.0215, -0.0140],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ..., -0.8796, -0.1065, -2.3559],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ..., -0.4608,  0.9047, -1.4091]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "probability distribution:  torch.Size([4, 100000])\n"
          ]
        }
      ],
      "source": [
        "# Thử nghiệm model bằng cách giả lập 1 input và thực hiện quá trình feed forward\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "hidden_size = 3\n",
        "n_layers = 7\n",
        "# embedding = nn.Embedding(11000, hidden_size)\n",
        "input_variable = torch.tensor([[  1,  2,   3, 4],\n",
        "                                [ 5,  1,   2,  3],\n",
        "                                [ 1, 3, 3,  4],\n",
        "                                [ 4,   3,   0, 0],\n",
        "                                [   1,    0,    0,    0]]).to(device)\n",
        "\n",
        "lengths =  torch.tensor([5, 4, 3, 3]).to(device)\n",
        "print('input_seq: \\n', input_variable)\n",
        "print('input_lengths: \\n', lengths)\n",
        "model_test = NARM(hidden_size = hidden_size, n_items  = 100000, num_features=8, embedding_dim = 100, n_layers=1, dropout=0.25).to(device)\n",
        "print('model phrase: \\n', model_test)\n",
        "scores = model_test.forward(input_seq = input_variable, input_lengths = lengths)\n",
        "print('probability distribution: ', scores.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ETpqzXf3ub3"
      },
      "source": [
        "# concate other feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziqA75_m3xEV"
      },
      "outputs": [],
      "source": [
        "class NARM(nn.Module):\n",
        "    def __init__(self, hidden_size, n_items, embedding_dim, num_features, n_layers=1, dropout=0.25):\n",
        "        super(NARM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_items = n_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(self.n_items, self.embedding_dim, padding_idx = 0)\n",
        "        self.num_features = num_features\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        # set bidirectional = True for bidirectional\n",
        "        # self.gru = nn.GRU(input_size = hidden_size, # number of expected feature of input x\n",
        "        #                   hidden_size = hidden_size, # number of expected feature of hidden state\n",
        "        #                   num_layers = n_layers, # number of GRU layers\n",
        "        #                   dropout=(0 if n_layers == 1 else dropout), # dropout probability apply in encoder network\n",
        "        #                   bidirectional=True # one or two directions.\n",
        "        #                  )\n",
        "        self.emb_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(self.embedding_dim + self.num_features, self.hidden_size, self.n_layers)\n",
        "        self.a_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "        self.a_2 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "        self.v_t = nn.Linear(self.hidden_size, 1, bias=False)\n",
        "        self.ct_dropout = nn.Dropout(0.5)\n",
        "        self.b = nn.Linear(self.embedding_dim + self.num_features, 2 * self.hidden_size, bias=False)\n",
        "        self.sf = nn.Softmax()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        \"\"\"\n",
        "        input_seq: Batch input_sequence. Shape: max_len x batch_size\n",
        "        input_lengths: Batch input lengths. Shape: batch_size\n",
        "        \"\"\"\n",
        "        # Step 1: Convert sequence indexes to embeddings\n",
        "        # shape: (max_length , batch_size , hidden_size)\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # print(\"embedded: \", embedded)\n",
        "        # Step 1.2: add item dense feature\n",
        "        embedded, new_hidden_size = add_dense_feature(input_seq, embedded, self.num_features)\n",
        "        # self.hidden_size=new_hidden_size\n",
        "\n",
        "        # input_lengths = [il + 3 for il in input_lengths]\n",
        "        # print(\"embedded after: \", embedded)\n",
        "        # print(\"embedded :\", embedded.shape)\n",
        "        # print(\"input_lengths :\", input_lengths)\n",
        "        # Pack padded batch of sequences for RNN module. Padding zero when length less than max_length of input_lengths.\n",
        "        # shape: (total_lengths , hidden_size)\n",
        "        packed = pack_padded_sequence(embedded, input_lengths)\n",
        "        # print(\"packed :\", packed.data.shape)\n",
        "        # print(\"packed :\", packed.batch_sizes)\n",
        "\n",
        "\n",
        "        # Step 2: Forward packed through GRU\n",
        "        # outputs is output of final GRU layer\n",
        "        # hidden is concatenate of all hidden states corresponding with each time step.\n",
        "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
        "        # hidden shape: (n_layers x num_directions , batch_size , hidden_size)\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # print(\"outputs :\", outputs.data.shape)\n",
        "        # print(\"hidden :\", hidden.shape)\n",
        "\n",
        "        # Unpack padding. Revert of pack_padded_sequence\n",
        "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
        "        outputs, length = pad_packed_sequence(outputs)\n",
        "        # print(\"outputs :\", outputs.shape)\n",
        "        # print(\"length :\", length)\n",
        "\n",
        "\n",
        "        # Step 3: Global Encoder & Local Encoder\n",
        "        # num_directions = 1 -->\n",
        "        # outputs shape:(max_length , batch_size , hidden_size)\n",
        "        # hidden shape: (n_layers , batch_size , hidden_size)\n",
        "        # lấy hidden state tại time step cuối cùng\n",
        "        ht = hidden[-1] # (batch_size, hidden_size)\n",
        "        # print(\"ht :\", ht.shape)\n",
        "        # reshape outputs\n",
        "        outputs = outputs.permute(1, 0, 2) # [batch_size, max_length, hidden_size]\n",
        "        c_global = ht\n",
        "        # Flatten outputs thành shape: [batch_size * max_length, hidden_size]\n",
        "        gru_output_flatten = outputs.contiguous().view(-1, self.hidden_size)\n",
        "        # Thực hiện một phép chiếu linear projection để tạo các latent variable có shape [batch_size, max_length, hidden_size]\n",
        "        q1 = self.a_1(gru_output_flatten).view(outputs.size())\n",
        "        # print(\"q1:\", q1)\n",
        "        # Thực hiện một phép chiếu linear projection để tạo các latent variable có shape [batch_size, max_length, hidden_size]\n",
        "        q2 = self.a_2(ht) # (batch_size, hidden_size)\n",
        "        # print(\"q2: \", q2)\n",
        "        # Ma trận mask đánh dấu vị trí khác 0 trên padding sequence.\n",
        "        mask = torch.where(input_seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device)) # batch_size x max_len\n",
        "        # Điều chỉnh shape\n",
        "        q2_expand = q2.unsqueeze(1).expand_as(q1) # shape [batch_size, max_len, hidden_size]\n",
        "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand # batch_size x max_len x hidden_size\n",
        "        # print(\"q2_masked :\", q2_masked)\n",
        "        # Tính trọng số alpha đo lường similarity giữa các hidden state\n",
        "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size()) # batch_size x max_len\n",
        "        alpha_exp = alpha.unsqueeze(2).expand_as(outputs) # batch_size x max_len x hidden_size\n",
        "        # print(\"alpha_exp :\", alpha_exp)\n",
        "        # Tính linear combinition của các hidden state\n",
        "        c_local = torch.sum(alpha_exp * outputs, 1) # (batch_size x hidden_size)\n",
        "\n",
        "        # Véc tơ combinition tổng hợp\n",
        "        c_t = torch.cat([c_local, c_global], 1) # batch_size x (2*hidden_size)\n",
        "        c_t = self.ct_dropout(c_t)\n",
        "        # Tính scores\n",
        "\n",
        "        # Step 4: Decoder\n",
        "        # embedding cho toàn bộ các item\n",
        "        item_indices = torch.arange(self.n_items).to(device) # n_items\n",
        "\n",
        "        item_indices=item_indices.unsqueeze(1) # n_items x 1\n",
        "        # print(\"Step 4\")\n",
        "        # print(item_indices)\n",
        "        # print(item_indices.shape)\n",
        "\n",
        "        item_embs = self.embedding(item_indices) # n_items x 1 x embedding_dim\n",
        "\n",
        "        item_embs, n = add_dense_feature(item_indices, item_embs, self.num_features) # n_items x 1 x (embedding_dim+num_features)\n",
        "        # print(\"item_embs:\", item_embs)\n",
        "        # print(item_embs.shape)\n",
        "        # print(n)\n",
        "\n",
        "        item_embs=item_embs.squeeze(1)  # n_items x (embedding_dim+num_features)\n",
        "        # print(\"item_embs squeeze :\",item_embs)\n",
        "        # reduce dimension by bi-linear projection\n",
        "        B = self.b(item_embs).permute(1, 0) # (2*hidden_size) x n_items\n",
        "        scores = torch.matmul(c_t, B) # batch_size x n_items\n",
        "        # scores = self.sf(scores)\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EErHpm2aw8tC"
      },
      "source": [
        "# Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMTmuyAcxcxy",
        "outputId": "c97be605-1cfe-423a-9454-38a87b087422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "tensor([[1, 1, 1, 1, 1],\n",
            "        [2, 2, 2, 2, 2],\n",
            "        [3, 3, 3, 3, 3]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.tensor([1, 2, 3])\n",
        "# indices = torch.tensor([\n",
        "#     [  ],\n",
        "#     []\n",
        "# ])\n",
        "\n",
        "indices = torch.randn(3, 5)\n",
        "\n",
        "print(x1.view(-1, 1))\n",
        "\n",
        "x1 = x1.view(-1, 1).expand_as(indices)\n",
        "\n",
        "print(x1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhEsR5JnE7a9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def get_recall(indices, targets):\n",
        "    \"\"\"\n",
        "    Tính toán chỉ số recall cho một tập hợp predictions và targets\n",
        "    Args:\n",
        "        indices (Bxk): torch.LongTensor. top-k indices được dự báo từ mô hình model.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the recall score\n",
        "    \"\"\"\n",
        "    # copy targets k lần để trở thành kích thước Bxk\n",
        "    targets = targets.view(-1, 1).expand_as(indices)\n",
        "    # so sánh targets với indices để tìm ra vị trí mà khách hàng sẽ hit.\n",
        "    hits = (targets == indices).to(device)\n",
        "    hits = hits.double()\n",
        "    if targets.size(0) == 0:\n",
        "        return 0\n",
        "    # Đếm số hit\n",
        "    n_hits = torch.sum(hits)\n",
        "    recall = n_hits / targets.size(0)\n",
        "    return recall\n",
        "\n",
        "\n",
        "def get_mrr(indices, targets):\n",
        "    \"\"\"\n",
        "    Tính toán chỉ số MRR cho một tập hợp predictions và targets\n",
        "    Args:\n",
        "        indices (Bxk): torch.LongTensor. top-k indices được dự báo từ mô hình model.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the MRR score\n",
        "    \"\"\"\n",
        "    tmp = targets.view(-1, 1)\n",
        "    targets = tmp.expand_as(indices)\n",
        "    hits = (targets == indices).to(device)\n",
        "    hits = hits.double()\n",
        "    if hits.sum() == 0:\n",
        "      return 0\n",
        "    argsort = []\n",
        "    for i in np.arange(hits.shape[0]):\n",
        "      index_col = torch.where(hits[i, :] == 1)[0]+1\n",
        "      if index_col.shape[0] != 0:\n",
        "        argsort.append(index_col.double())\n",
        "    inv_argsort = [1/item for item in argsort]\n",
        "    mrr = sum(inv_argsort)/hits.shape[0]\n",
        "    return mrr\n",
        "\n",
        "\n",
        "def evaluate(logits, targets, k=20):\n",
        "    \"\"\"\n",
        "    Đánh giá model sử dụng Recall@K, MRR@K scores.\n",
        "    Args:\n",
        "        logits (B,C): torch.LongTensor. giá trị predicted logit cho itemId tiếp theo.\n",
        "        targets (B): torch.LongTensor. actual target indices.\n",
        "    Returns:\n",
        "        recall (float): the recall score\n",
        "        mrr (float): the mrr score\n",
        "    \"\"\"\n",
        "    # Tìm ra indices của topk lớn nhất các giá trị dự báo.\n",
        "    _, indices = torch.topk(logits, k, -1)\n",
        "    recall = get_recall(indices, targets)\n",
        "    mrr = get_mrr(indices, targets)\n",
        "    return recall, mrr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFB2WhYwXG8C"
      },
      "outputs": [],
      "source": [
        "def validate(valid_loader, model):\n",
        "    model.eval()\n",
        "    recalls = []\n",
        "    mrrs = []\n",
        "    with torch.no_grad():\n",
        "        for seq, target, lens in valid_loader:\n",
        "            seq = seq.to(device)\n",
        "            target = target.to(device)\n",
        "            outputs = model(seq, lens)\n",
        "            logits = F.softmax(outputs, dim = 1)\n",
        "            recall, mrr = evaluate(logits, target, k = args['topk'])\n",
        "            recalls.append(recall)\n",
        "            mrrs.append(mrr)\n",
        "\n",
        "    mean_recall = torch.mean(torch.stack(recalls))\n",
        "    mean_mrr = torch.mean(torch.stack(mrrs))\n",
        "    return mean_recall, mean_mrr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fmFtMQD1iqe",
        "outputId": "2ae2ad76-c4b7-424f-dabc-7f0c28ed689f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 1., 11.])\n",
            "tensor(6.)\n"
          ]
        }
      ],
      "source": [
        "from traitlets import Long\n",
        "x = torch.tensor(1)\n",
        "\n",
        "y = torch.tensor(11)\n",
        "\n",
        "z=[x,  y]\n",
        "\n",
        "zz = torch.stack(z).float()\n",
        "\n",
        "print(zz)\n",
        "\n",
        "print(torch.mean(zz))\n",
        "\n",
        "# mean_recall = torch.mean(torch.stack(recalls))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvQiHWMMY5xV"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O145a7NAvMuq"
      },
      "outputs": [],
      "source": [
        "loss_total = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "pipyd4uGUM62",
        "outputId": "3d5c211a-2c9c-40ac-970e-09e1a9b520f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkhanhnefd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231021_155525-n15k9ei9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/khanhnefd/Train%20model%20recommendation/runs/n15k9ei9' target=\"_blank\">Train_4</a></strong> to <a href='https://wandb.ai/khanhnefd/Train%20model%20recommendation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/khanhnefd/Train%20model%20recommendation' target=\"_blank\">https://wandb.ai/khanhnefd/Train%20model%20recommendation</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/khanhnefd/Train%20model%20recommendation/runs/n15k9ei9' target=\"_blank\">https://wandb.ai/khanhnefd/Train%20model%20recommendation/runs/n15k9ei9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from os.path import join\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.autograd import Variable\n",
        "from torch.backends import cudnn\n",
        "\n",
        "args = {\n",
        "    # 'dataset_path':'../input/yoochoose/yoochoose-clicks.dat',\n",
        "    'batch_size': 256,\n",
        "    'hidden_size': 100,\n",
        "    'embed_dim': 50,\n",
        "    'epoch': 30,\n",
        "    'lr':0.001,\n",
        "    'lr_dc':0.1,\n",
        "    'lr_dc_step':80,\n",
        "    'test':None,\n",
        "    'topk':20,\n",
        "    'valid_portion':0.1\n",
        "}\n",
        "\n",
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"Train model recommendation\",\n",
        "    name = \"Train_4\",\n",
        "    # track hyperparameters and run metadata\n",
        "    config=args\n",
        ")\n",
        "\n",
        "# here = os.path.dirname(os.getcwd())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def main():\n",
        "    print('Loading data...')\n",
        "    train_data, valid_data, test_data = load_data(train_set=train_index, test_set=test_index)\n",
        "    train_data = RecSysDataset(train_data)\n",
        "    valid_data = RecSysDataset(valid_data)\n",
        "    test_data = RecSysDataset(test_data)\n",
        "    train_loader = DataLoader(train_data, batch_size = args['batch_size'], shuffle = True, collate_fn = collate_fn)\n",
        "    valid_loader = DataLoader(valid_data, batch_size = args['batch_size'], shuffle = False, collate_fn = collate_fn)\n",
        "    test_loader = DataLoader(test_data, batch_size = args['batch_size'], shuffle = False, collate_fn = collate_fn)\n",
        "    print('Complete load data!')\n",
        "    n_items = voc.num_items\n",
        "    model = NARM(hidden_size = args['hidden_size'], n_items = n_items, embedding_dim = args['embed_dim'],num_features=8, n_layers=2, dropout=0.25).to(device)\n",
        "    print('complete load model!')\n",
        "\n",
        "    if args['test'] == 'store_true':\n",
        "        ckpt = torch.load('/content/drive/MyDrive/Đồ án model recommendation/checkpoint_model/latest_checkpoint.pt')\n",
        "        model.load_state_dict(ckpt['state_dict'])\n",
        "        recall, mrr = validate(test_loader, model)\n",
        "        print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args['topk'], recall, args['topk'], mrr))\n",
        "        return model\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), args['lr'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = StepLR(optimizer, step_size = args['lr_dc_step'], gamma = args['lr_dc'])\n",
        "\n",
        "    print('start training!')\n",
        "    previous_loss = 0\n",
        "    for epoch in tqdm(range(args['epoch'])):\n",
        "        # train for one epoch\n",
        "        current_loss = trainForEpoch(train_loader, model, optimizer, epoch, args['epoch'], criterion, log_aggr = 100)\n",
        "        scheduler.step()\n",
        "        recall, mrr = validate(valid_loader, model)\n",
        "        print('Epoch {} validation: Recall@{}: {:.4f}, MRR@{}: {:.4f} \\n'.format(epoch, args['topk'], recall, args['topk'], mrr))\n",
        "\n",
        "        wandb.log({\n",
        "            f\"recall@{args['topk']}\": recall,\n",
        "            \"mrr\": mrr,\n",
        "            \"epoch\": epoch + 1,\n",
        "        })\n",
        "\n",
        "        if epoch == 0 or current_loss < previous_loss:\n",
        "          # store best loss and save a model checkpoint\n",
        "          ckpt_dict = {\n",
        "              'epoch': epoch + 1,\n",
        "              'state_dict': model.state_dict(),\n",
        "              'optimizer': optimizer.state_dict(),\n",
        "              'loss': current_loss,\n",
        "          }\n",
        "\n",
        "          torch.save(ckpt_dict, '/content/drive/MyDrive/Đồ án model recommendation/checkpoint_model/full_data_increst_test_set/latest_checkpoint_4.pt')\n",
        "          # torch.save(ckpt_dict, '/content/drive/MyDrive/Đồ án model recommendation/checkpoint_model/full_data/latest_checkpoint_3.pt')\n",
        "\n",
        "          # torch.save(ckpt_dict, '/content/drive/MyDrive/Đồ án model recommendation/checkpoint_model/latest_checkpoint_2.pt')\n",
        "\n",
        "          print(f\"Save checkpoint at epoch {epoch}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} has loss {current_loss}\")\n",
        "\n",
        "        previous_loss = current_loss\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def trainForEpoch(train_loader, model, optimizer, epoch, num_epochs, criterion, log_aggr=100):\n",
        "    model.train()\n",
        "\n",
        "    sum_epoch_loss = 0\n",
        "\n",
        "    start = time.time()\n",
        "    for i, (seq, target, lens) in enumerate(train_loader):\n",
        "        # print(f\"batch {i}\")\n",
        "\n",
        "        seq = seq.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(seq, lens)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_val = loss.item()\n",
        "\n",
        "\n",
        "\n",
        "        sum_epoch_loss += loss_val\n",
        "\n",
        "        iter_num = epoch * len(train_loader) + i + 1\n",
        "\n",
        "        if i % log_aggr == 0:\n",
        "            print('[TRAIN] epoch %d/%d  observation %d/%d batch loss: %.4f (avg %.4f) (%.2f im/s)'\n",
        "                % (epoch + 1, num_epochs, i, len(train_loader), loss_val, sum_epoch_loss / (i + 1),\n",
        "                  len(seq) / (time.time() - start)))\n",
        "\n",
        "            loss_total.append(loss_val)\n",
        "\n",
        "            wandb.log({\"loss_val\": loss_val})\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        # loss_total.append(sum_epoch_loss / (i + 1))\n",
        "\n",
        "    return sum_epoch_loss / (i + 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sh2EFehv7gF",
        "outputId": "852e6346-cb62-4f42-e4a9-b30896e6236d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 411941\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 45771\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 59509\n",
            "--------------------------------------------------\n",
            "Complete load data!\n",
            "complete load model!\n",
            "start training!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TRAIN] epoch 1/30  observation 0/1610 batch loss: 9.8743 (avg 9.8743) (22.99 im/s)\n",
            "[TRAIN] epoch 1/30  observation 100/1610 batch loss: 9.1893 (avg 9.2326) (31.58 im/s)\n",
            "[TRAIN] epoch 1/30  observation 200/1610 batch loss: 8.8793 (avg 9.0950) (18.93 im/s)\n",
            "[TRAIN] epoch 1/30  observation 300/1610 batch loss: 8.2694 (avg 8.9183) (33.04 im/s)\n",
            "[TRAIN] epoch 1/30  observation 400/1610 batch loss: 8.0791 (avg 8.7313) (51.17 im/s)\n",
            "[TRAIN] epoch 1/30  observation 500/1610 batch loss: 7.8846 (avg 8.5600) (46.68 im/s)\n",
            "[TRAIN] epoch 1/30  observation 600/1610 batch loss: 7.4267 (avg 8.4101) (29.38 im/s)\n",
            "[TRAIN] epoch 1/30  observation 700/1610 batch loss: 7.6446 (avg 8.2810) (32.33 im/s)\n",
            "[TRAIN] epoch 1/30  observation 800/1610 batch loss: 7.2816 (avg 8.1704) (38.86 im/s)\n",
            "[TRAIN] epoch 1/30  observation 900/1610 batch loss: 6.9750 (avg 8.0722) (38.49 im/s)\n",
            "[TRAIN] epoch 1/30  observation 1000/1610 batch loss: 7.2793 (avg 7.9864) (35.03 im/s)\n",
            "[TRAIN] epoch 1/30  observation 1100/1610 batch loss: 7.3463 (avg 7.9132) (48.79 im/s)\n",
            "[TRAIN] epoch 1/30  observation 1200/1610 batch loss: 6.9805 (avg 7.8462) (62.35 im/s)\n",
            "[TRAIN] epoch 1/30  observation 1300/1610 batch loss: 6.9971 (avg 7.7848) (34.70 im/s)\n",
            "[TRAIN] epoch 1/30  observation 1400/1610 batch loss: 6.9941 (avg 7.7310) (19.51 im/s)\n",
            "[TRAIN] epoch 1/30  observation 1500/1610 batch loss: 7.0026 (avg 7.6790) (35.93 im/s)\n",
            "[TRAIN] epoch 1/30  observation 1600/1610 batch loss: 6.9100 (avg 7.6332) (39.67 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 1/30 [10:06<4:53:12, 606.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 validation: Recall@20: 0.2843, MRR@20: 0.1320 \n",
            "\n",
            "Save checkpoint at epoch 0\n",
            "Epoch 0 has loss 7.6291956247009844\n",
            "[TRAIN] epoch 2/30  observation 0/1610 batch loss: 6.8958 (avg 6.8958) (26.92 im/s)\n",
            "[TRAIN] epoch 2/30  observation 100/1610 batch loss: 6.8962 (avg 6.8452) (35.48 im/s)\n",
            "[TRAIN] epoch 2/30  observation 200/1610 batch loss: 6.9606 (avg 6.8386) (37.34 im/s)\n",
            "[TRAIN] epoch 2/30  observation 300/1610 batch loss: 6.8597 (avg 6.8210) (38.45 im/s)\n",
            "[TRAIN] epoch 2/30  observation 400/1610 batch loss: 6.4239 (avg 6.8095) (29.00 im/s)\n",
            "[TRAIN] epoch 2/30  observation 500/1610 batch loss: 6.6130 (avg 6.7958) (37.41 im/s)\n",
            "[TRAIN] epoch 2/30  observation 600/1610 batch loss: 6.6415 (avg 6.7840) (32.50 im/s)\n",
            "[TRAIN] epoch 2/30  observation 700/1610 batch loss: 6.6450 (avg 6.7714) (35.73 im/s)\n",
            "[TRAIN] epoch 2/30  observation 800/1610 batch loss: 6.6330 (avg 6.7528) (38.22 im/s)\n",
            "[TRAIN] epoch 2/30  observation 900/1610 batch loss: 6.7902 (avg 6.7386) (33.87 im/s)\n",
            "[TRAIN] epoch 2/30  observation 1000/1610 batch loss: 6.5010 (avg 6.7235) (41.04 im/s)\n",
            "[TRAIN] epoch 2/30  observation 1100/1610 batch loss: 6.6860 (avg 6.7087) (55.97 im/s)\n",
            "[TRAIN] epoch 2/30  observation 1200/1610 batch loss: 6.2667 (avg 6.6961) (17.46 im/s)\n",
            "[TRAIN] epoch 2/30  observation 1300/1610 batch loss: 6.4022 (avg 6.6831) (42.75 im/s)\n",
            "[TRAIN] epoch 2/30  observation 1400/1610 batch loss: 6.6196 (avg 6.6697) (62.75 im/s)\n",
            "[TRAIN] epoch 2/30  observation 1500/1610 batch loss: 6.4995 (avg 6.6592) (35.25 im/s)\n",
            "[TRAIN] epoch 2/30  observation 1600/1610 batch loss: 6.5828 (avg 6.6477) (28.69 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 2/30 [20:12<4:42:57, 606.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 validation: Recall@20: 0.3640, MRR@20: 0.1647 \n",
            "\n",
            "Save checkpoint at epoch 1\n",
            "Epoch 1 has loss 6.646461564709681\n",
            "[TRAIN] epoch 3/30  observation 0/1610 batch loss: 6.0455 (avg 6.0455) (44.24 im/s)\n",
            "[TRAIN] epoch 3/30  observation 100/1610 batch loss: 6.2742 (avg 6.4123) (62.79 im/s)\n",
            "[TRAIN] epoch 3/30  observation 200/1610 batch loss: 6.4908 (avg 6.3896) (61.23 im/s)\n",
            "[TRAIN] epoch 3/30  observation 300/1610 batch loss: 6.3213 (avg 6.3774) (23.24 im/s)\n",
            "[TRAIN] epoch 3/30  observation 400/1610 batch loss: 6.2894 (avg 6.3663) (35.67 im/s)\n",
            "[TRAIN] epoch 3/30  observation 500/1610 batch loss: 6.4805 (avg 6.3526) (38.41 im/s)\n",
            "[TRAIN] epoch 3/30  observation 600/1610 batch loss: 6.0482 (avg 6.3473) (38.33 im/s)\n",
            "[TRAIN] epoch 3/30  observation 700/1610 batch loss: 6.1835 (avg 6.3458) (23.15 im/s)\n",
            "[TRAIN] epoch 3/30  observation 800/1610 batch loss: 6.3171 (avg 6.3408) (34.10 im/s)\n",
            "[TRAIN] epoch 3/30  observation 900/1610 batch loss: 6.2841 (avg 6.3347) (40.99 im/s)\n",
            "[TRAIN] epoch 3/30  observation 1000/1610 batch loss: 6.5648 (avg 6.3269) (41.81 im/s)\n",
            "[TRAIN] epoch 3/30  observation 1100/1610 batch loss: 6.3154 (avg 6.3220) (25.37 im/s)\n",
            "[TRAIN] epoch 3/30  observation 1200/1610 batch loss: 6.3597 (avg 6.3152) (44.57 im/s)\n",
            "[TRAIN] epoch 3/30  observation 1300/1610 batch loss: 6.3466 (avg 6.3079) (34.26 im/s)\n",
            "[TRAIN] epoch 3/30  observation 1400/1610 batch loss: 6.1981 (avg 6.3012) (37.66 im/s)\n",
            "[TRAIN] epoch 3/30  observation 1500/1610 batch loss: 6.1591 (avg 6.2934) (17.33 im/s)\n",
            "[TRAIN] epoch 3/30  observation 1600/1610 batch loss: 5.8884 (avg 6.2848) (44.67 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 3/30 [30:16<4:32:16, 605.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 validation: Recall@20: 0.4066, MRR@20: 0.1832 \n",
            "\n",
            "Save checkpoint at epoch 2\n",
            "Epoch 2 has loss 6.283962816629351\n",
            "[TRAIN] epoch 4/30  observation 0/1610 batch loss: 6.2983 (avg 6.2983) (32.09 im/s)\n",
            "[TRAIN] epoch 4/30  observation 100/1610 batch loss: 5.9282 (avg 6.0829) (39.37 im/s)\n",
            "[TRAIN] epoch 4/30  observation 200/1610 batch loss: 5.8066 (avg 6.0945) (19.88 im/s)\n",
            "[TRAIN] epoch 4/30  observation 300/1610 batch loss: 5.9223 (avg 6.1034) (35.59 im/s)\n",
            "[TRAIN] epoch 4/30  observation 400/1610 batch loss: 5.9448 (avg 6.1042) (38.71 im/s)\n",
            "[TRAIN] epoch 4/30  observation 500/1610 batch loss: 6.1400 (avg 6.1013) (17.71 im/s)\n",
            "[TRAIN] epoch 4/30  observation 600/1610 batch loss: 5.9752 (avg 6.0962) (19.73 im/s)\n",
            "[TRAIN] epoch 4/30  observation 700/1610 batch loss: 6.0680 (avg 6.0906) (34.87 im/s)\n",
            "[TRAIN] epoch 4/30  observation 800/1610 batch loss: 5.8050 (avg 6.0849) (59.82 im/s)\n",
            "[TRAIN] epoch 4/30  observation 900/1610 batch loss: 5.9359 (avg 6.0761) (55.27 im/s)\n",
            "[TRAIN] epoch 4/30  observation 1000/1610 batch loss: 6.1012 (avg 6.0744) (27.13 im/s)\n",
            "[TRAIN] epoch 4/30  observation 1100/1610 batch loss: 5.8866 (avg 6.0660) (44.76 im/s)\n",
            "[TRAIN] epoch 4/30  observation 1200/1610 batch loss: 5.9891 (avg 6.0617) (49.41 im/s)\n",
            "[TRAIN] epoch 4/30  observation 1300/1610 batch loss: 6.0221 (avg 6.0603) (31.38 im/s)\n",
            "[TRAIN] epoch 4/30  observation 1400/1610 batch loss: 5.8771 (avg 6.0541) (33.33 im/s)\n",
            "[TRAIN] epoch 4/30  observation 1500/1610 batch loss: 6.3233 (avg 6.0511) (34.97 im/s)\n",
            "[TRAIN] epoch 4/30  observation 1600/1610 batch loss: 6.0511 (avg 6.0463) (61.11 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 4/30 [40:19<4:21:56, 604.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 validation: Recall@20: 0.4356, MRR@20: 0.1953 \n",
            "\n",
            "Save checkpoint at epoch 3\n",
            "Epoch 3 has loss 6.045784948183143\n",
            "[TRAIN] epoch 5/30  observation 0/1610 batch loss: 5.7661 (avg 5.7661) (27.17 im/s)\n",
            "[TRAIN] epoch 5/30  observation 100/1610 batch loss: 5.8627 (avg 5.8776) (35.21 im/s)\n",
            "[TRAIN] epoch 5/30  observation 200/1610 batch loss: 5.9926 (avg 5.8960) (38.51 im/s)\n",
            "[TRAIN] epoch 5/30  observation 300/1610 batch loss: 5.7888 (avg 5.8973) (34.39 im/s)\n",
            "[TRAIN] epoch 5/30  observation 400/1610 batch loss: 6.0824 (avg 5.8976) (19.31 im/s)\n",
            "[TRAIN] epoch 5/30  observation 500/1610 batch loss: 5.8866 (avg 5.8930) (43.98 im/s)\n",
            "[TRAIN] epoch 5/30  observation 600/1610 batch loss: 5.4950 (avg 5.8946) (40.89 im/s)\n",
            "[TRAIN] epoch 5/30  observation 700/1610 batch loss: 6.1291 (avg 5.8909) (38.69 im/s)\n",
            "[TRAIN] epoch 5/30  observation 800/1610 batch loss: 5.8526 (avg 5.8906) (17.17 im/s)\n",
            "[TRAIN] epoch 5/30  observation 900/1610 batch loss: 5.6969 (avg 5.8879) (41.61 im/s)\n",
            "[TRAIN] epoch 5/30  observation 1000/1610 batch loss: 5.9726 (avg 5.8858) (48.80 im/s)\n",
            "[TRAIN] epoch 5/30  observation 1100/1610 batch loss: 5.5039 (avg 5.8808) (46.95 im/s)\n",
            "[TRAIN] epoch 5/30  observation 1200/1610 batch loss: 5.7474 (avg 5.8769) (17.17 im/s)\n",
            "[TRAIN] epoch 5/30  observation 1300/1610 batch loss: 5.9991 (avg 5.8746) (38.27 im/s)\n",
            "[TRAIN] epoch 5/30  observation 1400/1610 batch loss: 5.9092 (avg 5.8724) (35.42 im/s)\n",
            "[TRAIN] epoch 5/30  observation 1500/1610 batch loss: 5.9574 (avg 5.8691) (50.59 im/s)\n",
            "[TRAIN] epoch 5/30  observation 1600/1610 batch loss: 5.7719 (avg 5.8662) (19.58 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 5/30 [50:24<4:11:54, 604.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 validation: Recall@20: 0.4567, MRR@20: 0.2038 \n",
            "\n",
            "Save checkpoint at epoch 4\n",
            "Epoch 4 has loss 5.865184537224148\n",
            "[TRAIN] epoch 6/30  observation 0/1610 batch loss: 5.8074 (avg 5.8074) (34.96 im/s)\n",
            "[TRAIN] epoch 6/30  observation 100/1610 batch loss: 5.7450 (avg 5.7766) (43.96 im/s)\n",
            "[TRAIN] epoch 6/30  observation 200/1610 batch loss: 5.5489 (avg 5.7460) (48.16 im/s)\n",
            "[TRAIN] epoch 6/30  observation 300/1610 batch loss: 5.7137 (avg 5.7582) (25.42 im/s)\n",
            "[TRAIN] epoch 6/30  observation 400/1610 batch loss: 5.9203 (avg 5.7584) (38.30 im/s)\n",
            "[TRAIN] epoch 6/30  observation 500/1610 batch loss: 5.7961 (avg 5.7525) (52.56 im/s)\n",
            "[TRAIN] epoch 6/30  observation 600/1610 batch loss: 5.6465 (avg 5.7454) (49.37 im/s)\n",
            "[TRAIN] epoch 6/30  observation 700/1610 batch loss: 5.9282 (avg 5.7420) (19.31 im/s)\n",
            "[TRAIN] epoch 6/30  observation 800/1610 batch loss: 5.7311 (avg 5.7390) (41.47 im/s)\n",
            "[TRAIN] epoch 6/30  observation 900/1610 batch loss: 5.8033 (avg 5.7386) (29.33 im/s)\n",
            "[TRAIN] epoch 6/30  observation 1000/1610 batch loss: 5.8228 (avg 5.7330) (42.28 im/s)\n",
            "[TRAIN] epoch 6/30  observation 1100/1610 batch loss: 5.5888 (avg 5.7330) (21.58 im/s)\n",
            "[TRAIN] epoch 6/30  observation 1200/1610 batch loss: 5.7155 (avg 5.7317) (41.37 im/s)\n",
            "[TRAIN] epoch 6/30  observation 1300/1610 batch loss: 5.3676 (avg 5.7284) (44.94 im/s)\n",
            "[TRAIN] epoch 6/30  observation 1400/1610 batch loss: 5.6406 (avg 5.7253) (35.16 im/s)\n",
            "[TRAIN] epoch 6/30  observation 1500/1610 batch loss: 5.7049 (avg 5.7228) (25.63 im/s)\n",
            "[TRAIN] epoch 6/30  observation 1600/1610 batch loss: 5.5901 (avg 5.7187) (28.60 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 6/30 [1:00:26<4:01:26, 603.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 validation: Recall@20: 0.4748, MRR@20: 0.2117 \n",
            "\n",
            "Save checkpoint at epoch 5\n",
            "Epoch 5 has loss 5.718912551121682\n",
            "[TRAIN] epoch 7/30  observation 0/1610 batch loss: 5.6170 (avg 5.6170) (42.62 im/s)\n",
            "[TRAIN] epoch 7/30  observation 100/1610 batch loss: 5.5681 (avg 5.6090) (30.93 im/s)\n",
            "[TRAIN] epoch 7/30  observation 200/1610 batch loss: 5.6736 (avg 5.6121) (29.35 im/s)\n",
            "[TRAIN] epoch 7/30  observation 300/1610 batch loss: 5.5067 (avg 5.6060) (28.49 im/s)\n",
            "[TRAIN] epoch 7/30  observation 400/1610 batch loss: 5.5690 (avg 5.6183) (42.26 im/s)\n",
            "[TRAIN] epoch 7/30  observation 500/1610 batch loss: 5.6379 (avg 5.6127) (39.02 im/s)\n",
            "[TRAIN] epoch 7/30  observation 600/1610 batch loss: 5.6360 (avg 5.6161) (19.41 im/s)\n",
            "[TRAIN] epoch 7/30  observation 700/1610 batch loss: 5.6559 (avg 5.6163) (42.07 im/s)\n",
            "[TRAIN] epoch 7/30  observation 800/1610 batch loss: 5.6631 (avg 5.6125) (57.89 im/s)\n",
            "[TRAIN] epoch 7/30  observation 900/1610 batch loss: 5.7039 (avg 5.6152) (28.61 im/s)\n",
            "[TRAIN] epoch 7/30  observation 1000/1610 batch loss: 5.4197 (avg 5.6158) (27.23 im/s)\n",
            "[TRAIN] epoch 7/30  observation 1100/1610 batch loss: 5.1672 (avg 5.6154) (44.19 im/s)\n",
            "[TRAIN] epoch 7/30  observation 1200/1610 batch loss: 5.7236 (avg 5.6121) (48.23 im/s)\n",
            "[TRAIN] epoch 7/30  observation 1300/1610 batch loss: 5.8890 (avg 5.6111) (45.21 im/s)\n",
            "[TRAIN] epoch 7/30  observation 1400/1610 batch loss: 5.6776 (avg 5.6112) (19.49 im/s)\n",
            "[TRAIN] epoch 7/30  observation 1500/1610 batch loss: 5.5288 (avg 5.6108) (38.99 im/s)\n",
            "[TRAIN] epoch 7/30  observation 1600/1610 batch loss: 5.7112 (avg 5.6102) (45.17 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 7/30 [1:10:28<3:51:09, 603.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 validation: Recall@20: 0.4836, MRR@20: 0.2167 \n",
            "\n",
            "Save checkpoint at epoch 6\n",
            "Epoch 6 has loss 5.61083342925362\n",
            "[TRAIN] epoch 8/30  observation 0/1610 batch loss: 5.0694 (avg 5.0694) (33.01 im/s)\n",
            "[TRAIN] epoch 8/30  observation 100/1610 batch loss: 5.4614 (avg 5.5148) (27.54 im/s)\n",
            "[TRAIN] epoch 8/30  observation 200/1610 batch loss: 5.5005 (avg 5.5306) (40.65 im/s)\n",
            "[TRAIN] epoch 8/30  observation 300/1610 batch loss: 5.6284 (avg 5.5327) (45.50 im/s)\n",
            "[TRAIN] epoch 8/30  observation 400/1610 batch loss: 5.4687 (avg 5.5333) (53.19 im/s)\n",
            "[TRAIN] epoch 8/30  observation 500/1610 batch loss: 5.5768 (avg 5.5315) (23.14 im/s)\n",
            "[TRAIN] epoch 8/30  observation 600/1610 batch loss: 5.4245 (avg 5.5258) (41.41 im/s)\n",
            "[TRAIN] epoch 8/30  observation 700/1610 batch loss: 5.4742 (avg 5.5274) (63.58 im/s)\n",
            "[TRAIN] epoch 8/30  observation 800/1610 batch loss: 5.5338 (avg 5.5266) (44.27 im/s)\n",
            "[TRAIN] epoch 8/30  observation 900/1610 batch loss: 5.8460 (avg 5.5314) (21.09 im/s)\n",
            "[TRAIN] epoch 8/30  observation 1000/1610 batch loss: 5.5236 (avg 5.5294) (41.76 im/s)\n",
            "[TRAIN] epoch 8/30  observation 1100/1610 batch loss: 5.4749 (avg 5.5292) (37.49 im/s)\n",
            "[TRAIN] epoch 8/30  observation 1200/1610 batch loss: 5.7183 (avg 5.5279) (48.04 im/s)\n",
            "[TRAIN] epoch 8/30  observation 1300/1610 batch loss: 5.4913 (avg 5.5264) (32.34 im/s)\n",
            "[TRAIN] epoch 8/30  observation 1400/1610 batch loss: 5.4344 (avg 5.5274) (48.32 im/s)\n",
            "[TRAIN] epoch 8/30  observation 1500/1610 batch loss: 5.5057 (avg 5.5271) (43.86 im/s)\n",
            "[TRAIN] epoch 8/30  observation 1600/1610 batch loss: 5.6480 (avg 5.5273) (38.20 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 8/30 [1:20:31<3:41:08, 603.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 validation: Recall@20: 0.4919, MRR@20: 0.2207 \n",
            "\n",
            "Save checkpoint at epoch 7\n",
            "Epoch 7 has loss 5.527271522794451\n",
            "[TRAIN] epoch 9/30  observation 0/1610 batch loss: 5.3409 (avg 5.3409) (22.32 im/s)\n",
            "[TRAIN] epoch 9/30  observation 100/1610 batch loss: 5.4677 (avg 5.4486) (46.26 im/s)\n",
            "[TRAIN] epoch 9/30  observation 200/1610 batch loss: 5.8133 (avg 5.4549) (34.68 im/s)\n",
            "[TRAIN] epoch 9/30  observation 300/1610 batch loss: 5.8042 (avg 5.4476) (34.42 im/s)\n",
            "[TRAIN] epoch 9/30  observation 400/1610 batch loss: 5.6306 (avg 5.4615) (25.62 im/s)\n",
            "[TRAIN] epoch 9/30  observation 500/1610 batch loss: 5.4496 (avg 5.4604) (42.29 im/s)\n",
            "[TRAIN] epoch 9/30  observation 600/1610 batch loss: 5.2501 (avg 5.4569) (42.36 im/s)\n",
            "[TRAIN] epoch 9/30  observation 700/1610 batch loss: 5.4332 (avg 5.4580) (32.18 im/s)\n",
            "[TRAIN] epoch 9/30  observation 800/1610 batch loss: 5.4187 (avg 5.4572) (23.41 im/s)\n",
            "[TRAIN] epoch 9/30  observation 900/1610 batch loss: 5.3524 (avg 5.4570) (59.96 im/s)\n",
            "[TRAIN] epoch 9/30  observation 1000/1610 batch loss: 5.3033 (avg 5.4595) (44.70 im/s)\n",
            "[TRAIN] epoch 9/30  observation 1100/1610 batch loss: 5.4866 (avg 5.4586) (60.52 im/s)\n",
            "[TRAIN] epoch 9/30  observation 1200/1610 batch loss: 5.3396 (avg 5.4598) (19.31 im/s)\n",
            "[TRAIN] epoch 9/30  observation 1300/1610 batch loss: 5.5771 (avg 5.4626) (42.95 im/s)\n",
            "[TRAIN] epoch 9/30  observation 1400/1610 batch loss: 5.3317 (avg 5.4639) (45.42 im/s)\n",
            "[TRAIN] epoch 9/30  observation 1500/1610 batch loss: 5.2494 (avg 5.4631) (46.70 im/s)\n",
            "[TRAIN] epoch 9/30  observation 1600/1610 batch loss: 5.6873 (avg 5.4634) (34.98 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 9/30 [1:30:35<3:31:10, 603.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 validation: Recall@20: 0.4967, MRR@20: 0.2239 \n",
            "\n",
            "Save checkpoint at epoch 8\n",
            "Epoch 8 has loss 5.464263787773085\n",
            "[TRAIN] epoch 10/30  observation 0/1610 batch loss: 5.5405 (avg 5.5405) (32.84 im/s)\n",
            "[TRAIN] epoch 10/30  observation 100/1610 batch loss: 5.4721 (avg 5.3871) (38.76 im/s)\n",
            "[TRAIN] epoch 10/30  observation 200/1610 batch loss: 5.1660 (avg 5.3847) (41.89 im/s)\n",
            "[TRAIN] epoch 10/30  observation 300/1610 batch loss: 5.8618 (avg 5.3891) (17.47 im/s)\n",
            "[TRAIN] epoch 10/30  observation 400/1610 batch loss: 5.4110 (avg 5.3960) (38.17 im/s)\n",
            "[TRAIN] epoch 10/30  observation 500/1610 batch loss: 5.2709 (avg 5.4039) (29.09 im/s)\n",
            "[TRAIN] epoch 10/30  observation 600/1610 batch loss: 5.1952 (avg 5.3998) (54.99 im/s)\n",
            "[TRAIN] epoch 10/30  observation 700/1610 batch loss: 5.3259 (avg 5.4056) (21.76 im/s)\n",
            "[TRAIN] epoch 10/30  observation 800/1610 batch loss: 5.3580 (avg 5.4073) (27.91 im/s)\n",
            "[TRAIN] epoch 10/30  observation 900/1610 batch loss: 5.2152 (avg 5.4098) (60.94 im/s)\n",
            "[TRAIN] epoch 10/30  observation 1000/1610 batch loss: 5.2754 (avg 5.4136) (37.52 im/s)\n",
            "[TRAIN] epoch 10/30  observation 1100/1610 batch loss: 5.4068 (avg 5.4138) (22.37 im/s)\n",
            "[TRAIN] epoch 10/30  observation 1200/1610 batch loss: 5.5743 (avg 5.4125) (38.49 im/s)\n",
            "[TRAIN] epoch 10/30  observation 1300/1610 batch loss: 5.5785 (avg 5.4134) (58.31 im/s)\n",
            "[TRAIN] epoch 10/30  observation 1400/1610 batch loss: 5.3291 (avg 5.4138) (62.52 im/s)\n",
            "[TRAIN] epoch 10/30  observation 1500/1610 batch loss: 5.5369 (avg 5.4150) (27.12 im/s)\n",
            "[TRAIN] epoch 10/30  observation 1600/1610 batch loss: 5.4423 (avg 5.4142) (28.83 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 10/30 [1:40:37<3:20:59, 602.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 validation: Recall@20: 0.5019, MRR@20: 0.2264 \n",
            "\n",
            "Save checkpoint at epoch 9\n",
            "Epoch 9 has loss 5.413845044781703\n",
            "[TRAIN] epoch 11/30  observation 0/1610 batch loss: 5.4012 (avg 5.4012) (29.55 im/s)\n",
            "[TRAIN] epoch 11/30  observation 100/1610 batch loss: 5.2644 (avg 5.3509) (41.48 im/s)\n",
            "[TRAIN] epoch 11/30  observation 200/1610 batch loss: 5.4694 (avg 5.3591) (24.12 im/s)\n",
            "[TRAIN] epoch 11/30  observation 300/1610 batch loss: 5.4582 (avg 5.3648) (41.57 im/s)\n",
            "[TRAIN] epoch 11/30  observation 400/1610 batch loss: 5.0802 (avg 5.3663) (35.04 im/s)\n",
            "[TRAIN] epoch 11/30  observation 500/1610 batch loss: 5.1685 (avg 5.3592) (61.49 im/s)\n",
            "[TRAIN] epoch 11/30  observation 600/1610 batch loss: 5.5174 (avg 5.3623) (25.51 im/s)\n",
            "[TRAIN] epoch 11/30  observation 700/1610 batch loss: 5.3575 (avg 5.3661) (41.73 im/s)\n",
            "[TRAIN] epoch 11/30  observation 800/1610 batch loss: 5.4074 (avg 5.3657) (40.79 im/s)\n",
            "[TRAIN] epoch 11/30  observation 900/1610 batch loss: 5.6181 (avg 5.3671) (50.42 im/s)\n",
            "[TRAIN] epoch 11/30  observation 1000/1610 batch loss: 5.0177 (avg 5.3669) (21.58 im/s)\n",
            "[TRAIN] epoch 11/30  observation 1100/1610 batch loss: 5.0206 (avg 5.3657) (45.55 im/s)\n",
            "[TRAIN] epoch 11/30  observation 1200/1610 batch loss: 5.3839 (avg 5.3650) (33.45 im/s)\n",
            "[TRAIN] epoch 11/30  observation 1300/1610 batch loss: 5.6834 (avg 5.3671) (17.80 im/s)\n",
            "[TRAIN] epoch 11/30  observation 1400/1610 batch loss: 5.5527 (avg 5.3689) (23.00 im/s)\n",
            "[TRAIN] epoch 11/30  observation 1500/1610 batch loss: 5.5655 (avg 5.3715) (37.61 im/s)\n",
            "[TRAIN] epoch 11/30  observation 1600/1610 batch loss: 5.3055 (avg 5.3697) (25.56 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 11/30 [1:50:39<3:10:48, 602.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 validation: Recall@20: 0.5068, MRR@20: 0.2284 \n",
            "\n",
            "Save checkpoint at epoch 10\n",
            "Epoch 10 has loss 5.369654311304507\n",
            "[TRAIN] epoch 12/30  observation 0/1610 batch loss: 5.4232 (avg 5.4232) (59.59 im/s)\n",
            "[TRAIN] epoch 12/30  observation 100/1610 batch loss: 5.3632 (avg 5.3089) (38.59 im/s)\n",
            "[TRAIN] epoch 12/30  observation 200/1610 batch loss: 5.1700 (avg 5.3143) (45.61 im/s)\n",
            "[TRAIN] epoch 12/30  observation 300/1610 batch loss: 5.2782 (avg 5.3233) (48.47 im/s)\n",
            "[TRAIN] epoch 12/30  observation 400/1610 batch loss: 5.4388 (avg 5.3214) (45.85 im/s)\n",
            "[TRAIN] epoch 12/30  observation 500/1610 batch loss: 5.4379 (avg 5.3313) (21.41 im/s)\n",
            "[TRAIN] epoch 12/30  observation 600/1610 batch loss: 5.3180 (avg 5.3304) (41.36 im/s)\n",
            "[TRAIN] epoch 12/30  observation 700/1610 batch loss: 5.1750 (avg 5.3331) (62.79 im/s)\n",
            "[TRAIN] epoch 12/30  observation 800/1610 batch loss: 5.3592 (avg 5.3351) (42.60 im/s)\n",
            "[TRAIN] epoch 12/30  observation 900/1610 batch loss: 4.9786 (avg 5.3337) (24.93 im/s)\n",
            "[TRAIN] epoch 12/30  observation 1000/1610 batch loss: 5.1820 (avg 5.3334) (51.48 im/s)\n",
            "[TRAIN] epoch 12/30  observation 1100/1610 batch loss: 5.3245 (avg 5.3337) (35.26 im/s)\n",
            "[TRAIN] epoch 12/30  observation 1200/1610 batch loss: 5.7613 (avg 5.3342) (42.06 im/s)\n",
            "[TRAIN] epoch 12/30  observation 1300/1610 batch loss: 5.5098 (avg 5.3341) (25.34 im/s)\n",
            "[TRAIN] epoch 12/30  observation 1400/1610 batch loss: 5.4700 (avg 5.3345) (38.59 im/s)\n",
            "[TRAIN] epoch 12/30  observation 1500/1610 batch loss: 5.5346 (avg 5.3363) (38.43 im/s)\n",
            "[TRAIN] epoch 12/30  observation 1600/1610 batch loss: 5.3786 (avg 5.3344) (44.15 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 12/30 [2:00:43<3:00:54, 603.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 validation: Recall@20: 0.5102, MRR@20: 0.2297 \n",
            "\n",
            "Save checkpoint at epoch 11\n",
            "Epoch 11 has loss 5.334040865986984\n",
            "[TRAIN] epoch 13/30  observation 0/1610 batch loss: 5.1077 (avg 5.1077) (20.75 im/s)\n",
            "[TRAIN] epoch 13/30  observation 100/1610 batch loss: 5.0008 (avg 5.2604) (38.91 im/s)\n",
            "[TRAIN] epoch 13/30  observation 200/1610 batch loss: 5.0620 (avg 5.2727) (48.93 im/s)\n",
            "[TRAIN] epoch 13/30  observation 300/1610 batch loss: 5.0025 (avg 5.2769) (44.86 im/s)\n",
            "[TRAIN] epoch 13/30  observation 400/1610 batch loss: 5.1945 (avg 5.2815) (28.93 im/s)\n",
            "[TRAIN] epoch 13/30  observation 500/1610 batch loss: 5.3685 (avg 5.2873) (45.17 im/s)\n",
            "[TRAIN] epoch 13/30  observation 600/1610 batch loss: 5.2487 (avg 5.2847) (38.87 im/s)\n",
            "[TRAIN] epoch 13/30  observation 700/1610 batch loss: 5.1720 (avg 5.2886) (51.94 im/s)\n",
            "[TRAIN] epoch 13/30  observation 800/1610 batch loss: 5.2632 (avg 5.2907) (30.02 im/s)\n",
            "[TRAIN] epoch 13/30  observation 900/1610 batch loss: 5.3618 (avg 5.2907) (42.25 im/s)\n",
            "[TRAIN] epoch 13/30  observation 1000/1610 batch loss: 5.4056 (avg 5.2936) (59.59 im/s)\n",
            "[TRAIN] epoch 13/30  observation 1100/1610 batch loss: 5.3426 (avg 5.2950) (61.68 im/s)\n",
            "[TRAIN] epoch 13/30  observation 1200/1610 batch loss: 5.3945 (avg 5.2981) (22.76 im/s)\n",
            "[TRAIN] epoch 13/30  observation 1300/1610 batch loss: 5.1603 (avg 5.2989) (55.20 im/s)\n",
            "[TRAIN] epoch 13/30  observation 1400/1610 batch loss: 5.2706 (avg 5.3007) (35.78 im/s)\n",
            "[TRAIN] epoch 13/30  observation 1500/1610 batch loss: 5.4158 (avg 5.3011) (27.40 im/s)\n",
            "[TRAIN] epoch 13/30  observation 1600/1610 batch loss: 5.0828 (avg 5.3019) (9.05 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 13/30 [2:10:45<2:50:49, 602.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 validation: Recall@20: 0.5116, MRR@20: 0.2322 \n",
            "\n",
            "Save checkpoint at epoch 12\n",
            "Epoch 12 has loss 5.302595836035213\n",
            "[TRAIN] epoch 14/30  observation 0/1610 batch loss: 5.2877 (avg 5.2877) (35.61 im/s)\n",
            "[TRAIN] epoch 14/30  observation 100/1610 batch loss: 5.3530 (avg 5.2735) (60.15 im/s)\n",
            "[TRAIN] epoch 14/30  observation 200/1610 batch loss: 5.0105 (avg 5.2638) (32.51 im/s)\n",
            "[TRAIN] epoch 14/30  observation 300/1610 batch loss: 5.3022 (avg 5.2590) (23.51 im/s)\n",
            "[TRAIN] epoch 14/30  observation 400/1610 batch loss: 5.4834 (avg 5.2603) (44.27 im/s)\n",
            "[TRAIN] epoch 14/30  observation 500/1610 batch loss: 5.2558 (avg 5.2585) (48.02 im/s)\n",
            "[TRAIN] epoch 14/30  observation 600/1610 batch loss: 5.4694 (avg 5.2672) (35.26 im/s)\n",
            "[TRAIN] epoch 14/30  observation 700/1610 batch loss: 5.3634 (avg 5.2691) (29.85 im/s)\n",
            "[TRAIN] epoch 14/30  observation 800/1610 batch loss: 5.0800 (avg 5.2675) (38.47 im/s)\n",
            "[TRAIN] epoch 14/30  observation 900/1610 batch loss: 5.1464 (avg 5.2656) (38.05 im/s)\n",
            "[TRAIN] epoch 14/30  observation 1000/1610 batch loss: 5.0622 (avg 5.2661) (32.07 im/s)\n",
            "[TRAIN] epoch 14/30  observation 1100/1610 batch loss: 5.4130 (avg 5.2662) (21.66 im/s)\n",
            "[TRAIN] epoch 14/30  observation 1200/1610 batch loss: 5.2000 (avg 5.2658) (45.75 im/s)\n",
            "[TRAIN] epoch 14/30  observation 1300/1610 batch loss: 5.2728 (avg 5.2668) (36.29 im/s)\n",
            "[TRAIN] epoch 14/30  observation 1400/1610 batch loss: 5.4800 (avg 5.2709) (48.46 im/s)\n",
            "[TRAIN] epoch 14/30  observation 1500/1610 batch loss: 5.1950 (avg 5.2728) (24.99 im/s)\n",
            "[TRAIN] epoch 14/30  observation 1600/1610 batch loss: 5.4183 (avg 5.2741) (25.44 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 14/30 [2:20:46<2:40:34, 602.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 validation: Recall@20: 0.5140, MRR@20: 0.2331 \n",
            "\n",
            "Save checkpoint at epoch 13\n",
            "Epoch 13 has loss 5.274257647769051\n",
            "[TRAIN] epoch 15/30  observation 0/1610 batch loss: 5.2597 (avg 5.2597) (38.71 im/s)\n",
            "[TRAIN] epoch 15/30  observation 100/1610 batch loss: 5.3775 (avg 5.2319) (41.70 im/s)\n",
            "[TRAIN] epoch 15/30  observation 200/1610 batch loss: 5.2931 (avg 5.2294) (28.06 im/s)\n",
            "[TRAIN] epoch 15/30  observation 300/1610 batch loss: 5.0164 (avg 5.2209) (34.65 im/s)\n",
            "[TRAIN] epoch 15/30  observation 400/1610 batch loss: 5.2932 (avg 5.2224) (49.46 im/s)\n",
            "[TRAIN] epoch 15/30  observation 500/1610 batch loss: 5.4885 (avg 5.2256) (48.52 im/s)\n",
            "[TRAIN] epoch 15/30  observation 600/1610 batch loss: 5.3457 (avg 5.2317) (32.53 im/s)\n",
            "[TRAIN] epoch 15/30  observation 700/1610 batch loss: 5.5122 (avg 5.2353) (18.87 im/s)\n",
            "[TRAIN] epoch 15/30  observation 800/1610 batch loss: 5.6330 (avg 5.2352) (35.67 im/s)\n",
            "[TRAIN] epoch 15/30  observation 900/1610 batch loss: 5.2024 (avg 5.2374) (35.28 im/s)\n",
            "[TRAIN] epoch 15/30  observation 1000/1610 batch loss: 5.0818 (avg 5.2382) (40.29 im/s)\n",
            "[TRAIN] epoch 15/30  observation 1100/1610 batch loss: 4.9810 (avg 5.2392) (17.82 im/s)\n",
            "[TRAIN] epoch 15/30  observation 1200/1610 batch loss: 5.5817 (avg 5.2418) (53.02 im/s)\n",
            "[TRAIN] epoch 15/30  observation 1300/1610 batch loss: 5.2393 (avg 5.2432) (61.12 im/s)\n",
            "[TRAIN] epoch 15/30  observation 1400/1610 batch loss: 5.0703 (avg 5.2443) (44.75 im/s)\n",
            "[TRAIN] epoch 15/30  observation 1500/1610 batch loss: 5.1021 (avg 5.2450) (23.38 im/s)\n",
            "[TRAIN] epoch 15/30  observation 1600/1610 batch loss: 5.4912 (avg 5.2462) (46.28 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 15/30 [2:30:47<2:30:28, 601.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 validation: Recall@20: 0.5167, MRR@20: 0.2335 \n",
            "\n",
            "Save checkpoint at epoch 14\n",
            "Epoch 14 has loss 5.246077688288245\n",
            "[TRAIN] epoch 16/30  observation 0/1610 batch loss: 4.8551 (avg 4.8551) (36.41 im/s)\n",
            "[TRAIN] epoch 16/30  observation 100/1610 batch loss: 5.0798 (avg 5.2117) (39.09 im/s)\n",
            "[TRAIN] epoch 16/30  observation 200/1610 batch loss: 5.1164 (avg 5.1958) (23.94 im/s)\n",
            "[TRAIN] epoch 16/30  observation 300/1610 batch loss: 5.0256 (avg 5.1952) (61.74 im/s)\n",
            "[TRAIN] epoch 16/30  observation 400/1610 batch loss: 4.9972 (avg 5.2004) (54.65 im/s)\n",
            "[TRAIN] epoch 16/30  observation 500/1610 batch loss: 5.2912 (avg 5.2064) (41.03 im/s)\n",
            "[TRAIN] epoch 16/30  observation 600/1610 batch loss: 5.1849 (avg 5.2082) (24.79 im/s)\n",
            "[TRAIN] epoch 16/30  observation 700/1610 batch loss: 5.3417 (avg 5.2102) (45.29 im/s)\n",
            "[TRAIN] epoch 16/30  observation 800/1610 batch loss: 5.2299 (avg 5.2151) (42.98 im/s)\n",
            "[TRAIN] epoch 16/30  observation 900/1610 batch loss: 5.2323 (avg 5.2164) (32.57 im/s)\n",
            "[TRAIN] epoch 16/30  observation 1000/1610 batch loss: 5.2210 (avg 5.2186) (24.80 im/s)\n",
            "[TRAIN] epoch 16/30  observation 1100/1610 batch loss: 5.2935 (avg 5.2204) (41.51 im/s)\n",
            "[TRAIN] epoch 16/30  observation 1200/1610 batch loss: 5.1928 (avg 5.2212) (45.69 im/s)\n",
            "[TRAIN] epoch 16/30  observation 1300/1610 batch loss: 5.6055 (avg 5.2242) (35.33 im/s)\n",
            "[TRAIN] epoch 16/30  observation 1400/1610 batch loss: 5.3565 (avg 5.2244) (29.40 im/s)\n",
            "[TRAIN] epoch 16/30  observation 1500/1610 batch loss: 5.0985 (avg 5.2246) (48.39 im/s)\n",
            "[TRAIN] epoch 16/30  observation 1600/1610 batch loss: 5.5027 (avg 5.2263) (63.41 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 16/30 [2:40:48<2:20:22, 601.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 validation: Recall@20: 0.5179, MRR@20: 0.2351 \n",
            "\n",
            "Save checkpoint at epoch 15\n",
            "Epoch 15 has loss 5.225801342910861\n",
            "[TRAIN] epoch 17/30  observation 0/1610 batch loss: 5.3882 (avg 5.3882) (46.76 im/s)\n",
            "[TRAIN] epoch 17/30  observation 100/1610 batch loss: 5.3364 (avg 5.1621) (27.14 im/s)\n",
            "[TRAIN] epoch 17/30  observation 200/1610 batch loss: 5.3198 (avg 5.1852) (48.47 im/s)\n",
            "[TRAIN] epoch 17/30  observation 300/1610 batch loss: 5.4886 (avg 5.1910) (63.08 im/s)\n",
            "[TRAIN] epoch 17/30  observation 400/1610 batch loss: 5.3182 (avg 5.1949) (62.39 im/s)\n",
            "[TRAIN] epoch 17/30  observation 500/1610 batch loss: 5.2985 (avg 5.1917) (31.71 im/s)\n",
            "[TRAIN] epoch 17/30  observation 600/1610 batch loss: 5.0076 (avg 5.1896) (42.46 im/s)\n",
            "[TRAIN] epoch 17/30  observation 700/1610 batch loss: 5.2059 (avg 5.1896) (37.82 im/s)\n",
            "[TRAIN] epoch 17/30  observation 800/1610 batch loss: 5.2306 (avg 5.1917) (64.87 im/s)\n",
            "[TRAIN] epoch 17/30  observation 900/1610 batch loss: 5.0500 (avg 5.1929) (21.79 im/s)\n",
            "[TRAIN] epoch 17/30  observation 1000/1610 batch loss: 5.5160 (avg 5.1943) (38.38 im/s)\n",
            "[TRAIN] epoch 17/30  observation 1100/1610 batch loss: 4.9071 (avg 5.1925) (40.32 im/s)\n",
            "[TRAIN] epoch 17/30  observation 1200/1610 batch loss: 5.0819 (avg 5.1942) (31.36 im/s)\n",
            "[TRAIN] epoch 17/30  observation 1300/1610 batch loss: 5.0212 (avg 5.1948) (39.34 im/s)\n",
            "[TRAIN] epoch 17/30  observation 1400/1610 batch loss: 4.8702 (avg 5.1973) (31.80 im/s)\n",
            "[TRAIN] epoch 17/30  observation 1500/1610 batch loss: 5.4078 (avg 5.1978) (23.84 im/s)\n",
            "[TRAIN] epoch 17/30  observation 1600/1610 batch loss: 5.4760 (avg 5.2001) (54.24 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 17/30 [2:50:50<2:10:22, 601.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 validation: Recall@20: 0.5197, MRR@20: 0.2370 \n",
            "\n",
            "Save checkpoint at epoch 16\n",
            "Epoch 16 has loss 5.20092495183767\n",
            "[TRAIN] epoch 18/30  observation 0/1610 batch loss: 5.1673 (avg 5.1673) (31.92 im/s)\n",
            "[TRAIN] epoch 18/30  observation 100/1610 batch loss: 4.8266 (avg 5.1446) (41.63 im/s)\n",
            "[TRAIN] epoch 18/30  observation 200/1610 batch loss: 4.9521 (avg 5.1536) (40.68 im/s)\n",
            "[TRAIN] epoch 18/30  observation 300/1610 batch loss: 5.2659 (avg 5.1486) (30.73 im/s)\n",
            "[TRAIN] epoch 18/30  observation 400/1610 batch loss: 5.1983 (avg 5.1611) (19.63 im/s)\n",
            "[TRAIN] epoch 18/30  observation 500/1610 batch loss: 5.0947 (avg 5.1665) (31.35 im/s)\n",
            "[TRAIN] epoch 18/30  observation 600/1610 batch loss: 5.0422 (avg 5.1693) (28.90 im/s)\n",
            "[TRAIN] epoch 18/30  observation 700/1610 batch loss: 5.4859 (avg 5.1727) (44.87 im/s)\n",
            "[TRAIN] epoch 18/30  observation 800/1610 batch loss: 5.0156 (avg 5.1743) (25.15 im/s)\n",
            "[TRAIN] epoch 18/30  observation 900/1610 batch loss: 5.3461 (avg 5.1788) (29.63 im/s)\n",
            "[TRAIN] epoch 18/30  observation 1000/1610 batch loss: 5.3580 (avg 5.1788) (56.75 im/s)\n",
            "[TRAIN] epoch 18/30  observation 1100/1610 batch loss: 5.2192 (avg 5.1770) (40.86 im/s)\n",
            "[TRAIN] epoch 18/30  observation 1200/1610 batch loss: 5.1588 (avg 5.1810) (21.64 im/s)\n",
            "[TRAIN] epoch 18/30  observation 1300/1610 batch loss: 5.3842 (avg 5.1804) (47.47 im/s)\n",
            "[TRAIN] epoch 18/30  observation 1400/1610 batch loss: 5.1170 (avg 5.1801) (31.63 im/s)\n",
            "[TRAIN] epoch 18/30  observation 1500/1610 batch loss: 5.2589 (avg 5.1803) (60.07 im/s)\n",
            "[TRAIN] epoch 18/30  observation 1600/1610 batch loss: 5.3682 (avg 5.1807) (25.37 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 18/30 [3:00:55<2:00:34, 602.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 validation: Recall@20: 0.5206, MRR@20: 0.2362 \n",
            "\n",
            "Save checkpoint at epoch 17\n",
            "Epoch 17 has loss 5.180671799405021\n",
            "[TRAIN] epoch 19/30  observation 0/1610 batch loss: 5.2015 (avg 5.2015) (57.84 im/s)\n",
            "[TRAIN] epoch 19/30  observation 100/1610 batch loss: 4.9526 (avg 5.1316) (47.74 im/s)\n",
            "[TRAIN] epoch 19/30  observation 200/1610 batch loss: 4.9610 (avg 5.1092) (27.95 im/s)\n",
            "[TRAIN] epoch 19/30  observation 300/1610 batch loss: 5.4086 (avg 5.1221) (19.81 im/s)\n",
            "[TRAIN] epoch 19/30  observation 400/1610 batch loss: 5.1930 (avg 5.1298) (35.33 im/s)\n",
            "[TRAIN] epoch 19/30  observation 500/1610 batch loss: 5.1431 (avg 5.1360) (39.95 im/s)\n",
            "[TRAIN] epoch 19/30  observation 600/1610 batch loss: 4.9528 (avg 5.1407) (46.15 im/s)\n",
            "[TRAIN] epoch 19/30  observation 700/1610 batch loss: 4.7868 (avg 5.1419) (21.59 im/s)\n",
            "[TRAIN] epoch 19/30  observation 800/1610 batch loss: 5.4008 (avg 5.1425) (31.85 im/s)\n",
            "[TRAIN] epoch 19/30  observation 900/1610 batch loss: 5.2304 (avg 5.1430) (45.36 im/s)\n",
            "[TRAIN] epoch 19/30  observation 1000/1610 batch loss: 5.0782 (avg 5.1460) (62.02 im/s)\n",
            "[TRAIN] epoch 19/30  observation 1100/1610 batch loss: 5.2218 (avg 5.1469) (17.60 im/s)\n",
            "[TRAIN] epoch 19/30  observation 1200/1610 batch loss: 5.0549 (avg 5.1501) (49.85 im/s)\n",
            "[TRAIN] epoch 19/30  observation 1300/1610 batch loss: 5.3215 (avg 5.1560) (57.85 im/s)\n",
            "[TRAIN] epoch 19/30  observation 1400/1610 batch loss: 4.9705 (avg 5.1585) (27.43 im/s)\n",
            "[TRAIN] epoch 19/30  observation 1500/1610 batch loss: 5.1954 (avg 5.1598) (19.93 im/s)\n",
            "[TRAIN] epoch 19/30  observation 1600/1610 batch loss: 5.0553 (avg 5.1602) (38.69 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 19/30 [3:10:59<1:50:33, 603.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 validation: Recall@20: 0.5217, MRR@20: 0.2366 \n",
            "\n",
            "Save checkpoint at epoch 18\n",
            "Epoch 18 has loss 5.159696866562648\n",
            "[TRAIN] epoch 20/30  observation 0/1610 batch loss: 5.0358 (avg 5.0358) (38.17 im/s)\n",
            "[TRAIN] epoch 20/30  observation 100/1610 batch loss: 5.2218 (avg 5.0839) (27.46 im/s)\n",
            "[TRAIN] epoch 20/30  observation 200/1610 batch loss: 5.0198 (avg 5.1006) (54.42 im/s)\n",
            "[TRAIN] epoch 20/30  observation 300/1610 batch loss: 5.0536 (avg 5.1088) (38.67 im/s)\n",
            "[TRAIN] epoch 20/30  observation 400/1610 batch loss: 4.9377 (avg 5.1183) (40.20 im/s)\n",
            "[TRAIN] epoch 20/30  observation 500/1610 batch loss: 4.8764 (avg 5.1201) (37.49 im/s)\n",
            "[TRAIN] epoch 20/30  observation 600/1610 batch loss: 5.1771 (avg 5.1271) (37.20 im/s)\n",
            "[TRAIN] epoch 20/30  observation 700/1610 batch loss: 5.0671 (avg 5.1294) (44.34 im/s)\n",
            "[TRAIN] epoch 20/30  observation 800/1610 batch loss: 5.4816 (avg 5.1331) (37.65 im/s)\n",
            "[TRAIN] epoch 20/30  observation 900/1610 batch loss: 5.0494 (avg 5.1331) (40.08 im/s)\n",
            "[TRAIN] epoch 20/30  observation 1000/1610 batch loss: 5.1902 (avg 5.1318) (32.17 im/s)\n",
            "[TRAIN] epoch 20/30  observation 1100/1610 batch loss: 5.1648 (avg 5.1338) (49.20 im/s)\n",
            "[TRAIN] epoch 20/30  observation 1200/1610 batch loss: 4.9715 (avg 5.1365) (38.18 im/s)\n",
            "[TRAIN] epoch 20/30  observation 1300/1610 batch loss: 5.2958 (avg 5.1369) (30.76 im/s)\n",
            "[TRAIN] epoch 20/30  observation 1400/1610 batch loss: 5.0790 (avg 5.1386) (17.79 im/s)\n",
            "[TRAIN] epoch 20/30  observation 1500/1610 batch loss: 5.0357 (avg 5.1401) (54.60 im/s)\n",
            "[TRAIN] epoch 20/30  observation 1600/1610 batch loss: 5.1732 (avg 5.1426) (35.70 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 20/30 [3:21:02<1:40:29, 602.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 validation: Recall@20: 0.5235, MRR@20: 0.2379 \n",
            "\n",
            "Save checkpoint at epoch 19\n",
            "Epoch 19 has loss 5.1428816241507205\n",
            "[TRAIN] epoch 21/30  observation 0/1610 batch loss: 5.1383 (avg 5.1383) (19.25 im/s)\n",
            "[TRAIN] epoch 21/30  observation 100/1610 batch loss: 5.1820 (avg 5.0863) (41.78 im/s)\n",
            "[TRAIN] epoch 21/30  observation 200/1610 batch loss: 5.2419 (avg 5.0888) (33.45 im/s)\n",
            "[TRAIN] epoch 21/30  observation 300/1610 batch loss: 5.3184 (avg 5.0859) (62.85 im/s)\n",
            "[TRAIN] epoch 21/30  observation 400/1610 batch loss: 4.9169 (avg 5.0937) (23.56 im/s)\n",
            "[TRAIN] epoch 21/30  observation 500/1610 batch loss: 5.2007 (avg 5.1043) (57.05 im/s)\n",
            "[TRAIN] epoch 21/30  observation 600/1610 batch loss: 5.4472 (avg 5.1108) (42.22 im/s)\n",
            "[TRAIN] epoch 21/30  observation 700/1610 batch loss: 4.9982 (avg 5.1113) (40.60 im/s)\n",
            "[TRAIN] epoch 21/30  observation 800/1610 batch loss: 5.1203 (avg 5.1123) (19.50 im/s)\n",
            "[TRAIN] epoch 21/30  observation 900/1610 batch loss: 5.2933 (avg 5.1117) (35.51 im/s)\n",
            "[TRAIN] epoch 21/30  observation 1000/1610 batch loss: 5.3129 (avg 5.1142) (62.40 im/s)\n",
            "[TRAIN] epoch 21/30  observation 1100/1610 batch loss: 5.2103 (avg 5.1170) (57.95 im/s)\n",
            "[TRAIN] epoch 21/30  observation 1200/1610 batch loss: 4.8304 (avg 5.1212) (21.56 im/s)\n",
            "[TRAIN] epoch 21/30  observation 1300/1610 batch loss: 5.2581 (avg 5.1214) (49.47 im/s)\n",
            "[TRAIN] epoch 21/30  observation 1400/1610 batch loss: 5.0122 (avg 5.1248) (45.89 im/s)\n",
            "[TRAIN] epoch 21/30  observation 1500/1610 batch loss: 4.9854 (avg 5.1239) (41.83 im/s)\n",
            "[TRAIN] epoch 21/30  observation 1600/1610 batch loss: 5.0485 (avg 5.1262) (32.60 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 21/30 [3:31:07<1:30:33, 603.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 validation: Recall@20: 0.5247, MRR@20: 0.2395 \n",
            "\n",
            "Save checkpoint at epoch 20\n",
            "Epoch 20 has loss 5.126073238124018\n",
            "[TRAIN] epoch 22/30  observation 0/1610 batch loss: 5.1777 (avg 5.1777) (36.24 im/s)\n",
            "[TRAIN] epoch 22/30  observation 100/1610 batch loss: 4.6423 (avg 5.0766) (32.14 im/s)\n",
            "[TRAIN] epoch 22/30  observation 200/1610 batch loss: 5.1753 (avg 5.0802) (47.54 im/s)\n",
            "[TRAIN] epoch 22/30  observation 300/1610 batch loss: 5.2459 (avg 5.0733) (32.22 im/s)\n",
            "[TRAIN] epoch 22/30  observation 400/1610 batch loss: 4.9531 (avg 5.0773) (28.69 im/s)\n",
            "[TRAIN] epoch 22/30  observation 500/1610 batch loss: 5.0868 (avg 5.0811) (34.61 im/s)\n",
            "[TRAIN] epoch 22/30  observation 600/1610 batch loss: 5.1991 (avg 5.0894) (56.68 im/s)\n",
            "[TRAIN] epoch 22/30  observation 700/1610 batch loss: 5.1816 (avg 5.0915) (38.87 im/s)\n",
            "[TRAIN] epoch 22/30  observation 800/1610 batch loss: 5.1990 (avg 5.0923) (61.28 im/s)\n",
            "[TRAIN] epoch 22/30  observation 900/1610 batch loss: 5.1048 (avg 5.0969) (61.91 im/s)\n",
            "[TRAIN] epoch 22/30  observation 1000/1610 batch loss: 4.9797 (avg 5.0972) (45.45 im/s)\n",
            "[TRAIN] epoch 22/30  observation 1100/1610 batch loss: 5.1954 (avg 5.1004) (25.96 im/s)\n",
            "[TRAIN] epoch 22/30  observation 1200/1610 batch loss: 5.4625 (avg 5.1027) (28.23 im/s)\n",
            "[TRAIN] epoch 22/30  observation 1300/1610 batch loss: 5.0343 (avg 5.1050) (48.07 im/s)\n",
            "[TRAIN] epoch 22/30  observation 1400/1610 batch loss: 5.1826 (avg 5.1080) (30.94 im/s)\n",
            "[TRAIN] epoch 22/30  observation 1500/1610 batch loss: 5.4290 (avg 5.1093) (21.08 im/s)\n",
            "[TRAIN] epoch 22/30  observation 1600/1610 batch loss: 4.8851 (avg 5.1093) (48.01 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 22/30 [3:41:10<1:20:26, 603.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 validation: Recall@20: 0.5232, MRR@20: 0.2392 \n",
            "\n",
            "Save checkpoint at epoch 21\n",
            "Epoch 21 has loss 5.10939832888775\n",
            "[TRAIN] epoch 23/30  observation 0/1610 batch loss: 4.9960 (avg 4.9960) (30.66 im/s)\n",
            "[TRAIN] epoch 23/30  observation 100/1610 batch loss: 4.9543 (avg 5.0477) (31.15 im/s)\n",
            "[TRAIN] epoch 23/30  observation 200/1610 batch loss: 5.1623 (avg 5.0644) (62.15 im/s)\n",
            "[TRAIN] epoch 23/30  observation 300/1610 batch loss: 4.8609 (avg 5.0675) (29.32 im/s)\n",
            "[TRAIN] epoch 23/30  observation 400/1610 batch loss: 5.0739 (avg 5.0812) (42.04 im/s)\n",
            "[TRAIN] epoch 23/30  observation 500/1610 batch loss: 5.1588 (avg 5.0796) (37.75 im/s)\n",
            "[TRAIN] epoch 23/30  observation 600/1610 batch loss: 5.0470 (avg 5.0782) (56.76 im/s)\n",
            "[TRAIN] epoch 23/30  observation 700/1610 batch loss: 5.2571 (avg 5.0814) (38.53 im/s)\n",
            "[TRAIN] epoch 23/30  observation 800/1610 batch loss: 5.3394 (avg 5.0832) (33.71 im/s)\n",
            "[TRAIN] epoch 23/30  observation 900/1610 batch loss: 4.9534 (avg 5.0851) (19.35 im/s)\n",
            "[TRAIN] epoch 23/30  observation 1000/1610 batch loss: 5.0547 (avg 5.0882) (28.06 im/s)\n",
            "[TRAIN] epoch 23/30  observation 1100/1610 batch loss: 4.9910 (avg 5.0908) (38.46 im/s)\n",
            "[TRAIN] epoch 23/30  observation 1200/1610 batch loss: 5.0550 (avg 5.0905) (31.45 im/s)\n",
            "[TRAIN] epoch 23/30  observation 1300/1610 batch loss: 5.0661 (avg 5.0907) (21.14 im/s)\n",
            "[TRAIN] epoch 23/30  observation 1400/1610 batch loss: 5.2628 (avg 5.0914) (34.86 im/s)\n",
            "[TRAIN] epoch 23/30  observation 1500/1610 batch loss: 5.1838 (avg 5.0930) (63.39 im/s)\n",
            "[TRAIN] epoch 23/30  observation 1600/1610 batch loss: 4.6919 (avg 5.0946) (45.36 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 23/30 [3:51:16<1:10:29, 604.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 validation: Recall@20: 0.5252, MRR@20: 0.2401 \n",
            "\n",
            "Save checkpoint at epoch 22\n",
            "Epoch 22 has loss 5.094801607783537\n",
            "[TRAIN] epoch 24/30  observation 0/1610 batch loss: 4.9203 (avg 4.9203) (27.51 im/s)\n",
            "[TRAIN] epoch 24/30  observation 100/1610 batch loss: 5.1769 (avg 5.0544) (37.96 im/s)\n",
            "[TRAIN] epoch 24/30  observation 200/1610 batch loss: 4.7972 (avg 5.0435) (62.00 im/s)\n",
            "[TRAIN] epoch 24/30  observation 300/1610 batch loss: 4.8374 (avg 5.0495) (27.37 im/s)\n",
            "[TRAIN] epoch 24/30  observation 400/1610 batch loss: 4.8818 (avg 5.0541) (22.00 im/s)\n",
            "[TRAIN] epoch 24/30  observation 500/1610 batch loss: 5.2635 (avg 5.0586) (48.61 im/s)\n",
            "[TRAIN] epoch 24/30  observation 600/1610 batch loss: 4.9363 (avg 5.0618) (44.87 im/s)\n",
            "[TRAIN] epoch 24/30  observation 700/1610 batch loss: 5.1166 (avg 5.0631) (43.94 im/s)\n",
            "[TRAIN] epoch 24/30  observation 800/1610 batch loss: 5.3135 (avg 5.0669) (19.92 im/s)\n",
            "[TRAIN] epoch 24/30  observation 900/1610 batch loss: 5.1540 (avg 5.0688) (45.55 im/s)\n",
            "[TRAIN] epoch 24/30  observation 1000/1610 batch loss: 5.1933 (avg 5.0695) (48.55 im/s)\n",
            "[TRAIN] epoch 24/30  observation 1100/1610 batch loss: 5.0239 (avg 5.0701) (37.63 im/s)\n",
            "[TRAIN] epoch 24/30  observation 1200/1610 batch loss: 5.1680 (avg 5.0693) (25.18 im/s)\n",
            "[TRAIN] epoch 24/30  observation 1300/1610 batch loss: 5.1813 (avg 5.0725) (41.00 im/s)\n",
            "[TRAIN] epoch 24/30  observation 1400/1610 batch loss: 5.5411 (avg 5.0748) (39.01 im/s)\n",
            "[TRAIN] epoch 24/30  observation 1500/1610 batch loss: 5.2151 (avg 5.0760) (37.91 im/s)\n",
            "[TRAIN] epoch 24/30  observation 1600/1610 batch loss: 5.2660 (avg 5.0794) (29.30 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 24/30 [4:01:19<1:00:23, 603.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 validation: Recall@20: 0.5248, MRR@20: 0.2397 \n",
            "\n",
            "Save checkpoint at epoch 23\n",
            "Epoch 23 has loss 5.079451433027753\n",
            "[TRAIN] epoch 25/30  observation 0/1610 batch loss: 5.2471 (avg 5.2471) (47.55 im/s)\n",
            "[TRAIN] epoch 25/30  observation 100/1610 batch loss: 4.5496 (avg 4.9798) (34.65 im/s)\n",
            "[TRAIN] epoch 25/30  observation 200/1610 batch loss: 4.9446 (avg 5.0045) (35.51 im/s)\n",
            "[TRAIN] epoch 25/30  observation 300/1610 batch loss: 4.9865 (avg 5.0173) (25.42 im/s)\n",
            "[TRAIN] epoch 25/30  observation 400/1610 batch loss: 4.9124 (avg 5.0217) (60.31 im/s)\n",
            "[TRAIN] epoch 25/30  observation 500/1610 batch loss: 4.9990 (avg 5.0285) (45.27 im/s)\n",
            "[TRAIN] epoch 25/30  observation 600/1610 batch loss: 5.0795 (avg 5.0301) (52.77 im/s)\n",
            "[TRAIN] epoch 25/30  observation 700/1610 batch loss: 5.1044 (avg 5.0335) (21.53 im/s)\n",
            "[TRAIN] epoch 25/30  observation 800/1610 batch loss: 5.4578 (avg 5.0374) (29.29 im/s)\n",
            "[TRAIN] epoch 25/30  observation 900/1610 batch loss: 4.9626 (avg 5.0415) (59.25 im/s)\n",
            "[TRAIN] epoch 25/30  observation 1000/1610 batch loss: 4.9755 (avg 5.0456) (50.40 im/s)\n",
            "[TRAIN] epoch 25/30  observation 1100/1610 batch loss: 4.9661 (avg 5.0492) (25.12 im/s)\n",
            "[TRAIN] epoch 25/30  observation 1200/1610 batch loss: 4.8633 (avg 5.0534) (44.00 im/s)\n",
            "[TRAIN] epoch 25/30  observation 1300/1610 batch loss: 5.2346 (avg 5.0574) (43.59 im/s)\n",
            "[TRAIN] epoch 25/30  observation 1400/1610 batch loss: 4.8936 (avg 5.0618) (63.41 im/s)\n",
            "[TRAIN] epoch 25/30  observation 1500/1610 batch loss: 5.3761 (avg 5.0644) (33.26 im/s)\n",
            "[TRAIN] epoch 25/30  observation 1600/1610 batch loss: 5.0662 (avg 5.0649) (56.44 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 25/30 [4:11:22<50:18, 603.64s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 validation: Recall@20: 0.5269, MRR@20: 0.2406 \n",
            "\n",
            "Save checkpoint at epoch 24\n",
            "Epoch 24 has loss 5.064497302037589\n",
            "[TRAIN] epoch 26/30  observation 0/1610 batch loss: 4.7232 (avg 4.7232) (26.12 im/s)\n",
            "[TRAIN] epoch 26/30  observation 100/1610 batch loss: 4.9141 (avg 4.9769) (22.40 im/s)\n",
            "[TRAIN] epoch 26/30  observation 200/1610 batch loss: 5.1551 (avg 5.0010) (27.84 im/s)\n",
            "[TRAIN] epoch 26/30  observation 300/1610 batch loss: 5.0311 (avg 5.0069) (47.69 im/s)\n",
            "[TRAIN] epoch 26/30  observation 400/1610 batch loss: 5.1357 (avg 5.0158) (35.59 im/s)\n",
            "[TRAIN] epoch 26/30  observation 500/1610 batch loss: 5.2034 (avg 5.0235) (23.04 im/s)\n",
            "[TRAIN] epoch 26/30  observation 600/1610 batch loss: 4.8446 (avg 5.0290) (32.19 im/s)\n",
            "[TRAIN] epoch 26/30  observation 700/1610 batch loss: 4.9045 (avg 5.0318) (36.79 im/s)\n",
            "[TRAIN] epoch 26/30  observation 800/1610 batch loss: 4.7205 (avg 5.0342) (41.14 im/s)\n",
            "[TRAIN] epoch 26/30  observation 900/1610 batch loss: 5.0416 (avg 5.0370) (21.82 im/s)\n",
            "[TRAIN] epoch 26/30  observation 1000/1610 batch loss: 5.0948 (avg 5.0425) (54.98 im/s)\n",
            "[TRAIN] epoch 26/30  observation 1100/1610 batch loss: 4.9790 (avg 5.0440) (35.81 im/s)\n",
            "[TRAIN] epoch 26/30  observation 1200/1610 batch loss: 5.0484 (avg 5.0470) (60.39 im/s)\n",
            "[TRAIN] epoch 26/30  observation 1300/1610 batch loss: 5.1007 (avg 5.0464) (36.29 im/s)\n",
            "[TRAIN] epoch 26/30  observation 1400/1610 batch loss: 4.9515 (avg 5.0487) (47.10 im/s)\n",
            "[TRAIN] epoch 26/30  observation 1500/1610 batch loss: 5.2030 (avg 5.0501) (48.28 im/s)\n",
            "[TRAIN] epoch 26/30  observation 1600/1610 batch loss: 5.1960 (avg 5.0497) (61.08 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 26/30 [4:21:27<40:16, 604.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 validation: Recall@20: 0.5263, MRR@20: 0.2405 \n",
            "\n",
            "Save checkpoint at epoch 25\n",
            "Epoch 25 has loss 5.04944098336356\n",
            "[TRAIN] epoch 27/30  observation 0/1610 batch loss: 5.2390 (avg 5.2390) (30.57 im/s)\n",
            "[TRAIN] epoch 27/30  observation 100/1610 batch loss: 4.8041 (avg 4.9839) (31.56 im/s)\n",
            "[TRAIN] epoch 27/30  observation 200/1610 batch loss: 5.0351 (avg 4.9947) (38.02 im/s)\n",
            "[TRAIN] epoch 27/30  observation 300/1610 batch loss: 5.0140 (avg 5.0039) (31.79 im/s)\n",
            "[TRAIN] epoch 27/30  observation 400/1610 batch loss: 5.1801 (avg 5.0100) (29.66 im/s)\n",
            "[TRAIN] epoch 27/30  observation 500/1610 batch loss: 4.9710 (avg 5.0153) (58.45 im/s)\n",
            "[TRAIN] epoch 27/30  observation 600/1610 batch loss: 5.2854 (avg 5.0204) (45.13 im/s)\n",
            "[TRAIN] epoch 27/30  observation 700/1610 batch loss: 5.2206 (avg 5.0219) (47.98 im/s)\n",
            "[TRAIN] epoch 27/30  observation 800/1610 batch loss: 4.9655 (avg 5.0219) (21.64 im/s)\n",
            "[TRAIN] epoch 27/30  observation 900/1610 batch loss: 4.8443 (avg 5.0262) (34.66 im/s)\n",
            "[TRAIN] epoch 27/30  observation 1000/1610 batch loss: 5.0531 (avg 5.0281) (29.19 im/s)\n",
            "[TRAIN] epoch 27/30  observation 1100/1610 batch loss: 4.9286 (avg 5.0308) (30.48 im/s)\n",
            "[TRAIN] epoch 27/30  observation 1200/1610 batch loss: 4.8591 (avg 5.0325) (21.15 im/s)\n",
            "[TRAIN] epoch 27/30  observation 1300/1610 batch loss: 5.3140 (avg 5.0330) (38.23 im/s)\n",
            "[TRAIN] epoch 27/30  observation 1400/1610 batch loss: 5.0806 (avg 5.0357) (55.86 im/s)\n",
            "[TRAIN] epoch 27/30  observation 1500/1610 batch loss: 4.9219 (avg 5.0350) (49.38 im/s)\n",
            "[TRAIN] epoch 27/30  observation 1600/1610 batch loss: 5.0480 (avg 5.0367) (21.51 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 27/30 [4:31:31<30:12, 604.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 validation: Recall@20: 0.5253, MRR@20: 0.2419 \n",
            "\n",
            "Save checkpoint at epoch 26\n",
            "Epoch 26 has loss 5.03674422169324\n",
            "[TRAIN] epoch 28/30  observation 0/1610 batch loss: 4.8413 (avg 4.8413) (43.66 im/s)\n",
            "[TRAIN] epoch 28/30  observation 100/1610 batch loss: 4.9467 (avg 4.9687) (42.51 im/s)\n",
            "[TRAIN] epoch 28/30  observation 200/1610 batch loss: 4.7208 (avg 4.9800) (42.52 im/s)\n",
            "[TRAIN] epoch 28/30  observation 300/1610 batch loss: 5.0550 (avg 4.9852) (27.50 im/s)\n",
            "[TRAIN] epoch 28/30  observation 400/1610 batch loss: 5.2703 (avg 4.9979) (40.83 im/s)\n",
            "[TRAIN] epoch 28/30  observation 500/1610 batch loss: 4.9803 (avg 5.0031) (45.89 im/s)\n",
            "[TRAIN] epoch 28/30  observation 600/1610 batch loss: 5.1654 (avg 5.0065) (51.95 im/s)\n",
            "[TRAIN] epoch 28/30  observation 700/1610 batch loss: 4.9934 (avg 5.0042) (25.62 im/s)\n",
            "[TRAIN] epoch 28/30  observation 800/1610 batch loss: 5.2436 (avg 5.0070) (55.77 im/s)\n",
            "[TRAIN] epoch 28/30  observation 900/1610 batch loss: 5.2848 (avg 5.0130) (34.16 im/s)\n",
            "[TRAIN] epoch 28/30  observation 1000/1610 batch loss: 4.7803 (avg 5.0166) (51.82 im/s)\n",
            "[TRAIN] epoch 28/30  observation 1100/1610 batch loss: 4.8916 (avg 5.0151) (23.71 im/s)\n",
            "[TRAIN] epoch 28/30  observation 1200/1610 batch loss: 5.0506 (avg 5.0185) (32.49 im/s)\n",
            "[TRAIN] epoch 28/30  observation 1300/1610 batch loss: 5.4127 (avg 5.0199) (64.40 im/s)\n",
            "[TRAIN] epoch 28/30  observation 1400/1610 batch loss: 5.0788 (avg 5.0217) (40.97 im/s)\n",
            "[TRAIN] epoch 28/30  observation 1500/1610 batch loss: 5.1292 (avg 5.0224) (27.38 im/s)\n",
            "[TRAIN] epoch 28/30  observation 1600/1610 batch loss: 5.1683 (avg 5.0250) (32.38 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 28/30 [4:41:34<20:07, 603.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 validation: Recall@20: 0.5257, MRR@20: 0.2414 \n",
            "\n",
            "Save checkpoint at epoch 27\n",
            "Epoch 27 has loss 5.02504788363202\n",
            "[TRAIN] epoch 29/30  observation 0/1610 batch loss: 5.2327 (avg 5.2327) (22.51 im/s)\n",
            "[TRAIN] epoch 29/30  observation 100/1610 batch loss: 5.0165 (avg 4.9665) (51.13 im/s)\n",
            "[TRAIN] epoch 29/30  observation 200/1610 batch loss: 5.0004 (avg 4.9642) (35.28 im/s)\n",
            "[TRAIN] epoch 29/30  observation 300/1610 batch loss: 5.1309 (avg 4.9692) (18.71 im/s)\n",
            "[TRAIN] epoch 29/30  observation 400/1610 batch loss: 4.9656 (avg 4.9778) (60.73 im/s)\n",
            "[TRAIN] epoch 29/30  observation 500/1610 batch loss: 4.6473 (avg 4.9862) (31.27 im/s)\n",
            "[TRAIN] epoch 29/30  observation 600/1610 batch loss: 5.1492 (avg 4.9918) (23.19 im/s)\n",
            "[TRAIN] epoch 29/30  observation 700/1610 batch loss: 5.0810 (avg 4.9925) (46.91 im/s)\n",
            "[TRAIN] epoch 29/30  observation 800/1610 batch loss: 5.0672 (avg 4.9958) (38.18 im/s)\n",
            "[TRAIN] epoch 29/30  observation 900/1610 batch loss: 4.7027 (avg 4.9996) (29.03 im/s)\n",
            "[TRAIN] epoch 29/30  observation 1000/1610 batch loss: 4.8015 (avg 4.9999) (25.07 im/s)\n",
            "[TRAIN] epoch 29/30  observation 1100/1610 batch loss: 5.1768 (avg 5.0027) (13.72 im/s)\n",
            "[TRAIN] epoch 29/30  observation 1200/1610 batch loss: 5.3559 (avg 5.0030) (30.05 im/s)\n",
            "[TRAIN] epoch 29/30  observation 1300/1610 batch loss: 4.9796 (avg 5.0062) (62.12 im/s)\n",
            "[TRAIN] epoch 29/30  observation 1400/1610 batch loss: 5.4966 (avg 5.0074) (39.00 im/s)\n",
            "[TRAIN] epoch 29/30  observation 1500/1610 batch loss: 5.0971 (avg 5.0120) (47.16 im/s)\n",
            "[TRAIN] epoch 29/30  observation 1600/1610 batch loss: 5.4016 (avg 5.0119) (35.52 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 29/30 [4:51:39<10:04, 604.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 validation: Recall@20: 0.5266, MRR@20: 0.2409 \n",
            "\n",
            "Save checkpoint at epoch 28\n",
            "Epoch 28 has loss 5.012268808021308\n",
            "[TRAIN] epoch 30/30  observation 0/1610 batch loss: 4.9812 (avg 4.9812) (25.46 im/s)\n",
            "[TRAIN] epoch 30/30  observation 100/1610 batch loss: 5.0215 (avg 4.9502) (37.32 im/s)\n",
            "[TRAIN] epoch 30/30  observation 200/1610 batch loss: 4.9989 (avg 4.9469) (46.68 im/s)\n",
            "[TRAIN] epoch 30/30  observation 300/1610 batch loss: 4.9976 (avg 4.9571) (55.70 im/s)\n",
            "[TRAIN] epoch 30/30  observation 400/1610 batch loss: 4.7490 (avg 4.9658) (21.38 im/s)\n",
            "[TRAIN] epoch 30/30  observation 500/1610 batch loss: 5.2281 (avg 4.9716) (35.13 im/s)\n",
            "[TRAIN] epoch 30/30  observation 600/1610 batch loss: 5.4581 (avg 4.9772) (38.40 im/s)\n",
            "[TRAIN] epoch 30/30  observation 700/1610 batch loss: 5.0914 (avg 4.9752) (35.84 im/s)\n",
            "[TRAIN] epoch 30/30  observation 800/1610 batch loss: 4.8270 (avg 4.9786) (25.51 im/s)\n",
            "[TRAIN] epoch 30/30  observation 900/1610 batch loss: 5.1400 (avg 4.9833) (37.76 im/s)\n",
            "[TRAIN] epoch 30/30  observation 1000/1610 batch loss: 4.7288 (avg 4.9861) (44.09 im/s)\n",
            "[TRAIN] epoch 30/30  observation 1100/1610 batch loss: 4.8880 (avg 4.9923) (45.12 im/s)\n",
            "[TRAIN] epoch 30/30  observation 1200/1610 batch loss: 4.8231 (avg 4.9958) (41.26 im/s)\n",
            "[TRAIN] epoch 30/30  observation 1300/1610 batch loss: 5.5134 (avg 4.9964) (17.55 im/s)\n",
            "[TRAIN] epoch 30/30  observation 1400/1610 batch loss: 5.2605 (avg 4.9978) (43.43 im/s)\n",
            "[TRAIN] epoch 30/30  observation 1500/1610 batch loss: 5.1635 (avg 5.0006) (31.57 im/s)\n",
            "[TRAIN] epoch 30/30  observation 1600/1610 batch loss: 4.9954 (avg 5.0002) (32.27 im/s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [5:01:43<00:00, 603.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 validation: Recall@20: 0.5252, MRR@20: 0.2408 \n",
            "\n",
            "Save checkpoint at epoch 29\n",
            "Epoch 29 has loss 5.000897481574775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = main()\n",
        "\n",
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "v8Fhk9FyS95I",
        "outputId": "eff57adc-a41e-4194-fae7-b5a8108a97b8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_total)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ0gyYwaaLHF",
        "outputId": "39122ae0-1e46-4d94-865a-e7c9fa5832e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 113426\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 12603\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 13120\n",
            "--------------------------------------------------\n",
            "Complete load data!\n",
            "complete load model!\n",
            "Test: Recall@20: 0.2997, MRR@20: 0.1287\n"
          ]
        }
      ],
      "source": [
        "model = main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yijue-7Sa7HI"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go65Pw6Sa5ig",
        "outputId": "fc580f0c-b4e5-4949-a6e7-6bcaf37e0b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "item indexes sequence input:  [[1207, 3730]]\n",
            "item index next output:  [2716]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "i = np.random.randint(0, len(test_index[0]))\n",
        "x = [test_index[0][i]]\n",
        "y = [test_index[1][i]]\n",
        "print('item indexes sequence input: ', x)\n",
        "print('item index next output: ', y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUjSJsKxbDzi",
        "outputId": "585c639c-b188-45d4-ba91-756afcc6449f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Dataset info:\n",
            "Number of sessions: 1\n",
            "--------------------------------------------------\n",
            "Is next clicked item in top 20 suggestions:  False\n",
            "Top 20 next item indices suggested: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 196, 1929,  553, 2913, 2973,  766, 1954,  923,  606,  919,  410,  625,\n",
              "          759, 1543,  175,  864, 3108,  358,  617, 2408]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = RecSysDataset([x, y])\n",
        "test_loader = DataLoader(test_data, batch_size = args['batch_size'], shuffle = False, collate_fn = collate_fn)\n",
        "\n",
        "# Step 2: Dự báo các indice tiếp theo mà khách hàng có khả năng click\n",
        "def _preddict(loader, model):\n",
        "    model.eval()\n",
        "    recalls = []\n",
        "    mrrs = []\n",
        "    j = 1\n",
        "    with torch.no_grad():\n",
        "      for seq, target, lens in loader:\n",
        "        seq = seq.to(device)\n",
        "        target = target.to(device)\n",
        "        outputs = model(seq, lens)\n",
        "        logits = F.softmax(outputs, dim = 1)\n",
        "        _, indices = torch.topk(logits, 20, -1)\n",
        "        print('Is next clicked item in top 20 suggestions: ', (target in indices))\n",
        "        print('Top 20 next item indices suggested: ')\n",
        "    return indices\n",
        "\n",
        "_preddict(test_loader, model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yKr9ze8ORAQx"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.10 ('conda_py10')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "3a78893d61157d25d64ba5e3be048e83c726ddc1b37f11cf180810da7e002b90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
